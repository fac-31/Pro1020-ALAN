{
  "documents": [
    "How AI generated code compounds technical debt\n\nAI Coding Tools Are Driving Code Duplication and Technical Debt, GitClear Report Warns\nGitClear\u2019s 2025 AI Copilot Code Quality report reveals a troubling trend: as AI coding assistants like Cursor and GitHub Copilot become ubiquitous, code duplication is surging and long-term code quality is declining. \u201cI don\u2019t think I have ever seen so much technical debt being created in such a short period of time during my 35-year career in technology.\u201d\n\u2014 Kin Lane, API Evangelist\n\n\nKey Findings from 211 Million Lines of Code (2020\u20132024)\nAnalyzing anonymized private repos and 25 major open-source projects, GitClear found:\n\n8x increase in duplicated code blocks (5+ lines) in 2024 vs. prior years \u2014 10x higher than two years ago. 46% of code changes were new lines; copy-pasted lines outnumbered moved lines. \"Moved\" lines \u2014 GitClear\u2019s metric for refactoring and reuse \u2014 are in steep decline.",
    "\"Moved\" lines \u2014 GitClear\u2019s metric for refactoring and reuse \u2014 are in steep decline. \u201cRefactored systems, and moved code in particular, are the signature of code reuse.\u201d\n\u2014 Bill Harding, CEO of GitClear & Amplenote\n\nThis shift signals developers are less likely to consolidate logic into reusable modules \u2014 a direct violation of the DRY (Don\u2019t Repeat Yourself) principle. More Code \u2260 Better Code\nDespite perceived productivity gains, AI-generated code is creating hidden maintenance burdens:\n\nThe Harness State of Software Delivery 2025 report found developers spend more time debugging AI code and fixing security vulnerabilities. Google\u2019s 2024 DORA report: +25% AI usage speeds reviews and docs, but cuts delivery stability by 7.2%. \u201cIf developer productivity continues being measured by commit count or lines added, AI-driven maintainability decay will proliferate.\u201d\n\u2014 Bill Harding\n\n\nThe Real Cost of Code Cloning\nDuplicated code isn\u2019t just messy \u2014 it\u2019s expensive:",
    "\u201cIf developer productivity continues being measured by commit count or lines added, AI-driven maintainability decay will proliferate.\u201d\n\u2014 Bill Harding\n\n\nThe Real Cost of Code Cloning\nDuplicated code isn\u2019t just messy \u2014 it\u2019s expensive: The Real Cost of Code Cloning\nDuplicated code isn\u2019t just messy \u2014 it\u2019s expensive:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImpactConsequenceStorageHigher cloud costsBugsDefects multiply across clonesTestingComplex, error-proneMaintenanceChanges must be made in multiple places\nA 2023 study from Central China Normal University confirms: code clones significantly increase defect rates. The Human Role in AI-Assisted Development\nAI excels at rapid generation, but its limited context window means it often fails to see the full codebase. Humans remain essential for:\n\nRefactoring repetitive logic\nConsolidating modules\nReusing microservices\nEnforcing architectural consistency\n\n\n\u201cThere is a lot of utility that AI provides, but the data from this year affirms why long-term-oriented devs might eye their \u2018tab\u2019 key with a faint sense of foreboding.\u201d\n\u2014 Bill Harding\n\n\nHow to Fight Back",
    "Humans remain essential for:\n\nRefactoring repetitive logic\nConsolidating modules\nReusing microservices\nEnforcing architectural consistency\n\n\n\u201cThere is a lot of utility that AI provides, but the data from this year affirms why long-term-oriented devs might eye their \u2018tab\u2019 key with a faint sense of foreboding.\u201d\n\u2014 Bill Harding\n\n\nHow to Fight Back How to Fight Back\n\nMeasure reuse, not just output (track \"moved\" lines, not LOC). Use AI to refactor \u2014 tools like Cursor can enforce consistency. Set explicit rules: \u201cNever duplicate \u2014 always modify existing code.\u201d\nAudit regularly for clones and redundant systems. Bottom Line\nAI coding tools are powerful accelerators \u2014 but without discipline, they risk turning software into infinite, unmaintainable sprawl. The future of sustainable development depends on using AI to refactor, not just generate.",
    "Monorepo vs Multi-repo vs Git submodule vs Git Subtree\n\nMonorepo vs Multi-repo vs Git submodule vs Git Subtree: A Complete Guide for Developers\nSubodh Shetty\nSubodh Shetty\n\nFollow\n5 min read\n\u00b7\n2 days ago\n44\n\n\n1\n\n\n\nPress enter or click to view image in full size\n\nMonoRepo vs MultiRepo vs Git Submodule vs Git Subtree\nAs projects grow, one question quietly becomes a big one:\n\n\u201cWhere should all this code live?\u201d\n\nSome teams prefer to keep everything in one place. Others prefer to split things into smaller, separate repositories. A few connect repositories using Git submodules or subtrees. In this guide, we\u2019ll walk through each strategy in plain English. You\u2019ll learn what each one does, when it helps, and what you trade off when you choose it. 1. Monorepo\nA monorepo means one big repository for all your projects. That includes backend, frontend, libraries, and sometimes even deployment scripts. Example\nImagine you are building an e-commerce system. Your structure might look like this:",
    "Your structure might look like this: Example\nImagine you are building an e-commerce system. Your structure might look like this:\n\n\nFolder structure\nDevelopers from multiple teams work inside this same repository.",
    "Your structure might look like this:\n\n\nFolder structure\nDevelopers from multiple teams work inside this same repository. Folder structure\nDevelopers from multiple teams work inside this same repository. Why teams use monorepos\nMonorepos make it easier to change related code together. Suppose your frontend and backend share a common API. You can update both sides in one pull request, and both will stay in sync. You also have one build pipeline, one testing setup, and one linting configuration. That makes consistency simple. What to keep in mind\nWhen a monorepo grows, builds can become slow if you do not optimize them. You also need a clear sense of code ownership. Without that, people can make changes in places they shouldn\u2019t. CODEOWNERS files help define who reviews which parts of the repository. When it fits\nMonorepos work best for small to medium teams where services are closely connected. They make shared tooling and cross-team collaboration easier. 2. Multi-repo (or Polyrepo)\nA multi-repo setup means each project has its own repository. It is the most common approach in the industry.",
    "It is the most common approach in the industry. Example\nYour company might have following Git repositories:\n\nPress enter or click to view image in full size\n\nEach repository has its own CI/CD setup, its own issue tracker, and its own release process.",
    "Example\nYour company might have following Git repositories:\n\nPress enter or click to view image in full size\n\nEach repository has its own CI/CD setup, its own issue tracker, and its own release process. Each repository has its own CI/CD setup, its own issue tracker, and its own release process. Why teams use multi-repos\nMulti-repos give teams freedom. Each team controls its own repo, deployment, and tools. The frontend team can use React while the backend uses Spring Boot or Node.js. Access control also becomes easier. Only members who work on a service need access to its repository. Real-world example\nThink of a company that has separate payments, catalog, and shipping teams. Each one builds its own service. They deploy independently and have different release schedules. That independence makes multi-repo a good fit. What to keep in mind\nWhen multiple repos depend on a shared library, keeping them consistent can be hard. If you fix a bug in that library, you need to update each repo using it. Cross-repo changes take longer and require coordination. When it fits\nMulti-repos are ideal for larger teams where services are mostly independent and ownership boundaries are clear.",
    "When it fits\nMulti-repos are ideal for larger teams where services are mostly independent and ownership boundaries are clear. 3. Git Submodules\nA Git submodule adds a reference to another repository at a specific commit. It does not copy the repository\u2019s content into your main repo\u2019s history. Instead, it just stores a pointer to the commit in the external repo. Example\nYou have:\n\nmain-app repository\nshared-logging repository\nYou add it like this:\n\ngit submodule add https://github.com/org/shared-logging.git libs/shared-logging\nYour main repository now contains the shared-logging code inside the libs/shared-logging folder. Updating a submodule\nIf the submodule has new commits, you need to pull them manually:\n\ncd libs/shared-logging\ngit checkout main\ngit pull origin main\ncd ../..\ngit add libs/shared-logging\ngit commit -m \"Update submodule to latest commit\"\nThat updates your main repo to point to the newer commit of the submodule. Cloning your main repo\nWhen someone clones your main repo, they have to run the following to download that external code. :",
    ": Cloning your main repo\nWhen someone clones your main repo, they have to run the following to download that external code. :\n\ngit submodule update --init --recursive\nOptional tracking\nIf you want your submodule to follow a specific branch:\n\ngit submodule add -b main https://github.com/org/shared-logging.git libs/shared-logging\nThen fetch updates using:",
    ":\n\ngit submodule update --init --recursive\nOptional tracking\nIf you want your submodule to follow a specific branch:\n\ngit submodule add -b main https://github.com/org/shared-logging.git libs/shared-logging\nThen fetch updates using: git submodule add -b main https://github.com/org/shared-logging.git libs/shared-logging\nThen fetch updates using:\n\ngit submodule update --remote\nWhy it exists\nSubmodules are designed for situations where you want to reuse code that lives in another repository. It\u2019s like having a dependency that you control. You decide when to upgrade to the next version by updating the pointer. What to keep in mind\nSubmodules need discipline. Submodules don\u2019t auto-update. You must manually pull updates. You have to remember to initialize them and update them when cloning. CI/CD pipelines must also handle them properly. 4. Git Subtree\nWhile submodules keep a pointer to another repository, a Git subtree actually copies the other repository\u2019s content into your own. It is like pulling another repository\u2019s code into a subfolder. Example\nYou can add a subtree like this:",
    "Example\nYou can add a subtree like this: Example\nYou can add a subtree like this:\n\ngit subtree add --prefix=libs/shared-logging https://github.com/org/shared-logging.git main --squash\nThis command copies all code from the shared-logging repository into the folder libs/shared-logging and adds it as part of your project. When the shared library gets updates, you can pull those updates later:\n\ngit subtree pull --prefix=libs/shared-logging https://github.com/org/shared-logging.git main --squash\nIf you make local changes and want to send them back upstream:",
    "When the shared library gets updates, you can pull those updates later:\n\ngit subtree pull --prefix=libs/shared-logging https://github.com/org/shared-logging.git main --squash\nIf you make local changes and want to send them back upstream: git subtree push --prefix=libs/shared-logging https://github.com/org/shared-logging.git main\nHow it works\nA subtree merges the other repository\u2019s history into yours. The files become a permanent part of your repository. Your project can now build without needing the external repository. Advantages\nNo extra setup for developers. Works with normal git clone. No special CI handling required. All code is available locally. What to keep in mind\nYour repository size grows because it includes the subtree\u2019s history. Managing many subtrees can become complex. You need to remember which folder maps to which external repository. When to use\nSubtrees are a good fit when you want to vendor another repository\u2019s code. That means you want to copy it inside your repo and update it occasionally. It\u2019s common for internal forks or open-source libraries that you customize. In Conclusion,",
    "In Conclusion, That means you want to copy it inside your repo and update it occasionally. It\u2019s common for internal forks or open-source libraries that you customize. In Conclusion,\nRepository structure influences how teams work, not just how code is stored. It affects how you test, deploy, and collaborate.",
    "It affects how you test, deploy, and collaborate. Before deciding, ask:\n\nHow independent are your services? How often do they change together? How do you want to manage shared code? A monorepo offers simplicity and consistency. A multi-repo offers independence and flexibility. A submodule links projects that evolve separately. A subtree embeds projects that need to live together. Each one solves a different kind of problem. Once you understand their behavior, choosing the right one becomes straightforward.",
    "Visualize FastAPI endpoints with FastAPI-Voyager\n\nLoading\u2026\nFastAPI Voyager\n{{ state.version }}\nscroll to zoom in/out\ndouble click node to view details. shift + click to see schema's dependencies without unrelated nodes. {{ tag.name }}\n{{ tag.routes.length }}\n{{ route.name }}\nNo routes\n{{ dumpJson }}\nImport core data JSON",
    "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology",
    "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology How I spent two decades tracking down the creators of a 1987 USENET game and learned modern packaging tools in the process. The Discovery: A Digital Time Capsule from 1987\nPicture this: October 26, 1987. The Berlin Wall still stands, the World Wide Web is just text, and software is distributed through USENET newsgroups in text files split across multiple posts. On that day, Edward Barlow posted something special to comp.sources.games\n:\n\u201cconquest \u2013 middle earth multi-player game, Part01/05\u201d\nThat\u2019s how Ed Barlow announced it at the time, before quickly changed the name to Conquer. This was Conquer \u2013 a sophisticated multi-player strategy game that would influence countless others. Players controlled nations in Middle Earth, managing resources, armies, magic systems, and diplomatic relations. What made it remarkable wasn\u2019t just the gameplay, but how it was built and distributed in an era when \u201copen source\u201d wasn\u2019t even a term yet. Chapter 0: University Days.",
    "Chapter 0: University Days. Chapter 0: University Days. It was during these days, in the middle of the 90s, that my fellow students and I spent hours experimenting with terminals in the Computer Unix Labs, USENET, links, news, msgs, and of course: conquer. That game was a gem that required to be the leader of a country, and with a map representing as characters each player could control their elven kingdom, orcish empire, or human armies to fight each other while controlling all the details of the economy. But by 2006, this piece of computing history was trapped in legal limbo. Chapter 1: The Quest Begins (2006)\nAs a university student in Spain in the early \u201990s, I\u2019d encountered Conquer in the Unix labs. Fast forward to 2006, and I realized this pioneering game was at risk of being lost forever. The source code existed, scattered across ancient USENET archives, but its licensing was unclear \u2013 typical of the \u201cpost it and see what happens\u201d era of early internet software distribution.",
    "The source code existed, scattered across ancient USENET archives, but its licensing was unclear \u2013 typical of the \u201cpost it and see what happens\u201d era of early internet software distribution. I started what I thought would be a simple project: get permission from the original authors to relicense the code under GPL so it could be properly preserved and packaged for modern Linux distributions. Simple, right? Chapter 2: Digital Detective Work\nFinding Edward Barlow and Adam Bryant in 2006 was like archaeological work. Email addresses from the 1980s were long dead. USENET posts provided few clues. I scoured old university directories, googled fragments of names, and followed digital breadcrumbs across decades-old forums. The breakthrough came through pure persistence and a bit of luck. After months of searching, I managed to contact Ed Barlow. His response was refreshingly casual: \u201cYes i delegated it all to adam aeons ago. Im easy on it all\u2026. copyleft didnt exist when i wrote it and it was all for fun so\u2026\u201d\nBut there was a catch \u2013 I needed permission from Adam Bryant too, and he seemed to have vanished into the digital ether. Chapter 3: The Long Wait (2006-2011)",
    "Chapter 3: The Long Wait (2006-2011) But there was a catch \u2013 I needed permission from Adam Bryant too, and he seemed to have vanished into the digital ether. Chapter 3: The Long Wait (2006-2011)\nI documented everything on the Debian Legal mailing lists, created a GNU Savannah task (#5945), and even wrote blog posts hoping Adam would find them. The legal experts were clear: I needed explicit written permission from both copyright holders. Years passed. The project stalled. Then, on February 23, 2011, something magical happened. My phone buzzed with a contact form submission:\n\u201cI heard news of the request to release the code. I grant permission to release the code under GPL.\u201d \u2013 Adam Bryant\nHe had found one of my articles online and reached out on his own. Chapter 4: The Plot Twist \u2013 Version 5 Emerges (2025)",
    "Chapter 4: The Plot Twist \u2013 Version 5 Emerges (2025) He had found one of my articles online and reached out on his own. Chapter 4: The Plot Twist \u2013 Version 5 Emerges (2025)\nFast forward to 2025, and Stephen Smoogen contacts me about my relicesing efforts in 2006 and how he was particularly interested in reviving: Conquer Version 5 \u2013 a complete rewrite by Adam with advanced features like automatic data conversion, enhanced stability, and sophisticated administrative tools. This wasn\u2019t just an update; it was a complete reimagining of the game. But V5 had a different legal history. In the \u201990s, there had been commercial arrangements. Would Adam agree to GPL this version too? His response: \u201cI have no issues with applying a new GPL license to Version 5 as well.\u201d\nChapter 5: The Missing Piece \u2013 PostScript Magic",
    "His response: \u201cI have no issues with applying a new GPL license to Version 5 as well.\u201d\nChapter 5: The Missing Piece \u2013 PostScript Magic His response: \u201cI have no issues with applying a new GPL license to Version 5 as well.\u201d\nChapter 5: The Missing Piece \u2013 PostScript Magic\nJust when I thought the story was complete, I discovered another contributor: MaF, who had created PostScript utilities for generating printable game maps \u2013 a crucial feature in the pre-GUI era when players needed physical printouts to strategize. Tracking down MaF in 2025 led me to his company, where he\u2019s now Director of Product Security. His response: \u201cOh, that was a long time ago. But yes, that was me. And I have no problem with relicensing it to GPL.\u201d\nRichard Caley: More Than Just a Legal Footnote\nBut not all searches end with an answer. Some end with silence. My investigation of Richard Caley followed the same digital breadcrumbs. I traced him to the University of Edinburgh, where he worked on speech synthesis. I found his technical contributions to FreeBSD. But the trail went cold around 2005.",
    "But the trail went cold around 2005. Then I found him \u2013 not in a USENET archive, but on the front page of his own website, preserved exactly as he left it in web.archive.org. \u201cRichard Caley suffered a fatal heart attack on the 22nd of April, 2005. He was only 41, but had been an undiagnosed diabetic, probably for some considerable time. His web pages remain as he left them.\u201d\nReading those words felt different from finding a historical record. This wasn\u2019t archival research \u2013 this was walking into someone\u2019s house years after they\u2019d gone and finding a note on the table. The page continued:\n\u201cOver and above his tremendous ability with computers and programming, Richard had a keen mind and knowledge of an extraordinary range of topics, both of which he used in frequent contributions to on-line discussions. Despite his unique approach to speling, his prolific contributions to various news group debates informed and amused many over the years.\u201d\nThe \u201cCaleyisms\u201d \u2013 The Man Behind the Code",
    "Despite his unique approach to speling, his prolific contributions to various news group debates informed and amused many over the years.\u201d\nThe \u201cCaleyisms\u201d \u2013 The Man Behind the Code The \u201cCaleyisms\u201d \u2013 The Man Behind the Code\nAnd then I discovered his \u201cCaleyisms\u201d \u2013 a curated collection of his most brilliant USENET responses that revealed not just a programmer, but a person:\nWhat\u2019s a shell suit? \u201cOil company executive.\u201d\nHow do you prepare for a pyroclastic flow hitting Edinburgh? \u201cHang 1000 battered Mars bars on strings and stand back?\u201d\nOn his book addiction:\n\u201cI never got the hang of libraries, they keep wanting the things back and get upset when they need a crowbar to force it out of my hands.\u201d\nHis humor was dry, intelligent, and uniquely British. In technical discussions, he could be brutally precise:\n\u201cLack of proper punctuation, spacing, line breaks, capitalisation etc. is like bad handwriting, it doesn\u2019t make it impossible to read what was written, just harder. But you probably write in green crayon anyway.\u201d\nA Digital Office Preserved",
    "But you probably write in green crayon anyway.\u201d\nA Digital Office Preserved A Digital Office Preserved\nExploring his preserved website felt like walking through his digital office. The directory structure revealed his passions: FreeBSD how-tos, POVRAY experiments, wallpaper images, technical projects. His self-deprecating humor shone through in his \u201cAbout\u201d section:\n\u201cThankfully I don\u2019t have a photograph to inflict on you. Just use the picture of Iman Bowie to the left and then imagine someone who looks exactly the opposite in every possible way. This probably explains why she is married to David Bowie and I\u2019m not.\u201d\nHere was a complete person \u2013 technical director at Interactive Information Ltd, speech synthesis researcher, FreeBSD enthusiast, Kate Bush fan, and a wit who brightened countless online discussions. The legal reality was harsh: Richard\u2019s contributions to Conquer couldn\u2019t be relicensed. The university couldn\u2019t help contact heirs due to privacy laws. His friends had preserved his memory with a simple ASCII tribute at the end of his page:\n^_^\n(O O)",
    "His friends had preserved his memory with a simple ASCII tribute at the end of his page:\n^_^\n(O O) His friends had preserved his memory with a simple ASCII tribute at the end of his page:\n^_^\n(O O)\n\\_/@@\\\n\\\\~~/\n~~\n- RJC RIP\nIn the Conquer project documentation, Richard Caley isn\u2019t remembered as a \u201cproblem case\u201d or \u201cunlicensable code.\u201d He\u2019s honored as the vibrant person he was \u2013 the brilliant mind behind the \u201cCaleyisms,\u201d the researcher who contributed to speech synthesis, the FreeBSD advocate, and the witty participant in early online communities whose words continue to amuse and inform, decades after he wrote them. Chapter 6: Modern Renaissance \u2013 Enter GitHub, CICD and Modern Distributions\nHere\u2019s where the story gets really interesting. While working on preserving these Unix classics, I decided to learn modern packaging techniques. I chose to implement both APK (Alpine Linux) and Debian packaging for the games.",
    "I chose to implement both APK (Alpine Linux) and Debian packaging for the games. For APK packages, I used Melange \u2013 a sophisticated build system that creates provenance-tracked, reproducible packages for the Wolfi \u201cundistro\u201d. The irony? I discovered this tool when some friend started to work for the company that created it. Chapter 7: The Technical Journey: From USENET to Modern CI/CD\nThe transformation has been remarkable:\n1987 Original:\n- Distributed as split USENET posts\n- Manual compilation with system-specific Makefiles\n- No version control or automated testing\n2025 Revival:\n# Modern CI/CD with GitHub Actions\n- name: Build APK package\nrun: melange build conquer.yaml\n- name: Build Debian package\nrun: dpkg-buildpackage -b\nKey Modern Additions:\n- GPLv3 relicensing\n- Make building system modernization\n- C Codebase partially updated to support modern ANSI C99 specification\n- Debian packaging\n- APK packaging with Melange\nYou can see the complete transformation in the repositories:\n- Conquer v4 \u2013 The original classic\n- Conquer v5 \u2013 The advanced rewrite",
    "Chapter 7: The Technical Journey: From USENET to Modern CI/CD\nThe transformation has been remarkable:\n1987 Original:\n- Distributed as split USENET posts\n- Manual compilation with system-specific Makefiles\n- No version control or automated testing\n2025 Revival:\n# Modern CI/CD with GitHub Actions\n- name: Build APK package\nrun: melange build conquer.yaml\n- name: Build Debian package\nrun: dpkg-buildpackage -b\nKey Modern Additions:\n- GPLv3 relicensing\n- Make building system modernization\n- C Codebase partially updated to support modern ANSI C99 specification\n- Debian packaging\n- APK packaging with Melange\nYou can see the complete transformation in the repositories:\n- Conquer v4 \u2013 The original classic\n- Conquer v5 \u2013 The advanced rewrite - Debian packaging\n- APK packaging with Melange\nYou can see the complete transformation in the repositories:\n- Conquer v4 \u2013 The original classic\n- Conquer v5 \u2013 The advanced rewrite\nOriginal Conquer v4 code, by Ed Barlow and Adam Bryant\n(Conquer running in docker container alongside Apache, Curses to WebSockets output thanks to ttyd. Now we can play through the web!) Conquer Version 5 \u2013 The evolution of the classical Conquer, by Adam Bryant\nChapter 8: The Human Element: Why This Matters\nThis isn\u2019t just about preserving old games \u2013 it\u2019s about preserving the story of computing itself. Ed Barlow and Adam Bryant were pioneers who built sophisticated multiplayer experiences when most people had never heard of the internet. They distributed software through USENET because that\u2019s what you did \u2013 you shared cool things with the community.",
    "They distributed software through USENET because that\u2019s what you did \u2013 you shared cool things with the community. Martin Forssen\u2019s PostScript utilities represent the ingenuity of early developers who solved problems with whatever tools were available. Want to visualize your game state? Write a PostScript generator! The 20-year relicensing effort demonstrates something crucial about open source: it\u2019s not just about code, it\u2019s about community and continuity. Every time someone maintains a legacy project, documents its history, or tracks down long-lost contributors, they\u2019re weaving the threads that connect computing\u2019s past to its future. Lessons for Modern Developers\n- Document everything: Those casual USENET posts became crucial legal evidence decades later\n- License clearly: Ed\u2019s comment that \u201ccopyleft didnt exist when i wrote it\u201d highlights how licensing landscapes evolve\n- Community matters: Adam found my articles because the community was talking about preservation\n- Technical debt is temporal: What seems like legacy tech today might be tomorrow\u2019s archaeological treasure",
    "Lessons for Modern Developers\n- Document everything: Those casual USENET posts became crucial legal evidence decades later\n- License clearly: Ed\u2019s comment that \u201ccopyleft didnt exist when i wrote it\u201d highlights how licensing landscapes evolve\n- Community matters: Adam found my articles because the community was talking about preservation\n- Technical debt is temporal: What seems like legacy tech today might be tomorrow\u2019s archaeological treasure - Technical debt is temporal: What seems like legacy tech today might be tomorrow\u2019s archaeological treasure\n- Modern tools can revive ancient code: Melange and modern CI/CD gave 1987 software a 2025 renaissance\nThe Continuing Story\nBoth Conquer games are now fully GPL v3 licensed and available with modern packaging. They represent not just playable software, but a complete case study in software archaeology, legal frameworks for preservation, and the evolution of development practices across four decades. The next chapter? Teaching these classic strategy games to a new generation of developers and gamers, while demonstrating that proper legal frameworks and modern tooling can give any historical software a second life. Sometimes the best way to learn cutting-edge technology is by applying it to preserve computing history. What historical software deserves preservation in your field? Have you ever traced the lineage of code back to its original creators?",
    "Have you ever traced the lineage of code back to its original creators? What historical software deserves preservation in your field? Have you ever traced the lineage of code back to its original creators? #FreeSoftware #OpenSource #SoftwarePreservation #Unix #GNU #Linux #Packaging #Melange #TechHistory #GameDevelopment #Unix #USENET #GPL #FST #Debian #ncurses #terminal #shell\nRead this article in Spanish / Lee este art\u00edculo en espa\u00f1ol:\nhttps://vejeta.com/conquer-una-odisea-de-20-anos-en-arqueologia-digital/\nThis article was originally written in both English and Spanish, with additional insights and cultural context in the Spanish version.",
    "Email verification protocol",
    "Email verification protocol Verifying control of an email address is a frequent activity on the web today and is used both to prove the user has provided a valid email address, and as a means of authenticating the user when returning to an application. Verification is performed by either:\n-\nSending the user a link they click on or a verification code. This requires the user to switch from the application they are using to their email address and having to wait for the email arrive, and then perform the verification action. This friction often causes drop off in users completing the task. There are privacy implications as the email transmission informs the mail service the applications the user is using and when they used them. -",
    "- -\nThe user logs in with a social login provider such as Apple or Google that provide a verified email address. This requires the application to have set up a relationship with each social provider, and the user to be using one of those services and wanting to share the additional profile information that is also provided in the OpenID Connect flow. The Email Verification Protocol enables a web application to obtain a verified email address without sending an email, and without the user leaving the web page they are on. To enable the functionality, the mail domain delegates email verification to an issuer that has authentication cookies for the user. When the user provides an email to the HTML form field, the browser calls the issuer passing authentication cookies, the issuer returns a token, which the browser verifies and updates and provides to the web application. The web application then verifies the token and has a verified email address for the user.",
    "The web application then verifies the token and has a verified email address for the user. User privacy is enhanced as the issuer does not learn which web application is making the request as the request is mediated by the browser. -\nSD-JWT+KB token: The selective disclosure json web token with key binding is specified in Selective Disclosure for JWT. This protocol does not use the selective disclosure features, it uses the key binding feature which enables a separation of token issuance and token presentation. The SD-JWT+KB is a token composed of two JWTs separated by the\n~\ncharacter. The first JWT is an SD-JWT aka the issuance token and is signed by the issuer and contains theemail\nandemail_verified\nclaims for the user, and the public key used by the browser to make the request. The second JWT is a KB token and is signed by the browser and contains a hash of the first JWT. The resulting SD-JWT+KB is the presentation token, and enables the application to verify the issuer provided the email address for the user without the issuer learning about the specific application -",
    "The resulting SD-JWT+KB is the presentation token, and enables the application to verify the issuer provided the email address for the user without the issuer learning about the specific application - Issuer: The service that verifies the user controls an email address. A DNS record for the email domain delegates email verification to the issuer. The issuer serves a\n.well-known/email-verification\nmetadata file that contains itsissuance_endpoint\nthat is called to obtain an issuance token, and itsjwks_uri\nthat points to the JWKS file containing the public keys used to verify the SD-JWT. The issuer is identified by its domain, an eTLD+1 (egissuer.example\n). The hostname in all URLs from the issuer's metadata MUST end with the issuer's domain. This identifier is what binds the SD-JWT, the DNS delegation, with the issuer.",
    "This identifier is what binds the SD-JWT, the DNS delegation, with the issuer. ). The hostname in all URLs from the issuer's metadata MUST end with the issuer's domain. This identifier is what binds the SD-JWT, the DNS delegation, with the issuer. Verified Email Release: The user navigates to any website that requires a verified email address and an input field to enter the email address. The user focusses on the input field and the browser provides one or emails for the user to select based on emails the user has provided previously to the browser. The user selects a verified email and the app proceeds having obtained the verified email. Are emails that can be verified decorated by the browser in the autocomplete UI? What UX is presented to the user when the app gets a verified email so the user knows it is already verified? sequenceDiagram\nparticipant U as User\nparticipant B as Browser\nparticipant RP as RP Page\nparticipant RPS as RP Server\nparticipant I as Issuer\nparticipant DNS as DNS\nNote over U,DNS: Step 1: Email Request\nU->>RP: Navigate to site",
    "sequenceDiagram\nparticipant U as User\nparticipant B as Browser\nparticipant RP as RP Page\nparticipant RPS as RP Server\nparticipant I as Issuer\nparticipant DNS as DNS\nNote over U,DNS: Step 1: Email Request\nU->>RP: Navigate to site participant B as Browser\nparticipant RP as RP Page\nparticipant RPS as RP Server\nparticipant I as Issuer\nparticipant DNS as DNS\nNote over U,DNS: Step 1: Email Request\nU->>RP: Navigate to site\nRP->>RPS: Nonce request\nRPS->>RPS: Generate nonce, bind to session\nRPS->>RP: Nonce\nRP->>B: Display page\nNote over U,DNS: Step 2: Email Selection\nU->>RP: Focus on email input field\nRP->>B: Input field focused\nB->>U: Display email address list\nU->>B: Select email address\nNote over U,DNS: Step 3: Token Request\nB->>DNS: DNS TXT lookup<br/>_email-verification.$EMAIL_DOMAIN\nDNS->>B: Return iss=issuer.example\nB->>I: GET /.well-known/email-verification\nI->>B: Return metadata\nB->>B: Generate key pair<br/>Create request token\nB->>I: POST request_token=JWT... Note over U,DNS: Step 4: Token Issuance\nI->>I: Verify request\nI->>I: Generate SD-JWT\nI->>B: {\"issuance_token\":\"SD-JWT\"}\nNote over U,DNS: Step 5: Token Presentation\nB->>B: Verify SD-JWT\nB->>I: GET jwks_uri for public keys\nI->>B: Return JWKS",
    "Note over U,DNS: Step 4: Token Issuance\nI->>I: Verify request\nI->>I: Generate SD-JWT\nI->>B: {\"issuance_token\":\"SD-JWT\"}\nNote over U,DNS: Step 5: Token Presentation\nB->>B: Verify SD-JWT\nB->>I: GET jwks_uri for public keys\nI->>B: Return JWKS I->>I: Verify request\nI->>I: Generate SD-JWT\nI->>B: {\"issuance_token\":\"SD-JWT\"}\nNote over U,DNS: Step 5: Token Presentation\nB->>B: Verify SD-JWT\nB->>I: GET jwks_uri for public keys\nI->>B: Return JWKS\nB->>B: Create KB\nB->>RP: Provide SD-JWT+KB\nNote over U,DNS: Step 6: Token Verification\nRP->>RPS: Send SD-JWT+KB\nRPS->>RPS: Parse SD-JWT+KB\nRPS->>DNS: DNS TXT lookup for email domain\nDNS->>RPS: Return iss=issuer.example\nRPS->>I: GET /.well-known/email-verification\nI->>RPS: Return metadata with jwks_uri\nRPS->>I: GET jwks_uri\nI->>RPS: Return JWKS public keys\nRPS->>RPS: Verify SD-JWT\nRPS->>RPS: Verify KB-JWT\nRPS->>RP: Email verification complete\nUser navigates to a site that will act as the RP. -\n1.1 - the RP Server generates a nonce and binds the nonce to the session. -\n1.2 - the RP Server returns a page that has an input field with the\nautocomplete\nproperty set to\"email\"\nand thenonce\nproperty set the the nonce. If the browser receives anissuance_token",
    "If the browser receives anissuance_token -\n1.2 - the RP Server returns a page that has an input field with the\nautocomplete\nproperty set to\"email\"\nand thenonce\nproperty set the the nonce. If the browser receives anissuance_token\nper 4.4 below, then it sends aemailverifed\nevent that has apresentationToken\nproperty. Following is an example of the HTML in the page:\n<input id=\"email\"\ntype=\"email\"\nautocomplete=\"email\"\nnonce=\"12345677890..random\">\n<script>\nconst input = document.getElementById('email')\ninput.addEventListener('emailverified', e => {\n// e.presentationToken is SD-JWT+KB\nconsole.log({\npresentationToken: e.presentationToken\n})\n})\n</script>\nAuthors are exploring alternative HTML and JS API approaches\n-\n2.1 - User focusses on email input field\n-\n2.2 - The browser displays the list of email addresses it has for the user. Q: Are emails that could be verified decorated for user to understand? - 2.3 - User selects an email address from browser selection, or the user types an email into the field.",
    "- 2.3 - User selects an email address from browser selection, or the user types an email into the field. Q: Are emails that could be verified decorated for user to understand? - 2.3 - User selects an email address from browser selection, or the user types an email into the field. Future: allow user to type in a field so we learn about new emails, or if the user does not want the browser to remember emails, the Email Verification Protocol is still available. In the future when we allow the user to use a passkey to authenticate to the issuer, the user can provide a verified email to a web application using a public computer by authenticating with their passkey and not enter any secrets into the public computer. If the RP has performed (1):\n- 3.1 - the browser parses the email domain ($EMAIL_DOMAIN) from the email address, looks up the\nTXT\nrecord for_email-verification.$EMAIL_DOMAIN\n. The contents of the record MUST start withiss=\nfollowed by the issuer identifier. There MUST be only oneTXT\nrecord for_email-verification.$EMAIL_DOMAIN\n. example record",
    "example record . The contents of the record MUST start withiss=\nfollowed by the issuer identifier. There MUST be only oneTXT\nrecord for_email-verification.$EMAIL_DOMAIN\n. example record\n_email-verification.email-domain.example TXT iss=issuer.example\nThis record states that email-domain.example\nhas delegated email verification to the issuer issuer.example\n. If the email domain and the issuer are the same domain, then the record would be:\n_email-verification.issuer.example TXT iss=issuer.example\nAccess to DNS records and email is often independent of website deployments. This provides assurance that an issuer is truly authorized as an insider with only access to websites on\nissuer.example\ncould setup an issuer that would grant them verified emails for any email atissuer.example\n. - 3.2 - if an issuer is found, the browser loads\nhttps://$ISSUER$/.well-known/email-verification\nand MUST follow redirects to the same path but with a different subdomain of the Issuer.",
    "- 3.2 - if an issuer is found, the browser loads\nhttps://$ISSUER$/.well-known/email-verification\nand MUST follow redirects to the same path but with a different subdomain of the Issuer. . - 3.2 - if an issuer is found, the browser loads\nhttps://$ISSUER$/.well-known/email-verification\nand MUST follow redirects to the same path but with a different subdomain of the Issuer. For example, https://issuer.example/.well-known/email-verification\nmay redirect to https://accounts.issuer.example/.well-known/email-verification\n. -\n3.3 - the browser confirms that the\n.well-known/email-verification\nfile contains JSON that includes the following properties: -\nissuance_endpoint - the API endpoint the browser calls to obtain an SD-JWT\n-\njwks_uri - the URL where the issuer provides its public keys to verify the SD-JWT\n-\nsigning_alg_values_supported - OPTIONAL. JSON array containing a list of the JWS signing algorithms (\"alg\" values) supported by both the browser for request tokens and the issuer for issued tokens. The same algorithm MUST be used for both the\nrequest_token\nandissuance",
    "The same algorithm MUST be used for both the\nrequest_token\nandissuance request_token\nandissuance\nwithin a single issuance flow. Algorithm identifiers MUST be from the IANA \"JSON Web Signature and Encryption Algorithms\" registry. If omitted, \"EdDSA\" is the default. \"EdDSA\" SHOULD be included in the supported algorithms list. The value \"none\" MUST NOT be used. Each of these properties MUST include the issuer domain as the root of their hostname. Following is an example .well-known/email-verification\nfile\n{\n\"issuance_endpoint\": \"https://accounts.issuer.example/email-verification/issuance\",\n\"jwks_uri\": \"https://accounts.issuer.example/email-verification/jwks\",\n\"signing_alg_values_supported\": [\"EdDSA\", \"RS256\"]\n}\n-\n3.4 - the browser generates a fresh private / public key and signs a JWT with the private key that has the public key in the JWT header in the JWK format as a\njwk\nclaim that contains the following claims in the payload:- aud - the issuer\n- iat - time when the JWT was signed\n- jti - unique identifier for the token",
    "Following is an example .well-known/email-verification\nfile\n{\n\"issuance_endpoint\": \"https://accounts.issuer.example/email-verification/issuance\",\n\"jwks_uri\": \"https://accounts.issuer.example/email-verification/jwks\",\n\"signing_alg_values_supported\": [\"EdDSA\", \"RS256\"]\n}\n-\n3.4 - the browser generates a fresh private / public key and signs a JWT with the private key that has the public key in the JWT header in the JWK format as a\njwk\nclaim that contains the following claims in the payload:- aud - the issuer\n- iat - time when the JWT was signed\n- jti - unique identifier for the token jwk\nclaim that contains the following claims in the payload:- aud - the issuer\n- iat - time when the JWT was signed\n- jti - unique identifier for the token\n- email - email address to be verified\nThe browser SHOULD select an algorithm from the issuer's signing_alg_values_supported\narray, or use \"EdDSA\" if the property is not present. An example JWT header:\n{\n\"alg\": \"EdDSA\",\n\"typ\": \"JWT\",\n\"jwk\": {\n\"kty\": \"OKP\",\n\"crv\": \"Ed25519\",\n\"x\": \"11qYAYdk9E6z7mT6rk6j1QnXb6pYq4v9wXb6pYq4v9w\" // base64url-encoded public key\n}\n}\ndo we want to register a new JWT\ntyp\nAn example payload\n{\n\"aud\": \"issuer.example\",\n\"iat\": 1692345600,\n\"email\": \"user@example.com\"\n}\n- 3.5 - the browser POSTs to the\nissuance_endpoint\nof the issuer with 1P cookies with a content-type ofapplication/x-www-form-urlencoded\ncontaining arequest_token\nparameter set to the signed JWT and theSec-Fetch-Dest\nheader set toemail-verification\n. POST /email-verification/issuance HTTP/1.1\nHost: accounts.issuer.example\nCookie: session=...",
    "POST /email-verification/issuance HTTP/1.1\nHost: accounts.issuer.example\nCookie: session=... parameter set to the signed JWT and theSec-Fetch-Dest\nheader set toemail-verification\n. POST /email-verification/issuance HTTP/1.1\nHost: accounts.issuer.example\nCookie: session=...\nContent-Type: application/x-www-form-urlencoded\nSec-Fetch-Dest: email-verification\nrequest_token=eyJhbGciOiJFZERTQSIsInR5cCI6IkpXVC...\nOn receipt of a token request:\n-\n4.1 - the issuer MUST verify the request headers:\nContent-Type\nisapplication/x-www-form-urlencoded\nSec-Fetch-Dest\nisemail-verification\n-\n4.2 - the issuer MUST verify the request_token by:\n- parsing the JWT into header, payload, and signature components\n- confirming the presence of, and extracting the\njwk\nandalg\nfields from the JWT header, and theaud\n,iat\n, andemail\n, claims from the payload - verifying the JWT signature using the\njwk\nwith thealg\nalgorithm - verifying the\naud\nclaim exactly matches the issuer's identifier - verifying the\niat\nclaim is within 60 seconds of the current time - verifying the\nemail",
    "POST /email-verification/issuance HTTP/1.1\nHost: accounts.issuer.example\nCookie: session=...\nContent-Type: application/x-www-form-urlencoded\nSec-Fetch-Dest: email-verification\nrequest_token=eyJhbGciOiJFZERTQSIsInR5cCI6IkpXVC...\nOn receipt of a token request:\n-\n4.1 - the issuer MUST verify the request headers:\nContent-Type\nisapplication/x-www-form-urlencoded\nSec-Fetch-Dest\nisemail-verification\n-\n4.2 - the issuer MUST verify the request_token by:\n- parsing the JWT into header, payload, and signature components\n- confirming the presence of, and extracting the\njwk\nandalg\nfields from the JWT header, and theaud\n,iat\n, andemail\n, claims from the payload - verifying the JWT signature using the\njwk\nwith thealg\nalgorithm - verifying the\naud\nclaim exactly matches the issuer's identifier - verifying the\niat\nclaim is within 60 seconds of the current time - verifying the\nemail jwk\nwith thealg\nalgorithm - verifying the\naud\nclaim exactly matches the issuer's identifier - verifying the\niat\nclaim is within 60 seconds of the current time - verifying the\nemail\nclaim contains a syntactically valid email address\n-\n4.3 - the issuer checks if the cookies sent represent a logged in user, and if the logged in user has control of the email provided in the request_token. If so the issuer generates an SD-JWT with the following properties:\n- Header: MUST contain\nalg\n: signing algorithm (SHOULD match the algorithm from the request_token)kid\n: key identifier of key used to signtyp\nset to \"evp+sd-jwt\"\n- Payload: MUST contain the following claims:\niss\n: the issuer identifieriat\n: issued at timecnf\n: confirmation claim containing the public key from the request_token'sjwk\nfieldemail\n: claim containing the email address from the request_tokenemail_verified\n: claim that email is verified per OpenID Connect 1.0",
    "If so the issuer generates an SD-JWT with the following properties:\n- Header: MUST contain\nalg\n: signing algorithm (SHOULD match the algorithm from the request_token)kid\n: key identifier of key used to signtyp\nset to \"evp+sd-jwt\"\n- Payload: MUST contain the following claims:\niss\n: the issuer identifieriat\n: issued at timecnf\n: confirmation claim containing the public key from the request_token'sjwk\nfieldemail\n: claim containing the email address from the request_tokenemail_verified\n: claim that email is verified per OpenID Connect 1.0 fieldemail\n: claim containing the email address from the request_tokenemail_verified\n: claim that email is verified per OpenID Connect 1.0\n- Signature: MUST be signed with the issuer's private key corresponding to a public key in the\njwks_uri\nidentified bykid\n- Header: MUST contain\nExample header:\n{\n\"alg\": \"EdDSA\",\n\"kid\": \"2024-08-19\",\n\"typ\": \"evp+sd-jwt\"\n}\nExample payload:\n{\n\"iss\": \"issuer.example\",\n\"iat\": 1724083200,\n\"cnf\": {\n\"jwk\": {\n\"kty\": \"OKP\",\n\"crv\": \"Ed25519\",\n\"x\": \"11qYAYdk9E6z7mT6rk6j1QnXb6pYq4v9wXb6pYq4v9w\"\n}\n},\n\"email\": \"user@example.com\",\n\"email_verified\": true\n}\nThe resulting JWT has the ~\nappended to it, making it a valid SD-JWT. - 4.4 - the issuer returns the SD-JWT to the browser as the value of\nissuance_token\nin anapplication/json\nresponse. Example:\nHTTP/1.1 200 OK\nContent-Type: application/json\n{\"issuance_token\":\"eyJhbGciOiJFZERTQSIsImtpZCI6IjIwMjQtMDgtMTkiLCJ0eXAiOiJ3ZWItaWRlbnRpdHkrc2Qtand0In0...\"}",
    "Example:\nHTTP/1.1 200 OK\nContent-Type: application/json\n{\"issuance_token\":\"eyJhbGciOiJFZERTQSIsImtpZCI6IjIwMjQtMDgtMTkiLCJ0eXAiOiJ3ZWItaWRlbnRpdHkrc2Qtand0In0...\"} in anapplication/json\nresponse. Example:\nHTTP/1.1 200 OK\nContent-Type: application/json\n{\"issuance_token\":\"eyJhbGciOiJFZERTQSIsImtpZCI6IjIwMjQtMDgtMTkiLCJ0eXAiOiJ3ZWItaWRlbnRpdHkrc2Qtand0In0...\"}\nIf the issuer cannot process the token request successfully, it MUST return an appropriate HTTP status code with a JSON error response containing an error\nfield and optionally an error_description\nfield. When the request does not include the required Content-Type: application/x-www-form-urlencoded\nheader, the server MUST return the 415 HTTP response code\nWhen the request does not include the required Sec-Fetch-Dest: email-verification\nheader:\nHTTP 400 Bad Request\n{\n\"error\": \"invalid-request\",\n\"error_description\": \"Missing or invalid Sec-Fetch-Dest header\"\n}\nThe error_description\nSHOULD specify that the Sec-Fetch-Dest header is missing or invalid.",
    "When the request does not include the required Content-Type: application/x-www-form-urlencoded\nheader, the server MUST return the 415 HTTP response code\nWhen the request does not include the required Sec-Fetch-Dest: email-verification\nheader:\nHTTP 400 Bad Request\n{\n\"error\": \"invalid-request\",\n\"error_description\": \"Missing or invalid Sec-Fetch-Dest header\"\n}\nThe error_description\nSHOULD specify that the Sec-Fetch-Dest header is missing or invalid. {\n\"error\": \"invalid-request\",\n\"error_description\": \"Missing or invalid Sec-Fetch-Dest header\"\n}\nThe error_description\nSHOULD specify that the Sec-Fetch-Dest header is missing or invalid. When the request lacks valid authentication cookies, contains expired/invalid cookies, or the authenticated user does not have control of the requested email address:\nHTTP 401 Unauthorized\n{\n\"error\": \"authentication_required\",\n\"error_description\": \"User must be authenticated and have control of the requested email address\"\n}\nWhen the request_token\nis malformed, missing required claims, or contains invalid values:\nHTTP 400 Bad Request\n{\n\"error\": \"invalid_request\",\n\"error_description\": \"Invalid or malformed request_token\"\n}\nWhen the request_token\nsignature verification fails or the token structure is invalid:\nHTTP 400 Bad Request\n{\n\"error\": \"invalid_token\",\n\"error_description\": \"Token signature verification failed or token structure is invalid\"\n}\nFor internal server errors or temporary unavailability:",
    "When the request lacks valid authentication cookies, contains expired/invalid cookies, or the authenticated user does not have control of the requested email address:\nHTTP 401 Unauthorized\n{\n\"error\": \"authentication_required\",\n\"error_description\": \"User must be authenticated and have control of the requested email address\"\n}\nWhen the request_token\nis malformed, missing required claims, or contains invalid values:\nHTTP 400 Bad Request\n{\n\"error\": \"invalid_request\",\n\"error_description\": \"Invalid or malformed request_token\"\n}\nWhen the request_token\nsignature verification fails or the token structure is invalid:\nHTTP 400 Bad Request\n{\n\"error\": \"invalid_token\",\n\"error_description\": \"Token signature verification failed or token structure is invalid\"\n}\nFor internal server errors or temporary unavailability: HTTP 400 Bad Request\n{\n\"error\": \"invalid_token\",\n\"error_description\": \"Token signature verification failed or token structure is invalid\"\n}\nFor internal server errors or temporary unavailability:\nHTTP 500 Internal Server Error\n{\n\"error\": \"server_error\",\n\"error_description\": \"Temporary server error, please try again later\"\n}\nIn a future version of this spec, the issuer could prompt the user to login via a URL or with a Passkey request. On receiving the issuance_token\n:\n-\n5.1 - the browser MUST verify the SD-JWT per (SD-JWT spec) by:\n- parsing the SD-JWT into header, payload, and signature components\n- confirming the presence of, and extracting the\nalg\nandkid\nfields from the SD-JWT header, and theiss\n,iat\n,cnf\n,email\n, andemail_verified\nclaims from the payload - parsing the email domain from the\nemail\nclaim and looking up theTXT\nrecord for_email-verification.$EMAIL_DOMAIN\nto verify theiss\nclaim matches the issuer identifier in the DNS record - fetching the issuer's public keys from the",
    "On receiving the issuance_token\n:\n-\n5.1 - the browser MUST verify the SD-JWT per (SD-JWT spec) by:\n- parsing the SD-JWT into header, payload, and signature components\n- confirming the presence of, and extracting the\nalg\nandkid\nfields from the SD-JWT header, and theiss\n,iat\n,cnf\n,email\n, andemail_verified\nclaims from the payload - parsing the email domain from the\nemail\nclaim and looking up theTXT\nrecord for_email-verification.$EMAIL_DOMAIN\nto verify theiss\nclaim matches the issuer identifier in the DNS record - fetching the issuer's public keys from the email\nclaim and looking up theTXT\nrecord for_email-verification.$EMAIL_DOMAIN\nto verify theiss\nclaim matches the issuer identifier in the DNS record - fetching the issuer's public keys from the\njwks_uri\nspecified in the.well-known/email-verification\nfile - verifying the SD-JWT signature using the public key identified by\nkid\nfrom the JWKS with thealg\nalgorithm - verifying the\niat\nclaim is within 60 seconds of the current time - verifying the\nemail\nclaim matches the email address the user selected - verifying the\nemail_verified\nclaim is true\n-\n5.2 - the browser then creates an SD-JWT+KB by:\n- taking the verified SD-JWT from step 5.1 as the base token\n- creating a Key Binding JWT (KB-JWT) with the following structure:\n- Header:\nalg\n: same signing algorithm used by the browser's private keytyp\n: \"kb+jwt\"\n- Payload:\naud\n: the RP's originnonce\n: the nonce from the originalnavigator.credentials.get()\ncalliat\n: current time when creating the KB-JWTsd_hash\n: SHA-256 hash of the SD-JWT",
    "email\nclaim and looking up theTXT\nrecord for_email-verification.$EMAIL_DOMAIN\nto verify theiss\nclaim matches the issuer identifier in the DNS record - fetching the issuer's public keys from the\njwks_uri\nspecified in the.well-known/email-verification\nfile - verifying the SD-JWT signature using the public key identified by\nkid\nfrom the JWKS with thealg\nalgorithm - verifying the\niat\nclaim is within 60 seconds of the current time - verifying the\nemail\nclaim matches the email address the user selected - verifying the\nemail_verified\nclaim is true\n-\n5.2 - the browser then creates an SD-JWT+KB by:\n- taking the verified SD-JWT from step 5.1 as the base token\n- creating a Key Binding JWT (KB-JWT) with the following structure:\n- Header:\nalg\n: same signing algorithm used by the browser's private keytyp\n: \"kb+jwt\"\n- Payload:\naud\n: the RP's originnonce\n: the nonce from the originalnavigator.credentials.get()\ncalliat\n: current time when creating the KB-JWTsd_hash\n: SHA-256 hash of the SD-JWT : \"kb+jwt\"\n- Payload:\naud\n: the RP's originnonce\n: the nonce from the originalnavigator.credentials.get()\ncalliat\n: current time when creating the KB-JWTsd_hash\n: SHA-256 hash of the SD-JWT\n- Header:\n- signing the KB-JWT with the browser's private key (the same key pair generated in step 3.4)\n- concatenating the SD-JWT and the KB-JWT separated by a tilde (~) to form the SD-JWT+KB\nExample KB-JWT header:\n{ \"alg\": \"EdDSA\", \"typ\": \"kb+jwt\" }\nExample KB-JWT payload:\n{ \"aud\": \"https://rp.example\", \"nonce\": \"259c5eae-486d-4b0f-b666-2a5b5ce1c925\", \"salt\": \"kR7fY9mP3xQ8wN2vL5jH6tZ1cB4nM9sD8fG3hJ7kL2p\", \"iat\": 1724083260, \"sd_hash\": \"X9yH0Ajrdm1Oij4tWso9UzzKJvPoDxwmuEcO3XAdRC0\" }\n-\n5.3 - the browser sets a TBD hidden field and fires the TBD event ...\ndetails TBD\nThe RP web page now has the SD-JWT+KB from the event, and passes it to the RP server, or the token was posted to the RP server. details TBD\nThe RP server MUST verify the SD-JWT+KB by:\n-",
    "details TBD\nThe RP server MUST verify the SD-JWT+KB by:\n- details TBD\nThe RP web page now has the SD-JWT+KB from the event, and passes it to the RP server, or the token was posted to the RP server. details TBD\nThe RP server MUST verify the SD-JWT+KB by:\n-\n6.1 - the RP server receives the SD-JWT+KB from the web page\n-\n6.2 - the RP parses the SD-JWT+KB by separating the SD-JWT and KB-JWT components (separated by tilde ~)\n-\n6.3 - the RP verifies the KB-JWT by:\n- parsing the KB-JWT into header, payload, and signature components\n- confirming the presence of, and extracting the\nalg\nfield from the KB-JWT header, and theaud\n,nonce\n,iat\n, andsd_hash\nclaims from the payload - verifying the\naud\nclaim matches the RP's origin - verifying the\nnonce\nclaim matches the nonce from the RP's session with the web page - verifying the\niat\nclaim is within a reasonable time window - computing the SHA-256 hash of the SD-JWT and verifying it matches the\nsd_hash\nclaim\n-\n6.4 - the RP verifies the SD-JWT by:",
    "details TBD\nThe RP server MUST verify the SD-JWT+KB by:\n-\n6.1 - the RP server receives the SD-JWT+KB from the web page\n-\n6.2 - the RP parses the SD-JWT+KB by separating the SD-JWT and KB-JWT components (separated by tilde ~)\n-\n6.3 - the RP verifies the KB-JWT by:\n- parsing the KB-JWT into header, payload, and signature components\n- confirming the presence of, and extracting the\nalg\nfield from the KB-JWT header, and theaud\n,nonce\n,iat\n, andsd_hash\nclaims from the payload - verifying the\naud\nclaim matches the RP's origin - verifying the\nnonce\nclaim matches the nonce from the RP's session with the web page - verifying the\niat\nclaim is within a reasonable time window - computing the SHA-256 hash of the SD-JWT and verifying it matches the\nsd_hash\nclaim\n-\n6.4 - the RP verifies the SD-JWT by: iat\nclaim is within a reasonable time window - computing the SHA-256 hash of the SD-JWT and verifying it matches the\nsd_hash\nclaim\n-\n6.4 - the RP verifies the SD-JWT by:\n- parsing the SD-JWT into header, payload, and signature components\n- confirming the presence of, and extracting the\nalg\nandkid\nfields from the SD-JWT header, and theiss\n,iat\n,cnf\n,email\n, andemail_verified\nclaims from the payload - parsing the email domain from the\nemail\nclaim and looking up theTXT\nrecord for_email-verification.$EMAIL_DOMAIN\nto verify theiss\nclaim matches the issuer identifier in the DNS record - fetching the issuer's public keys from the\njwks_uri\nspecified in the.well-known/email-verification\nfile - verifying the SD-JWT signature using the public key identified by\nkid\nfrom the JWKS with thealg\nalgorithm - verifying the\niss\nclaim exactly matches the issuer identifier from the DNS record - verifying the\niat\nclaim is within a reasonable time window - verifying the\nemail_verified\nclaim is true\n-",
    "iat\nclaim is within a reasonable time window - computing the SHA-256 hash of the SD-JWT and verifying it matches the\nsd_hash\nclaim\n-\n6.4 - the RP verifies the SD-JWT by:\n- parsing the SD-JWT into header, payload, and signature components\n- confirming the presence of, and extracting the\nalg\nandkid\nfields from the SD-JWT header, and theiss\n,iat\n,cnf\n,email\n, andemail_verified\nclaims from the payload - parsing the email domain from the\nemail\nclaim and looking up theTXT\nrecord for_email-verification.$EMAIL_DOMAIN\nto verify theiss\nclaim matches the issuer identifier in the DNS record - fetching the issuer's public keys from the\njwks_uri\nspecified in the.well-known/email-verification\nfile - verifying the SD-JWT signature using the public key identified by\nkid\nfrom the JWKS with thealg\nalgorithm - verifying the\niss\nclaim exactly matches the issuer identifier from the DNS record - verifying the\niat\nclaim is within a reasonable time window - verifying the\nemail_verified\nclaim is true\n- iss\nclaim exactly matches the issuer identifier from the DNS record - verifying the\niat\nclaim is within a reasonable time window - verifying the\nemail_verified\nclaim is true\n-\n6.5 - the RP verifies the KB-JWT signature using the public key from the\ncnf\nclaim in the SD-JWT with thealg\nalgorithm from the KB-JWT header\nBelow are notes capturing some discussions of potential privacy implications. -\nThe email domain operator no longer learns which applications the user is verifying their email address to as the applications are no longer sending an email verification code to the user. By using an SD-JWT+KB, the browser intermediates the request and response so that the issuer does not learn the identity of the RP. -\nThe RP can infer if a user is logged into the issuer as the RP receives a SD-JWT when the user is logged in, and does not when the user is not logged in. -\nThe issuer may learn the user has email at a mail domain it is authoritative for that it did not know the user had.",
    "-\nThe issuer may learn the user has email at a mail domain it is authoritative for that it did not know the user had. -\nThe issuer may learn the user has email at a mail domain it is authoritative for that it did not know the user had. The web page would call an API passing the email address and nonce. It would return a promise that resolves to the SD_JWT or an error response. The API would only be callable after a user gesture such as clicking a button labelled verify on the web page. This provides the web page in more flexibility in how to gather the email address. For example, if the web page is using EVP for login, and the user has used different emails for login and those are stored in cookies, the page can display the list of emails and an option to provide a different one. The user can then select the email they want to use rather than having to type it into a text field.",
    "The user can then select the email they want to use rather than having to type it into a text field. In addition to, or instead of the browser sending cookies to the Issuer, the Issuer could return a WebAuthN request to the browser if it has credentials for the user identified by the email address. The browser would then interact with the user and provide the WebAuthN response to the Issuer, authenticating the user, and the Issuer would then return the SD-JWT. Rather than the DNS TXT record, the Mail Domain would host a JSON file in the .wellknown domain. This creates challenges for the long tail of individually owned domains:\n- would require a domain that is used just for email to now have to support a web server\n- the mail domain is usually an apex domain, which does not support CNAME, complicating hosting a web site",
    "Using bubblewrap to add sandboxing to NetBSD",
    "Using bubblewrap to add sandboxing to NetBSD Google Summer of Code 2025 Reports: Using bubblewrap to add sandboxing to NetBSD\nThis report was written by Vasyl Lanko as part of Google Summer of Code 2025. Introduction\nAs of the time of writing, there is no real sandboxing technique available to NetBSD. There is chroot, which can be considered a weak sandbox because it modifies the root directory of the process, effectively restricting the process' view of the file system, but it doesn't isolate anything else, so all networking, IPC, and mounts inside this restricted file system are the same as of the system, and are accessible. There has already been some research on implementing kernel-level isolation in NetBSD with tools like gaols, mult and netbsd-sandbox, but they haven't been merged to NetBSD. Other operating systems have their own ways to isolate programs, FreeBSD has jails, and Linux has namespaces. Project Goals",
    "Project Goals Project Goals\nThe goal of this project is to bring a new way of sandboxing to NetBSD. More specifically, we want to implement a mechanism like Linux namespaces. These namespaces allow the isolation of parts of the system from a namespace, or, as the user sees it, from an application. NetBSD has compat_linux to run Linux binaries on NetBSD systems, and the implementation of namespaces can also be utilized to emulate namespace-related functionality of Linux binaries. A simple example to visualize our intended result is to consider an application running under an isolated UTS namespace that modifies the hostname. From the system's view, the hostname remains the same old hostname, but from the application's view it sees the modified hostname. Project Implementation\nLinux has 8 namespace types, in this project we will focus on only 2 of them:\n- UTS namespace, it is the simplest so we can focus on building the general namespace infrastructure with little namespace-specific details",
    "Project Implementation\nLinux has 8 namespace types, in this project we will focus on only 2 of them:\n- UTS namespace, it is the simplest so we can focus on building the general namespace infrastructure with little namespace-specific details - UTS namespace, it is the simplest so we can focus on building the general namespace infrastructure with little namespace-specific details\n- mount namespace, it is a prerequisite to most other namespace types because UNIX follows the philosophy of \"everything is a file\", so we need a separate mount namespace to have different configuration files on the same location as the system. Linux creates namespaces via the unshare or clone system calls, and it will also be our way of calling the namespace creation logic. We setup the base for implementing Linux namespaces in the NetBSD kernel using kauth, the subsystem managing all authorization requests inside the kernel. It associates credentials with objects, and because the namespace lifecycle management is related to the credential lifecycle it handles all the credential inheritance and reference counting for us. (Thanks kauth devs!)",
    "(Thanks kauth devs!) We separate the implementation of each namespace in a different secmodel, resulting in a similar framework to Linux which allows the isolation of a single namespace type. Our implementation also allows users to pick whether they want to have namespace support, and of what kind, via compilation flags, just like in Linux. UTS namespace\nUTS stands for UNIX Timesharing System, because it allows multiple users to share a single computer system. Isolating the utsname\ncan be useful to give users the illusion that they have control over the system's hostname, and also, for example, to give different hostnames to virtual servers. The UTS namespace stores the namespace's hostname, domain name, and their lengths. To isolate the utsname\nwe need to first create a copy of the current UTS information, plus we need a variable containing the number of credentials referencing this namespace, or, in simpler terms, the reference count of this namespace.",
    "To isolate the utsname\nwe need to first create a copy of the current UTS information, plus we need a variable containing the number of credentials referencing this namespace, or, in simpler terms, the reference count of this namespace. This namespace specific information needs to be saved somewhere, and for that we use the credential's private_data\nfield, so we can use a UTS_key\nto save and retrieve UTS\nrelated information from the secmodel. The key specifies the type of information we want to retrieve from the private_data\n, hence using a UTS_key\nfor the UTS namespace. The key for each namespace is a fixed value (we don't create a new key for every credential), but the retrieved value for that key from different credentials may be different. We had to modify kernel code that was directly accessing the hostname\nand domainname\nvariables, to instead call get_uts()\n, which retrieves the UTS struct for the namespace of the calling process. We didn't modify occurrences in kernel drivers because drivers are not part of any namespace, so they should still access the system's resources directly. MNT namespace",
    "MNT namespace MNT namespace\nThe MNT namespace isolates mounts across namespaces. It is used to have different versions of mounted filesystems across namespaces, meaning a user inside a mount namespace can mount and unmount whatever they want without affecting or even breaking the system. The mount namespace structure in Linux is fairly complicated. To have something similar in NetBSD we need to be able to control the mounts accessed by each namespace, and for that we need to control what is each namespace's mountlist, this is also enough for unmounting file systems, because in practice we can just hide them. For the mount_namespace, mountlist structure and the number of credentials using the mount namespace are stored in the credential's private data with the MNT_key\n. Similarly to the UTS namespace, we had to modify kernel code to not directly access the mountlist\n, but instead go through a wrapper called get_mountlist()",
    "Similarly to the UTS namespace, we had to modify kernel code to not directly access the mountlist\n, but instead go through a wrapper called get_mountlist() . Similarly to the UTS namespace, we had to modify kernel code to not directly access the mountlist\n, but instead go through a wrapper called get_mountlist()\nwhich returns the correct mountlist for the namespace the calling process resides in. Implementation for the mount namespace is immensely more complex than for the UTS namespace, it involves having a good understanding of both Linux and NetBSD behaviour, and I would frequently find myself wondering how to implement something after reading the Linux man pages, which would lead to me looking for it in the Linux source code, understanding it, then going back to NetBSD source code, trying to implement it, and seeing it's too different to implement in the same way. Project Status\nYou can find all code written during this project in GitHub at maksymlanko/netbsd-src gsoc-bubblewrap\nbranch. Because I intend to continue this work outside of GSoC, I want to reinforce that this was the last commit still during GSoC on gsoc-bubblewrap",
    "Because I intend to continue this work outside of GSoC, I want to reinforce that this was the last commit still during GSoC on gsoc-bubblewrap branch. Because I intend to continue this work outside of GSoC, I want to reinforce that this was the last commit still during GSoC on gsoc-bubblewrap\nbranch and this was the last one for the mnt_ns\nstill WIP branch. The link includes implementation of general namespace code via secmodels, implementation of the UTS namespace and related ATF-tests, and the work-in-progress implementation of mount namespaces. The mount namespace functionality is not finished as it would require much more work than the time available for this project. To complete it, it would be required invasive and non-trivial changes to the original source code, and, of course, more time. Future Work\nAs previously mentioned, Linux has 8 namespace types, it is important to see which of the missing namespaces are considered useful and feasible to implement.",
    "Future Work\nAs previously mentioned, Linux has 8 namespace types, it is important to see which of the missing namespaces are considered useful and feasible to implement. Future Work\nAs previously mentioned, Linux has 8 namespace types, it is important to see which of the missing namespaces are considered useful and feasible to implement. I believe that after mount namespaces it would be interesting to implement PID namespaces as this in combination with mount namespaces would permit process isolation from this sandbox. Afterwards, implementing user namespaces would allow users to get capabilities similar to root\nin the namespace, giving them sudo\npermissions while still restricting system-wide actions like shutting down the machine. A lower hanging fruit is to implement the namespace management functionality, which in Linux is lsns to list existing namespaces, and setns to move the current process to an already existing namespace. Challenges\n- Semantics. Did you know the unmount system call with MNT_FORCE flag in Linux (usually) returns EBUSY, and in NetBSD it forces the unmounting? One of them makes it easier to implement mount namespaces.",
    "One of them makes it easier to implement mount namespaces. - The behaviour of namespaces is not fully specified in the man pages. If something is not clear from the man pages you need to read the source code. - Unexpected need to learn a lot of VFS concepts and their differences in NetBSD and Linux. - There was a much bigger research component than I anticipated. In the end, Linux and NetBSD are different operating systems, implemented in different ways. Linux is complex and it is not trivial to port namespaces to NetBSD. Notes\nThe project is called \"Using bubblewrap to add sandboxing to NetBSD\" and was initially projected to emulate the unshare\nsystem call into compat_linux\n, but, seeing that having namespaces could be useful for NetBSD, and that it would be easy to add to compat_linux\nafterwards, we decided to instead implement namespaces directly in the NetBSD kernel. Implementing other system calls necessary to make the bwrap",
    "Implementing other system calls necessary to make the bwrap afterwards, we decided to instead implement namespaces directly in the NetBSD kernel. Implementing other system calls necessary to make the bwrap\nlinux binary work correctly also wouldn't be as satisfying as implementing namespaces directly into NetBSD, so this was why the project was initially called \"Using bubblewrap to add sandboxing to NetBSD\" but nowadays it would be more accurate to call it \"Sandboxing in NetBSD with Linux-like namespaces\". Thanks\nI am very grateful to Google for Google Summer of Code, because without it I wouldn't have learned so much this summer, wouldn't have met with smart and interesting people, and for sure wouldn't have tried to contribute to a project like NetBSD, even if I always wanted to write operating systems code... But, the biggest thing I will take with me from this project is the confidence to be able to contribute to NetBSD and other open source projects.",
    "But, the biggest thing I will take with me from this project is the confidence to be able to contribute to NetBSD and other open source projects. I would also like to thank the members of the NetBSD organization for helping me throughout this project, and more specifically:\n- Taylor R. Campbell, Harold Gutch and Nia Alarie from IRC, for helping me fix a nasty\nLD_LIBRARY_PATH\nbug I had on my system which wouldn't let me finish compiling NetBSD, and general GSoC recomendations. - Emmanuel Dreyfus from\ntech-kern\n, with whom I discussed ideas for projects and proposal suggestions, and in the end inspired the namespaces project. - Christoph Badura and Leonardo Taccari who volunteered to be my mentors. They took time to research and answer my questions, anticipated possible problems in my approaches, and always pointed me in the right direction, daily, during all of GSoC's period. This project is from the 3 of us.",
    "Montana Becomes First State to Enshrine 'Right to Compute' into Law",
    "Montana Becomes First State to Enshrine 'Right to Compute' into Law Montana has made history as the first state in the U.S. to legally protect its citizens\u2019 right to access and use computational tools and artificial intelligence technologies. Governor Greg Gianforte signed Senate Bill 212, officially known as the Montana Right to Compute Act (MRTCA), into law. The groundbreaking legislation affirms Montanans\u2019 fundamental right to own and operate computational resources \u2014 including hardware, software, and AI tools \u2014 under the state\u2019s constitutional protections for property and free expression. Supporters of the bill say it represents a major step in securing digital freedoms in an increasingly AI-driven world. \u201cMontana is once again leading the way in defending individual liberty,\u201d said Senator Daniel Zolnikov, the bill\u2019s sponsor and a longtime advocate for digital privacy. \u201cWith the Right to Compute Act, we are ensuring that every Montanan can access and control the tools of the future.\u201d",
    "\u201cWith the Right to Compute Act, we are ensuring that every Montanan can access and control the tools of the future.\u201d While the law allows state regulation of computation in the interest of public health and safety, it sets a high bar: any restrictions must be demonstrably necessary and narrowly tailored to serve a compelling interest. Legal experts note that this is one of the most protective standards available under Montana law. The act also includes provisions for AI-controlled critical infrastructure, requiring both a \u201cshutdown mechanism\u201d to allow human control and annual safety reviews \u2014 a move aimed at balancing innovation with public safety concerns. The bill has drawn praise from privacy advocates and tech policy groups. Tanner Avery, Policy Director at the free-market think tank Frontier Institute, called the law a \u201cflag in the ground\u201d for digital rights, adding: \u201cMontana has made clear it will treat any attempt to infringe on fundamental digital freedoms with the utmost scrutiny.\u201d",
    "Tanner Avery, Policy Director at the free-market think tank Frontier Institute, called the law a \u201cflag in the ground\u201d for digital rights, adding: \u201cMontana has made clear it will treat any attempt to infringe on fundamental digital freedoms with the utmost scrutiny.\u201d The MRTCA stands in stark contrast to recent regulatory efforts in other states, such as California, Virginia, and New York, where proposals to rein in AI technologies have either failed or been heavily revised. Montana\u2019s approach leans toward empowering individual users rather than restricting access. The law has already inspired similar efforts in New Hampshire, where lawmakers are pushing a constitutional amendment guaranteeing access to computation. Rep. Keith Ammon, the state\u2019s Majority Floor Leader, praised Montana\u2019s leadership: \u201cThis is the kind of bold move that sets the tone for the rest of the country.\u201d\nNationally, the Right to Compute movement is gaining traction. Spearheaded by the grassroots group RightToCompute.ai, the campaign argues that computation \u2014 like speech and property \u2014 is a fundamental human right. \u201cA computer is an extension of the human capacity to think,\u201d the organization states.",
    "\u201cA computer is an extension of the human capacity to think,\u201d the organization states. The movement is supported by Haltia.AI, a Dubai-based AI startup, and the ASIMOV Protocol, a blockchain consortium advocating for decentralized AI infrastructure. Talal Thabet, Co-Founder of both groups, praised Montana\u2019s law as \u201ca monumental step forward in ensuring individuals retain control of their own data and digital tools.\u201d\nAs debates over AI governance and digital rights continue to evolve, Montana\u2019s bold new law could serve as a blueprint for other states seeking to safeguard freedom in the digital era.",
    "Show HN: Pipeflow-PHP \u2013 Automate anything with pipelines even non-devs can edit",
    "Show HN: Pipeflow-PHP \u2013 Automate anything with pipelines even non-devs can edit Pipeflow is a lightweight pipeline engine for PHP applications. It lets you describe complex automations as a sequence of small, reusable processing steps called stages. The real superpower is that the entire flow can be expressed in a clear XML format that is easy to read, visualise, and reason about\u2014so even non-developers can review, maintain, and update automations without touching PHP code (but you can also configure the pipelines via hard coded php code). Each stage receives a shared context, performs a focused unit of work, and returns the enriched context to the next stage. By chaining stages together you can orchestrate complex jobs while keeping each piece easy to maintain and test.",
    "By chaining stages together you can orchestrate complex jobs while keeping each piece easy to maintain and test. In other words Pipeflow library gives you the instruments to instantiate one or more pipelines from an xml configuration, providing starting data in an initial context (optionally), and execute them when you want. What you will need to do is use these instruments in your web application to allow your actors to: edit the pipeline's configurations xml (via a text editor), save the pipeline xml configuration somewhere (e.g. your application db), and, when your application need to start a pipeline (manually or through a cron), just load the xml, feed it in the Pipeline class instance, and launch it. - Why Pipeflow matters\n- Real Use Cases\n- Other example use cases\n- Installation and Documentation\n- Quick introduction to pipelines\n- Extending with custom stages\n- Learn more\n- Contribute to PipeFlow\n- License\n- Human-friendly configuration \u2013 describe automations in an XML document that business users and developers alike can read, review, and edit safely.",
    "- Why Pipeflow matters\n- Real Use Cases\n- Other example use cases\n- Installation and Documentation\n- Quick introduction to pipelines\n- Extending with custom stages\n- Learn more\n- Contribute to PipeFlow\n- License\n- Human-friendly configuration \u2013 describe automations in an XML document that business users and developers alike can read, review, and edit safely. - Learn more\n- Contribute to PipeFlow\n- License\n- Human-friendly configuration \u2013 describe automations in an XML document that business users and developers alike can read, review, and edit safely. - Composable workflows \u2013 build sophisticated automations by wiring together focused stages instead of writing one-off scripts. - Consistent execution model \u2013 every stage works with the same\nPipelineContext\n, making it straightforward to pass data between steps. - Configurable runtime \u2013 author pipelines either in PHP or in XML, choose the configuration style that best fits your team. - Extensible catalogue \u2013 register your own custom stages to integrate third-party services, generative AI calls, or bespoke business logic. Here is some real use cases which leverages the power of PipeFlow\n-",
    "Here is some real use cases which leverages the power of PipeFlow\n- PagineDaColorare.it: A wordpress website that automatically create and published coloring pages for children, daily, using the AI. This website uses two wordpress plugins I've developed (that maybe i will publish in future): one of them exposes pipeflow-php into wordpress, adding some custom stages to manage wordpress (creating posts, saving images, setting custom fields, category and tags) and allowing to modify the pipeline's xml from the wordpress admin panel (so that i can refine it, improve the content creation logic, change the logic on holidays, i.e. Christmas, and so on). The other plugins adds some more custom stages to pipeflow which allows to generate text and images with OpenAI apis. All these new custom stages is then used together to automatically run the coloring page content generation pipeline daily, with a cron",
    "All these new custom stages is then used together to automatically run the coloring page content generation pipeline daily, with a cron . All these new custom stages is then used together to automatically run the coloring page content generation pipeline daily, with a cron. The advantage is that anyone, even non-developers, can refine, mantain, edit the coloring page content generation pipeline logic, simply by changing the XML configuration in the wordpress admin panel. The coloring page content generation pipeline configuration is now quite complex, but is very easy to read, understand and mantain: it combines many different stage types which randomizes coloring pages themes, subjects, actions, asking the supporting of the AI in different phases of the pipeline execution.",
    "The coloring page content generation pipeline configuration is now quite complex, but is very easy to read, understand and mantain: it combines many different stage types which randomizes coloring pages themes, subjects, actions, asking the supporting of the AI in different phases of the pipeline execution. -\nFiaberello.it: Similar to the website above, this is another website I've developed with the power of pipeflow. It automaticallys creates and publish fairy tales for children, with a cover image for each tale. This is more a test/example, it's pipeline is more simple and refined than the previous one, so it can be even improved. -\nEditorial automation for any CMS \u2013 Create a plugin for your CMS which leverage pipeflow to build custom workflows which can be easily edited and refined by any actor in your team, even non developers: fetch posts, transform content, and trigger publication flows from scheduled pipelines, with editors able to tweak behaviour directly in XML, allowing any actor in your team (including non-developers) to mantain, refine, change the workflow. -\nBack-office data processing \u2013 build nightly ETL jobs that consume feeds, clean data, and sync results to downstream services without redeploying code. -",
    "- -\nBack-office data processing \u2013 build nightly ETL jobs that consume feeds, clean data, and sync results to downstream services without redeploying code. -\nMarketing and CRM orchestration \u2013 enrich leads, call external APIs, and keep SaaS tools in sync while letting stakeholders adjust logic themselves. -\nAI-assisted content workflows \u2013 combine prompt generation, randomisation, and templating stages to automate creative tasks, like i did on the websites above. -\nAny automation/workflow you can image, easily mantained by even non-developers - By allowing to create custom stages, you can encapsulate your custom business logic in new custom stages, which then can be used in your pipelines. These pipelines can then be edited, mantained or refined by any actor in your team, easily and visually by an easy to reason and read XML configuration. The full reference, including installation instructions, quick start, and detailed stage catalogue, lives in DOCUMENTATION.md.",
    "The full reference, including installation instructions, quick start, and detailed stage catalogue, lives in DOCUMENTATION.md. The full reference, including installation instructions, quick start, and detailed stage catalogue, lives in DOCUMENTATION.md. A pipeline describes the ordered stages that should run and the data they exchange. Typical stages read or write values from the PipelineContext\nwhich is a container which contains parameters and their values, transform data, or control the flow of execution (loops, conditionals, etc.). The pipeline starts with an empty context, but you can feed a starting context from code if you want to provide the pipeline with prepared data to be available to the stages.",
    "The pipeline starts with an empty context, but you can feed a starting context from code if you want to provide the pipeline with prepared data to be available to the stages. Each stage can reads and write data (parameters) to the context and perform operations (even custom operations by implementing custom stages, like calling apis, performing custom business logic operations, etc...), which can then be read and manipulated by the subsequent stages, until the pipelines finish the execution. At that point, the manipulated context is returned by the pipeline (with all the parameters written by the stages that has been executed). Pipelines can be declared in XML so they can be edited without touching PHP code. A minimal XML pipeline looks like the following. <?xml version=\"1.0\" encoding=\"utf-8\"?>\n<pipeline id=\"hello_world\">\n<stages>\n<stage type=\"SetValue\">\n<settings>\n<param name=\"parameterName\">message</param>\n<param name=\"parameterValue\">Hello Pipeflow!</param>\n</settings>\n</stage>\n<stage type=\"Echo\">\n<settings>\n<param name=\"text\">%%message%%</param>\n</settings>\n</stage>\n</stages>\n</pipeline>",
    "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<pipeline id=\"hello_world\">\n<stages>\n<stage type=\"SetValue\">\n<settings>\n<param name=\"parameterName\">message</param>\n<param name=\"parameterValue\">Hello Pipeflow!</param>\n</settings>\n</stage>\n<stage type=\"Echo\">\n<settings>\n<param name=\"text\">%%message%%</param>\n</settings>\n</stage>\n</stages>\n</pipeline> <param name=\"parameterValue\">Hello Pipeflow!</param>\n</settings>\n</stage>\n<stage type=\"Echo\">\n<settings>\n<param name=\"text\">%%message%%</param>\n</settings>\n</stage>\n</stages>\n</pipeline>\nYour application tells pipeflow to load the XML configuration, pipeflow will automatically configure the pipeline and prepares it for execution. Your application can then launch the pipeline when it's needed simply by calling the execute() method on the pipeline instance (on demand or even via a cron). If you want, you can also pass a pre-defined starting context (if you want to feed, for example, some data from code into the pipeline execution, that can be used by the stages). Because the pipeline definition is data-driven, you can adjust parameters or reorder stages without redeploying code.",
    "Because the pipeline definition is data-driven, you can adjust parameters or reorder stages without redeploying code. Because the pipeline definition is data-driven, you can adjust parameters or reorder stages without redeploying code. ### Configuring programmatically via PHP Since XML is the easier way to configure pipelines \"visually\" and allows also non-developers to edit and mantain them by enabling any actor to manage automations in your web applications, you can also configure the pipelines programmatically in your php code. This may have sense for example for those business logic automations that doesn't need to be edited/mantained from your application administration panels, are fixed (doesn't change often), or doesn't need to be mantained by non-developers actors. More info in the DOCUMENTATION.md\nPipeflow ships with a catalogue of built-in stages, but you can register your own custom stages to integrate APIs, internal systems, or platform-specific behaviour. Once registered, custom stages become available to both PHP and XML pipelines, letting you reuse them across projects.",
    "Once registered, custom stages become available to both PHP and XML pipelines, letting you reuse them across projects. The full reference, including installation instructions, control-flow stages, and detailed stage catalogue, lives in DOCUMENTATION.md. Pipeflow thrives on community input and it surely needs improvements and features: Whether you want to improve the core engine, add new features, add new built-in stages, fix bugs, or share feedback from real-world deployments, we would love to collaborate. Check out CONTRIBUTING.md for guidelines on reporting issues, proposing ideas, and submitting pull requests. Pipeflow is distributed under the permissive BSD 3-Clause License, which keeps the project friendly for both open-source and commercial use while encouraging community contributions.",
    "I Am Mark Zuckerberg",
    "I Am Mark Zuckerberg Welcome to iammarkzuckerg.com\nNo, not THAT Mark Zuckerberg-this one's busy helping Hoosiers, not launching social networks. Relax, you haven't accidentally logged into Facebook or the Metaverse. You're on the site of Mark S. Zuckerberg, Indiana's original bearer of the name, proud bankruptcy attorney, and frequent recipient of confused emails from people seeking tech support or handouts of money. What I Really Do:\n- Help people obtain a fresh financial start (no passwords required)\n- Offer dependable, human-involved advice (my artificial intelligence is powered by coffee)\n- Answer local legal questions, not privacy scandals\nReal Zuckerberg Facts:\n- Shares a name, not fortune, with the Facebook founder\n- Gets mistaken daily for a tech billionaire\n- Has written zero social media apps, but plenty of court briefs\nFun Fact:\nIn Indiana, saying \"I'm Mark Zuckerberg\" gets more laughs than likes. But if you need trustworthy bankruptcy help, you're in exactly the right place!",
    "But if you need trustworthy bankruptcy help, you're in exactly the right place! Fun Fact:\nIn Indiana, saying \"I'm Mark Zuckerberg\" gets more laughs than likes. But if you need trustworthy bankruptcy help, you're in exactly the right place! Click around, get to know your (non-billionaire) local Mark, and remember: No login required. Click Here to See How Other\nWebsites Have Reacted to This\nInteresting Things That Have Happened to Me Because My Name is Mark Zuckerberg\nFor a complete list of things that have happened to Mark Zuckerberg click here\nLike I said, I don't wish Mark E. Zuckerberg any ill will at all. I hope the best for him, but let me tell you this: I will rule the search for \"Mark Zuckerberg bankruptcy\". And if he does fall upon difficult financial times, and happens to be in Indiana, I will gladly handle his case in honor of our eponymy.",
    "Ironclad \u2013 formally verified, real-time capable, Unix-like OS kernel",
    "Ironclad \u2013 formally verified, real-time capable, Unix-like OS kernel Ironclad is a (partially) formally verified, real-time capable, UNIX-like operating system kernel for general-purpose and embedded uses. It is written in SPARK and Ada, and is comprised of 100% free software. Ironclad features a familiar POSIX-compatible interface, true simultaneous preemptive multitasking, Mandatory Access Control (MAC), and support for hard real-time scheduling. Ironclad is fully open source and distributed under the GPLv3, ensuring it remains free. No firmware blobs are needed or shipped with the kernel. Every piece of the stack is open source. SPARK's state of the art formal verification is employed for ensuring absence of errors and correctness of big portions of Ironclad, like cryptography, MAC, and user-facing facilities. Ported to several platforms and boards, and designed to be easily portable to many more. Dependency on only the GNU toolchain allows for easy cross-compilation.",
    "Dependency on only the GNU toolchain allows for easy cross-compilation. Ported to several platforms and boards, and designed to be easily portable to many more. Dependency on only the GNU toolchain allows for easy cross-compilation. Ironclad will always be free for use, study, and modification, so, to support the project, we rely on the use of donations and grants. Every contribution makes a difference and allows us to do more. This project is funded through NGI Zero Core, a fund established by NLnet with financial support from the European Commission's Next Generation Internet program. Learn more at the NLnet project page. Additionally, we would like to thank the following organizations:",
    "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
    "Zensical \u2013 A modern static site generator built by the Material for MkDocs team Zensical \u2013 A modern static site generator built by the Material for MkDocs team\u00b6\nWe are thrilled to announce Zensical, our next-gen static site generator designed to simplify the process of building documentation sites. Distilled from a decade of experience, Zensical is our effort to overcome the technical limitations of MkDocs, reaching far beyond its capabilities. Zensical is the result of thousands of hours of work \u2013 built from the ground up for a modern and comfortable authoring experience, while making it easy for developers to extend and customize Zensical through its upcoming module system. Our goal is to support docs-as-code workflows with tens of thousands of pages, without compromising performance or usability. To make the transition seamless, compatibility comes first. We're putting significant effort into ensuring a smooth migration from Material for MkDocs for all users. Zensical can natively read mkdocs.yml",
    "Zensical can natively read mkdocs.yml , allowing you to build your existing project with minimal changes. As of now, a subset of plugins is supported, and we're working on feature parity in the coming months. Zensical is fully Open Source, licensed under MIT, and can be used for any purpose, including for commercial use. We're also saying goodbye to our sponsorware model, replacing it with our new offering for professional users: Zensical Spark. This allows us to stay independent, maximizing user value, as we shape the future of Zensical together with you. You can subscribe to our newsletter to stay in the loop. This is the second article in a four-part series:\n- Transforming Material for MkDocs\n- Zensical \u2013 A modern static site generator built by the creators of Material for MkDocs. - What happens to the features in Insiders coming November 11, 2025\n- A path forward for our community coming November 18, 2025\nWhy Zensical?\u00b6",
    "- What happens to the features in Insiders coming November 11, 2025\n- A path forward for our community coming November 18, 2025\nWhy Zensical?\u00b6 - What happens to the features in Insiders coming November 11, 2025\n- A path forward for our community coming November 18, 2025\nWhy Zensical?\u00b6\nSince its initial release in 2016, Material for MkDocs has helped tens of thousands of teams to publish and maintain reliable documentation. However, in recent years, it has become apparent that we were running up against limitations of our core dependency, MkDocs. These limitations proved impossible to overcome as they are deeply rooted in its architecture. We also mentioned in our update on our foundational work that MkDocs must be considered a supply chain risk, since it's unmaintained since August 2024. It has seen no releases in over a year and is accumulating unresolved issues and pull requests. These developments have forced us to cut our ties to MkDocs as a dependency.",
    "These developments have forced us to cut our ties to MkDocs as a dependency. In order to map out a path forward, we went back to the drawing board, talked to dozens of our professional users and thoroughly analyzed the MkDocs ecosystem. We didn't just want to create a fork or port of MkDocs, but decided to rethink static site generation from first principles. With Zensical, we are creating a modern static site generator, which is compatible with your content and customizations, and addresses MkDocs' limitations. While Material for MkDocs is built on top of MkDocs, Zensical consolidates both projects into one coherent stack, covering static site generation, theming, and customization. What you can expect today:\nAlthough we haven't reached full feature parity yet, you can already use Zensical to build your existing Material for MkDocs projects with minimal changes. You can jump to the compatibility section to learn what is already supported. What you can expect\u00b6\nSolid foundation\u00b6",
    "What you can expect\u00b6\nSolid foundation\u00b6 You can jump to the compatibility section to learn what is already supported. What you can expect\u00b6\nSolid foundation\u00b6\nOur goal with Zensical is to create a coherent and modern stack, vertically integrating all parts of the authoring experience (AX), developer experience (DX), and user experience (UX). This gives us a significant competitive advantage over solutions that overly rely on third-party frameworks and dependencies, helping us to create much more robust Open Source software. ZRX, our new differential build engine, creates a solid foundation for Zensical, and is an Open Source project of its own. It's a fresh take on making differential data flows easy to build and a joy to work with. Most engineering effort has gone into ZRX, as it forms the backbone of Zensical, and will allow us to ship features faster.",
    "Most engineering effort has gone into ZRX, as it forms the backbone of Zensical, and will allow us to ship features faster. Following the principle of architectural hoisting, we moved essential, reusable functionality into ZRX, which allows us to keep Zensical's core simple and focused on static site generation. ZRX handles the heavy lifting \u2013 differential builds, caching, and data flow orchestration. With the upcoming module system and component system, both of which are on our public roadmap, Zensical will gain more degrees of freedom in the coming months, allowing you to extend and customize Zensical in ways that were previously impossible with MkDocs. Modern design\u00b6\nZensical brings a fresh, modern design that breaks out of the Materal Design aesthetic, creating a visual foundation that is more easily brandable and adaptable to different use cases. The new design prioritizes clarity, simplicity, and usability, while having a more professional finish:",
    "The new design prioritizes clarity, simplicity, and usability, while having a more professional finish: Right now, the layout and site structure of Zensical match Material for MkDocs closely, as we're focusing on ensuring maximum compatibility. Once we finish work on our upcoming component system, we'll provide an alternative that is much more flexible and adaptable, and can be tailored to different use cases and branding requirements more easily. You can also keep the Material for MkDocs look and feel with a single line of configuration. Blazing-fast search\u00b6\nClient-side search isn't a compromise \u2013 for the vast majority of static sites, it's the best solution, since it's faster, involves zero maintenance, and doesn't require you to pay for a service. As covered in depth in the first part of this series, the current search implementation in Material for MkDocs has severe limitations, and is based on a now unmaintained library, which is why we decided to build a new search engine from scratch. It's based on the same goals as Zensical itself: performance, flexibility, and extensibility.",
    "It's based on the same goals as Zensical itself: performance, flexibility, and extensibility. Disco, our modular and blazing-fast client-side search engine, is exclusively available in Zensical. When you build your site with Zensical, your users will immediately benefit from Disco's improved ranking algorithm, as well as its filtering and aggregation capabilities:\nIn early 2026, we'll be releasing Disco as a standalone Open Source project. With the feedback of our professional users in Zensical Spark, we're going to evolve the search experience, turning Disco into a highly configurable and customizable search engine that adapts to your needs. You can subscribe to our newsletter to receive news about Disco. Authoring experience\u00b6\nSlow feedback loops can be a major pain point when writing documentation. Almost all of us know the feeling of waiting for the static site generator to finish building the site, just to see a small change reflected in the output. With Zensical, we're finally addressing this issue.",
    "With Zensical, we're finally addressing this issue. It's important to understand that we're not yet utilizing the differential capabilities of ZRX to the fullest extent, as we're forced to make several compromises to ensure maximum compatibility with Material for MkDocs at the moment. Markdown rendering needs to go through Python Markdown, which forces us to pay for extra marshalling costs. While the initial build can sometimes be slower than with MkDocs, repeated builds \u2013 especially when serving the site \u2013 are already 4 to 5x faster, as only changed files need to be rebuilt. We're also working on a new Markdown toolchain based on a CommonMark-compliant parser written in Rust, which will make Markdown processing significantly faster. We'll be tackling this as part of the upcoming component system, which we'll start working on in early 2026. Once our new Markdown toolchain is ready, we'll provide automated tools to translate between Python Markdown and CommonMark, so you don't need to manually migrate your content.",
    "Once our new Markdown toolchain is ready, we'll provide automated tools to translate between Python Markdown and CommonMark, so you don't need to manually migrate your content. Maximum compatibility\u00b6\nCompatibility with Material for MkDocs is our top priority. We understand that switching to a new static site generator can be challenging, especially for large projects with many customizations. Therefore, we've put significant effort into ensuring that Zensical understands mkdocs.yml\nconfiguration files, so that you can build your projects with minimal changes. This means your existing Markdown files, template overrides, CSS and JavaScript extensions don't need to be touched, primarily because we did not change the generated HTML, and rely on Python Markdown for processing your content. However, plugins are a different story. In MkDocs, practically all plugins have side effects, making it impossible to parallelize builds. We started from first principles and asked: what should extensibility look like in a modern static site generator? Our answer is the upcoming module system, which takes a fundamentally different approach based on four core principles:",
    "Our answer is the upcoming module system, which takes a fundamentally different approach based on four core principles: - Modules can inject, extend, and re-define functionality\n- Modules are deterministic through topological ordering\n- Modules foster reusability, with the possibility to remix them\n- Modules can cooperate through well-defined contracts\nWe're working on shipping essential functionality as provided by MkDocs plugins as built-in modules. In early 2026, we will open the module system to third-party developers, so they can start building their own modules, as we see Zensical as the heart of a thriving ecosystem. Zensical Spark\u00b6\nZensical Spark, our offering for professionals, is the result of countless calls with professional users of Material for MkDocs. From startups to large enterprises, we enable organizations to realize complex projects in diverse environments. For this, we've created Zensical Spark as a collaborative space. If you're a professional user, Zensical Spark is for you, since:\n-",
    "If you're a professional user, Zensical Spark is for you, since:\n- -\nYou can be confident that Zensical will continue to be developed and maintained in the long term as a set of interconnected and sustainable OSI-compliant Open Source projects. -\nYou can receive the support you need to successfully use, configure and customize Zensical in your organization, receiving first-class support from the Zensical team. -\nYou can influence the future development of Zensical by participating in our new approach to Open Source software development, helping us to build exactly what you need. Let's talk! If you're working in a professional context, reach out to contact@zensical.org to schedule a call and learn how Zensical Spark enables your team to transition to Zensical smoothly and have a voice in its continued development. You should also consider joining the waiting list, since seats are limited. We're growing our team\u00b6\nWe're also excited to announce that we're growing our team:\nTimoth\u00e9e Mazzucotelli, also known as @pawamoy, is joining Zensical!",
    "We're growing our team\u00b6\nWe're also excited to announce that we're growing our team:\nTimoth\u00e9e Mazzucotelli, also known as @pawamoy, is joining Zensical! We're growing our team\u00b6\nWe're also excited to announce that we're growing our team:\nTimoth\u00e9e Mazzucotelli, also known as @pawamoy, is joining Zensical! At Zensical, Tim is focusing on providing the same seamless experience for generating API reference documentation from source code (via docstrings) as he has done with mkdocstrings, the second biggest project in the MkDocs ecosystem. With his expertise, and Zensical's new stack, we'll be pushing the boundaries of what's possible with API reference documentation. Goodbye, GitHub Sponsors\u00b6\nThank you! To all of you who have supported us over the years through GitHub Sponsors \u2013 we are incredibly grateful for your support. It has been invaluable in helping us to build, maintain and evolve Material for MkDocs, and we couldn't have done it without you. Seriously, thank you!",
    "Seriously, thank you! Material for MkDocs gave us something invaluable: experience building for tens of thousands of users, and the opportunity to build a team around Open Source software. It showed us that making a living from Open Source isn't just possible \u2013 we grew it into one of the largest sponsorware projects on GitHub and inspired others to pursue similar paths. Now we're breaking new ground. Zensical is our next chapter, and we're professionalizing how we approach Open Source development. Our vision is to make Zensical free for everyone to use while building a sustainable business around it through our new approach. This transition means saying goodbye to GitHub Sponsors. It has served us exceptionally well, but as we professionalize and scale, we're making the leap from personal project to company \u2013 building a business and team that can meet the growing demands of professional users while staying true to our values. We're doubling down on Open Source, developing software for everyone.",
    "We're doubling down on Open Source, developing software for everyone. We're doubling down on Open Source, developing software for everyone. If you want to continue supporting our work, please subscribe to our newsletter. We'll be providing new methods to support us in the coming months, with the possibility of getting exclusive goodies. Looking Ahead\u00b6\nMaterial for MkDocs grew organically in a pot that eventually became too small. With Zensical, we're building on solid foundations designed to grow with us \u2013 and with you. Material for MkDocs is now in maintenance mode\nWe want to be transparent about the risks of staying on Material for MkDocs. With MkDocs unmaintained and facing fundamental supply chain concerns, we cannot guarantee Material for MkDocs will continue working reliably in the future. We're aware that transitioning takes time, which is why we commit to support it at least for the next 12 months, fixing critical bugs and security vulnerabilities as needed, but the path forward is with Zensical.",
    "We're aware that transitioning takes time, which is why we commit to support it at least for the next 12 months, fixing critical bugs and security vulnerabilities as needed, but the path forward is with Zensical. If documentation plays a critical role in your organization, and you're worried how this might affect your business, consider joining Zensical Spark, or feel free to schedule a call by reaching out at contact@zensical.org. Where we'll be in 12 months\u00b6\nOver the next 12 months, following our phased transition strategy, we'll reach Phase 2 and 3 \u2013 introducing our module system and component system, as well as CommonMark support. By replacing Python Markdown with a Rust-based Markdown parser, we'll unlock performance improvements and the modularity needed for flexible templating. This is where Zensical truly starts to unfold its capabilities. Zensical is already powering real projects due to extensive compatibility with Material for MkDocs. We're actively working on closing the gap to reach full feature parity. You can install Zensical now, and build your existing Material for MkDocs projects with it. If you run into a bug, please don't hesitate to open an issue \u2013 we're here to help.",
    "If you run into a bug, please don't hesitate to open an issue \u2013 we're here to help. You can install Zensical now, and build your existing Material for MkDocs projects with it. If you run into a bug, please don't hesitate to open an issue \u2013 we're here to help. Connect with us\u00b6\nIf you have questions we haven't addressed, please reach out to us at contact@zensical.org. We're currently collecting questions from the community about Zensical, and will address them in an FAQ section as part of our documentation in the coming weeks. We're incredibly thankful that you have been part of our journey so far. With Zensical, we're embarking on a new chapter, and we couldn't be more excited to have you with us. You can subscribe to our newsletter to stay in the loop.",
    "The Manuscripts of Edsger W. Dijkstra",
    "The Manuscripts of Edsger W. Dijkstra Home\nNumerical EWD Index: 00xx 01xx 02xx 03xx 04xx 05xx 06xx 07xx 08xx 09xx 10xx 11xx 12xx 13xx\nBibTeX index\nMC Reports\nOther documents\nTranscriptions\nVideo and Audio\nExternal links\nIn addition, Dijkstra was intensely interested in teaching, and in the relationships between academic computing science and the software industry. During his forty-plus years as a computing scientist, which included positions in both academia and industry, Dijkstra\u2019s contributions brought him many prizes and awards, including computing science\u2019s highest honor, the ACM Turing Award.",
    "During his forty-plus years as a computing scientist, which included positions in both academia and industry, Dijkstra\u2019s contributions brought him many prizes and awards, including computing science\u2019s highest honor, the ACM Turing Award. Like most of us, Dijkstra always believed it a scientist\u2019s duty to maintain a lively correspondence with his scientific colleagues. To a greater extent than most of us, he put that conviction into practice. For over four decades, he mailed copies of his consecutively numbered technical notes, trip reports, insightful observations, and pungent commentaries, known collectively as \u201cEWDs\u201d, to several dozen recipients in academia and industry. Thanks to the ubiquity of the photocopier and the wide interest in Dijkstra\u2019s writings, the informal circulation of many of the EWDs eventually reached into the thousands.",
    "Thanks to the ubiquity of the photocopier and the wide interest in Dijkstra\u2019s writings, the informal circulation of many of the EWDs eventually reached into the thousands. Although most of Dijkstra\u2019s publications began life as EWD manuscripts, the great majority of his manuscripts remain unpublished. They have been inaccessible to many potential readers, and those who have received copies have been unable to cite them in their own work. To alleviate both of these problems, the department has collected over a thousand of the manuscripts in this permanent web site, in the form of PDF bitmap documents (to read them, you\u2019ll need a copy of Acrobat Reader). We hope you will find it convenient, useful, inspiring, and enjoyable. The original manuscripts, along with diaries, correspondence, photographs, and other papers, are housed at The Center for American History of The University of Texas at Austin. Each manuscript file is accessible through either of two indexes:\n0. BibTeX index. Each entry includes all the available bibliographic data. 1. Ad-hoc indexes. These contain titles only, but are faster if you know what you\u2019re looking for.",
    "These contain titles only, but are faster if you know what you\u2019re looking for. 0. BibTeX index. Each entry includes all the available bibliographic data. 1. Ad-hoc indexes. These contain titles only, but are faster if you know what you\u2019re looking for. EWD-numbered documents (This index gives an approximate correspondence between manuscripts\u2019 EWD numbers and the year in which they appeared.) Technical reports from the Mathematical Centre (now CWI: Centrum voor Wiskunde en Informatica) PhD thesis (5.3 MB) Other documents\nEWD-numbered documents (This index gives an approximate correspondence between manuscripts\u2019 EWD numbers and the year in which they appeared.) Technical reports from the Mathematical Centre (now CWI: Centrum voor Wiskunde en Informatica)\nPhD thesis (5.3 MB)\nYou can find a table relating EWD numbers to publication years here. Many of the privately circulated manuscripts collected here were subsequently published; their copyrights are held by their respective publishers.",
    "Many of the privately circulated manuscripts collected here were subsequently published; their copyrights are held by their respective publishers. Many of the privately circulated manuscripts collected here were subsequently published; their copyrights are held by their respective publishers. A growing number of the PDF bitmap documents have been transcribed to make them searchable and accessible to visitors who are visually impaired. A few of the manuscripts written in Dutch have been translated into English, and one \u2014EWD1036\u2014 has been translated into Spanish. EWD28 has been translated from English into Russian. For these transcriptions and translations we are grateful to over sixty contributors. Volunteers willing to transcribe manuscripts are always welcome (Note: doing EWDs justice in translation has turned out to be too difficult, so we are no longer soliciting translations).",
    "Volunteers willing to transcribe manuscripts are always welcome (Note: doing EWDs justice in translation has turned out to be too difficult, so we are no longer soliciting translations). Proofreading Each transcription gets a cursory scan as it\u2019s prepared for uploading, but since a web page can always be updated, I don\u2019t strive for (unattainable) perfection before installing it. On the web, proofreading is a game that can be played by every reader; if you spot an error, please\nA compilation of cross-references has been contributed by Diethard Michaelis. As its author notes, the collection is incomplete, and all readers are invited to add to it. Dijkstra often returned to topics about which he had already written, when he had something new to say or even just a better way of saying it. When Dijkstra himself didn\u2019t provide the backward references, we indicate the relationship by \"see also\" links in the index, leaving the judgment of the extent to which the earlier EWD is superseded by the later one to the reader. Any reader who notices such a relationship is invited to",
    "Any reader who notices such a relationship is invited to We have begun adding summaries of the EWDs. This innovation was suggested by G\u00fcnter Rote, who contributed the first dozen summaries. Additional contributions of summaries\u2014especially summaries in English of EWDs in Dutch\u2014are most welcome. Copyrights in most EWDs are held by his children, one of whom \u2014 \u2014 handles requests for permission to publish reproductions. The exceptions are documents that were published, and whose copyrights are held by their publishers; those documents are listed here, and each one is provided with a cover page identifying the copyright holder. Because the original manuscripts are in possession of the Briscoe Center for American History at The University of Texas, the Center\u2019s policies are also applicable. In addition to the manuscripts, you may enjoy some recordings of Dijkstra lectures and interviews.",
    "In addition to the manuscripts, you may enjoy some recordings of Dijkstra lectures and interviews. In addition to the manuscripts, you may enjoy some recordings of Dijkstra lectures and interviews. An interview with Dijkstra (Spanish translation here) was conducted in 1985 by Rogier F. van Vlissingen, who has also written a personal reflection on \u201cDijkstra\u2019s sense of what computer science and programming are and what they aren\u2019t.\u201d\nAnother interview was conducted by Philip L. Frana in August 2001. A transcript is available in the on-line collection of the Charles Babbage Institute.",
    "A transcript is available in the on-line collection of the Charles Babbage Institute. Another interview was conducted by Philip L. Frana in August 2001. A transcript is available in the on-line collection of the Charles Babbage Institute. To mark the occasion of Dijkstra\u2019s retirement in November 1999 from the Schlumberger Centennial Chair in Computer Sciences, which he had occupied since 1984, and to celebrate his forty-plus years of seminal contributions to computing science, the Department of Computer Sciences organized a symposium, In Pursuit of Simplicity, which took place on his birthday in May 2000. The symposium\u2019s program (10 MB) contains an outline of Dijkstra\u2019s career, as well as a collection of quotes culled from his writings, from his blackboard, and from what others have said about him. Banquet speeches by David Gries, Fred Schneider, Krzysztof Apt, W.M. Turski, and H. Richards were recorded on a video. Dijkstra\u2019s death in August 2002 was marked by many obituaries and memorials, including the Computer Sciences department\u2019s memorial celebration.",
    "Dijkstra\u2019s death in August 2002 was marked by many obituaries and memorials, including the Computer Sciences department\u2019s memorial celebration. Dijkstra\u2019s death in August 2002 was marked by many obituaries and memorials, including the Computer Sciences department\u2019s memorial celebration. A remembrance of Dijkstra was posted in May 2008 by Maarten van Emden (thanks to Tristram Brelstaff for noting it). In 2021 Krzysztof R. Apt and Tony Hoare edited a commemoration of Edsger Dijkstra written by more than twenty computer scientists who knew him as a colleague, teacher, and friend. A blog devoted to Dijkstra\u2019s works and thoughts has been created, and is being maintained, by the historian of computing Edgar G. Daylight. An article by Daylight, \u201cDijkstra\u2019s Rallying Cry for Generalization: the Advent of the Recursive Procedure, late 1950s - early 1960s,\u201d appeared in The Computer Journal, March 2011.",
    "An article by Daylight, \u201cDijkstra\u2019s Rallying Cry for Generalization: the Advent of the Recursive Procedure, late 1950s - early 1960s,\u201d appeared in The Computer Journal, March 2011. In his blog A Programmer\u2019s Place, Maarten van Emden has an entry entitled \u201cAnother scoop by Dijkstra?\u201d. The entry describes Dijkstra\u2019s \u201cremarkable insight [in \u201cNotes on Structured Programming\u201d (EWD 249)] that resolves the stand-off between the Sieve of Eratosthenes (efficient in terms of time, but not memory) and the method of Trial Division (efficient in terms of memory, but not time)\u201d by applying the Assembly-line Principle. The Edsger W. Dijkstra Prize in Distributed Computing honors Dijkstra\u2019s \u201cfoundational work on concurrency primitives (such as the semaphore), concurrency problems (such as mutual exclusion and deadlock), reasoning about concurrent systems, and self-stabilization [, which] comprises one of the most important supports upon which the field of distributed computing is built.\u201d\nA series of annual lectures in memory of Dijkstra commenced at The University of Texas in October 2010.",
    "The Edsger W. Dijkstra Prize in Distributed Computing honors Dijkstra\u2019s \u201cfoundational work on concurrency primitives (such as the semaphore), concurrency problems (such as mutual exclusion and deadlock), reasoning about concurrent systems, and self-stabilization [, which] comprises one of the most important supports upon which the field of distributed computing is built.\u201d\nA series of annual lectures in memory of Dijkstra commenced at The University of Texas in October 2010. A series of annual lectures in memory of Dijkstra commenced at The University of Texas in October 2010. Recent significant changes in the site are listed here; the most recent change was posted on 30 March 2021. The folks who contributed most significantly to the site\u2019s creation are acknowledged here. Comments and suggestions about the site are always welcome; please email them to the\nIf you find this site interesting, you may also be interested in another site:\nDiscipline in Thought which is a website dedicated to disciplined thinking, calculational mathematics, and mathematical methodology. The members of this site are markedly influenced by the works of EWD, and the material shared through the website continues in the traditions set by EWD (among others). Revised 2020-01-12",
    "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology",
    "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology How I spent two decades tracking down the creators of a 1987 USENET game and learned modern packaging tools in the process. The Discovery: A Digital Time Capsule from 1987\nPicture this: October 26, 1987. The Berlin Wall still stands, the World Wide Web is just text, and software is distributed through USENET newsgroups in text files split across multiple posts. On that day, Edward Barlow posted something special to comp.sources.games\n:\n\u201cconquest \u2013 middle earth multi-player game, Part01/05\u201d\nThat\u2019s how Ed Barlow announced it at the time, before quickly changed the name to Conquer. This was Conquer \u2013 a sophisticated multi-player strategy game that would influence countless others. Players controlled nations in Middle Earth, managing resources, armies, magic systems, and diplomatic relations. What made it remarkable wasn\u2019t just the gameplay, but how it was built and distributed in an era when \u201copen source\u201d wasn\u2019t even a term yet. Chapter 0: University Days.",
    "Chapter 0: University Days. Chapter 0: University Days. It was during these days, in the middle of the 90s, that my fellow students and I spent hours experimenting with terminals in the Computer Unix Labs, USENET, links, news, msgs, and of course: conquer. That game was a gem that required to be the leader of a country, and with a map representing as characters each player could control their elven kingdom, orcish empire, or human armies to fight each other while controlling all the details of the economy. But by 2006, this piece of computing history was trapped in legal limbo. Chapter 1: The Quest Begins (2006)\nAs a university student in Spain in the early \u201990s, I\u2019d encountered Conquer in the Unix labs. Fast forward to 2006, and I realized this pioneering game was at risk of being lost forever. The source code existed, scattered across ancient USENET archives, but its licensing was unclear \u2013 typical of the \u201cpost it and see what happens\u201d era of early internet software distribution.",
    "The source code existed, scattered across ancient USENET archives, but its licensing was unclear \u2013 typical of the \u201cpost it and see what happens\u201d era of early internet software distribution. I started what I thought would be a simple project: get permission from the original authors to relicense the code under GPL so it could be properly preserved and packaged for modern Linux distributions. Simple, right? Chapter 2: Digital Detective Work\nFinding Edward Barlow and Adam Bryant in 2006 was like archaeological work. Email addresses from the 1980s were long dead. USENET posts provided few clues. I scoured old university directories, googled fragments of names, and followed digital breadcrumbs across decades-old forums. The breakthrough came through pure persistence and a bit of luck. After months of searching, I managed to contact Ed Barlow. His response was refreshingly casual: \u201cYes i delegated it all to adam aeons ago. Im easy on it all\u2026. copyleft didnt exist when i wrote it and it was all for fun so\u2026\u201d\nBut there was a catch \u2013 I needed permission from Adam Bryant too, and he seemed to have vanished into the digital ether. Chapter 3: The Long Wait (2006-2011)",
    "Chapter 3: The Long Wait (2006-2011) But there was a catch \u2013 I needed permission from Adam Bryant too, and he seemed to have vanished into the digital ether. Chapter 3: The Long Wait (2006-2011)\nI documented everything on the Debian Legal mailing lists, created a GNU Savannah task (#5945), and even wrote blog posts hoping Adam would find them. The legal experts were clear: I needed explicit written permission from both copyright holders. Years passed. The project stalled. Then, on February 23, 2011, something magical happened. My phone buzzed with a contact form submission:\n\u201cI heard news of the request to release the code. I grant permission to release the code under GPL.\u201d \u2013 Adam Bryant\nHe had found one of my articles online and reached out on his own. Chapter 4: The Plot Twist \u2013 Version 5 Emerges (2025)",
    "Chapter 4: The Plot Twist \u2013 Version 5 Emerges (2025) He had found one of my articles online and reached out on his own. Chapter 4: The Plot Twist \u2013 Version 5 Emerges (2025)\nFast forward to 2025, and Stephen Smoogen contacts me about my relicesing efforts in 2006 and how he was particularly interested in reviving: Conquer Version 5 \u2013 a complete rewrite by Adam with advanced features like automatic data conversion, enhanced stability, and sophisticated administrative tools. This wasn\u2019t just an update; it was a complete reimagining of the game. But V5 had a different legal history. In the \u201990s, there had been commercial arrangements. Would Adam agree to GPL this version too? His response: \u201cI have no issues with applying a new GPL license to Version 5 as well.\u201d\nChapter 5: The Missing Piece \u2013 PostScript Magic",
    "His response: \u201cI have no issues with applying a new GPL license to Version 5 as well.\u201d\nChapter 5: The Missing Piece \u2013 PostScript Magic His response: \u201cI have no issues with applying a new GPL license to Version 5 as well.\u201d\nChapter 5: The Missing Piece \u2013 PostScript Magic\nJust when I thought the story was complete, I discovered another contributor: MaF, who had created PostScript utilities for generating printable game maps \u2013 a crucial feature in the pre-GUI era when players needed physical printouts to strategize. Tracking down MaF in 2025 led me to his company, where he\u2019s now Director of Product Security. His response: \u201cOh, that was a long time ago. But yes, that was me. And I have no problem with relicensing it to GPL.\u201d\nRichard Caley: More Than Just a Legal Footnote\nBut not all searches end with an answer. Some end with silence. My investigation of Richard Caley followed the same digital breadcrumbs. I traced him to the University of Edinburgh, where he worked on speech synthesis. I found his technical contributions to FreeBSD. But the trail went cold around 2005.",
    "But the trail went cold around 2005. Then I found him \u2013 not in a USENET archive, but on the front page of his own website, preserved exactly as he left it in web.archive.org. \u201cRichard Caley suffered a fatal heart attack on the 22nd of April, 2005. He was only 41, but had been an undiagnosed diabetic, probably for some considerable time. His web pages remain as he left them.\u201d\nReading those words felt different from finding a historical record. This wasn\u2019t archival research \u2013 this was walking into someone\u2019s house years after they\u2019d gone and finding a note on the table. The page continued:\n\u201cOver and above his tremendous ability with computers and programming, Richard had a keen mind and knowledge of an extraordinary range of topics, both of which he used in frequent contributions to on-line discussions. Despite his unique approach to speling, his prolific contributions to various news group debates informed and amused many over the years.\u201d\nThe \u201cCaleyisms\u201d \u2013 The Man Behind the Code",
    "Despite his unique approach to speling, his prolific contributions to various news group debates informed and amused many over the years.\u201d\nThe \u201cCaleyisms\u201d \u2013 The Man Behind the Code The \u201cCaleyisms\u201d \u2013 The Man Behind the Code\nAnd then I discovered his \u201cCaleyisms\u201d \u2013 a curated collection of his most brilliant USENET responses that revealed not just a programmer, but a person:\nWhat\u2019s a shell suit? \u201cOil company executive.\u201d\nHow do you prepare for a pyroclastic flow hitting Edinburgh? \u201cHang 1000 battered Mars bars on strings and stand back?\u201d\nOn his book addiction:\n\u201cI never got the hang of libraries, they keep wanting the things back and get upset when they need a crowbar to force it out of my hands.\u201d\nHis humor was dry, intelligent, and uniquely British. In technical discussions, he could be brutally precise:\n\u201cLack of proper punctuation, spacing, line breaks, capitalisation etc. is like bad handwriting, it doesn\u2019t make it impossible to read what was written, just harder. But you probably write in green crayon anyway.\u201d\nA Digital Office Preserved",
    "But you probably write in green crayon anyway.\u201d\nA Digital Office Preserved A Digital Office Preserved\nExploring his preserved website felt like walking through his digital office. The directory structure revealed his passions: FreeBSD how-tos, POVRAY experiments, wallpaper images, technical projects. His self-deprecating humor shone through in his \u201cAbout\u201d section:\n\u201cThankfully I don\u2019t have a photograph to inflict on you. Just use the picture of Iman Bowie to the left and then imagine someone who looks exactly the opposite in every possible way. This probably explains why she is married to David Bowie and I\u2019m not.\u201d\nHere was a complete person \u2013 technical director at Interactive Information Ltd, speech synthesis researcher, FreeBSD enthusiast, Kate Bush fan, and a wit who brightened countless online discussions. The legal reality was harsh: Richard\u2019s contributions to Conquer couldn\u2019t be relicensed. The university couldn\u2019t help contact heirs due to privacy laws. His friends had preserved his memory with a simple ASCII tribute at the end of his page:\n^_^\n(O O)",
    "His friends had preserved his memory with a simple ASCII tribute at the end of his page:\n^_^\n(O O) His friends had preserved his memory with a simple ASCII tribute at the end of his page:\n^_^\n(O O)\n\\_/@@\\\n\\\\~~/\n~~\n- RJC RIP\nIn the Conquer project documentation, Richard Caley isn\u2019t remembered as a \u201cproblem case\u201d or \u201cunlicensable code.\u201d He\u2019s honored as the vibrant person he was \u2013 the brilliant mind behind the \u201cCaleyisms,\u201d the researcher who contributed to speech synthesis, the FreeBSD advocate, and the witty participant in early online communities whose words continue to amuse and inform, decades after he wrote them. Chapter 6: Modern Renaissance \u2013 Enter GitHub, CICD and Modern Distributions\nHere\u2019s where the story gets really interesting. While working on preserving these Unix classics, I decided to learn modern packaging techniques. I chose to implement both APK (Alpine Linux) and Debian packaging for the games.",
    "I chose to implement both APK (Alpine Linux) and Debian packaging for the games. For APK packages, I used Melange \u2013 a sophisticated build system that creates provenance-tracked, reproducible packages for the Wolfi \u201cundistro\u201d. The irony? I discovered this tool when some friend started to work for the company that created it. Chapter 7: The Technical Journey: From USENET to Modern CI/CD\nThe transformation has been remarkable:\n1987 Original:\n- Distributed as split USENET posts\n- Manual compilation with system-specific Makefiles\n- No version control or automated testing\n2025 Revival:\n# Modern CI/CD with GitHub Actions\n- name: Build APK package\nrun: melange build conquer.yaml\n- name: Build Debian package\nrun: dpkg-buildpackage -b\nKey Modern Additions:\n- GPLv3 relicensing\n- Make building system modernization\n- C Codebase partially updated to support modern ANSI C99 specification\n- Debian packaging\n- APK packaging with Melange\nYou can see the complete transformation in the repositories:\n- Conquer v4 \u2013 The original classic\n- Conquer v5 \u2013 The advanced rewrite",
    "Chapter 7: The Technical Journey: From USENET to Modern CI/CD\nThe transformation has been remarkable:\n1987 Original:\n- Distributed as split USENET posts\n- Manual compilation with system-specific Makefiles\n- No version control or automated testing\n2025 Revival:\n# Modern CI/CD with GitHub Actions\n- name: Build APK package\nrun: melange build conquer.yaml\n- name: Build Debian package\nrun: dpkg-buildpackage -b\nKey Modern Additions:\n- GPLv3 relicensing\n- Make building system modernization\n- C Codebase partially updated to support modern ANSI C99 specification\n- Debian packaging\n- APK packaging with Melange\nYou can see the complete transformation in the repositories:\n- Conquer v4 \u2013 The original classic\n- Conquer v5 \u2013 The advanced rewrite - Debian packaging\n- APK packaging with Melange\nYou can see the complete transformation in the repositories:\n- Conquer v4 \u2013 The original classic\n- Conquer v5 \u2013 The advanced rewrite\nOriginal Conquer v4 code, by Ed Barlow and Adam Bryant\n(Conquer running in docker container alongside Apache, Curses to WebSockets output thanks to ttyd. Now we can play through the web!) Conquer Version 5 \u2013 The evolution of the classical Conquer, by Adam Bryant\nChapter 8: The Human Element: Why This Matters\nThis isn\u2019t just about preserving old games \u2013 it\u2019s about preserving the story of computing itself. Ed Barlow and Adam Bryant were pioneers who built sophisticated multiplayer experiences when most people had never heard of the internet. They distributed software through USENET because that\u2019s what you did \u2013 you shared cool things with the community.",
    "They distributed software through USENET because that\u2019s what you did \u2013 you shared cool things with the community. Martin Forssen\u2019s PostScript utilities represent the ingenuity of early developers who solved problems with whatever tools were available. Want to visualize your game state? Write a PostScript generator! The 20-year relicensing effort demonstrates something crucial about open source: it\u2019s not just about code, it\u2019s about community and continuity. Every time someone maintains a legacy project, documents its history, or tracks down long-lost contributors, they\u2019re weaving the threads that connect computing\u2019s past to its future. Lessons for Modern Developers\n- Document everything: Those casual USENET posts became crucial legal evidence decades later\n- License clearly: Ed\u2019s comment that \u201ccopyleft didnt exist when i wrote it\u201d highlights how licensing landscapes evolve\n- Community matters: Adam found my articles because the community was talking about preservation\n- Technical debt is temporal: What seems like legacy tech today might be tomorrow\u2019s archaeological treasure",
    "Lessons for Modern Developers\n- Document everything: Those casual USENET posts became crucial legal evidence decades later\n- License clearly: Ed\u2019s comment that \u201ccopyleft didnt exist when i wrote it\u201d highlights how licensing landscapes evolve\n- Community matters: Adam found my articles because the community was talking about preservation\n- Technical debt is temporal: What seems like legacy tech today might be tomorrow\u2019s archaeological treasure - Technical debt is temporal: What seems like legacy tech today might be tomorrow\u2019s archaeological treasure\n- Modern tools can revive ancient code: Melange and modern CI/CD gave 1987 software a 2025 renaissance\nThe Continuing Story\nBoth Conquer games are now fully GPL v3 licensed and available with modern packaging. They represent not just playable software, but a complete case study in software archaeology, legal frameworks for preservation, and the evolution of development practices across four decades. The next chapter? Teaching these classic strategy games to a new generation of developers and gamers, while demonstrating that proper legal frameworks and modern tooling can give any historical software a second life. Sometimes the best way to learn cutting-edge technology is by applying it to preserve computing history. What historical software deserves preservation in your field? Have you ever traced the lineage of code back to its original creators?",
    "Have you ever traced the lineage of code back to its original creators? What historical software deserves preservation in your field? Have you ever traced the lineage of code back to its original creators? #FreeSoftware #OpenSource #SoftwarePreservation #Unix #GNU #Linux #Packaging #Melange #TechHistory #GameDevelopment #Unix #USENET #GPL #FST #Debian #ncurses #terminal #shell\nRead this article in Spanish / Lee este art\u00edculo en espa\u00f1ol:\nhttps://vejeta.com/conquer-una-odisea-de-20-anos-en-arqueologia-digital/\nThis article was originally written in both English and Spanish, with additional insights and cultural context in the Spanish version.",
    "Visualize FastAPI endpoints with FastAPI-Voyager\n\nLoading\u2026\nFastAPI Voyager\n{{ state.version }}\nscroll to zoom in/out\ndouble click node to view details. shift + click to see schema's dependencies without unrelated nodes. {{ tag.name }}\n{{ tag.routes.length }}\n{{ route.name }}\nNo routes\n{{ dumpJson }}\nImport core data JSON",
    "Email verification protocol",
    "Email verification protocol Verifying control of an email address is a frequent activity on the web today and is used both to prove the user has provided a valid email address, and as a means of authenticating the user when returning to an application. Verification is performed by either:\n-\nSending the user a link they click on or a verification code. This requires the user to switch from the application they are using to their email address and having to wait for the email arrive, and then perform the verification action. This friction often causes drop off in users completing the task. There are privacy implications as the email transmission informs the mail service the applications the user is using and when they used them. -",
    "- -\nThe user logs in with a social login provider such as Apple or Google that provide a verified email address. This requires the application to have set up a relationship with each social provider, and the user to be using one of those services and wanting to share the additional profile information that is also provided in the OpenID Connect flow. The Email Verification Protocol enables a web application to obtain a verified email address without sending an email, and without the user leaving the web page they are on. To enable the functionality, the mail domain delegates email verification to an issuer that has authentication cookies for the user. When the user provides an email to the HTML form field, the browser calls the issuer passing authentication cookies, the issuer returns a token, which the browser verifies and updates and provides to the web application. The web application then verifies the token and has a verified email address for the user.",
    "The web application then verifies the token and has a verified email address for the user. User privacy is enhanced as the issuer does not learn which web application is making the request as the request is mediated by the browser. -\nSD-JWT+KB token: The selective disclosure json web token with key binding is specified in Selective Disclosure for JWT. This protocol does not use the selective disclosure features, it uses the key binding feature which enables a separation of token issuance and token presentation. The SD-JWT+KB is a token composed of two JWTs separated by the\n~\ncharacter. The first JWT is an SD-JWT aka the issuance token and is signed by the issuer and contains theemail\nandemail_verified\nclaims for the user, and the public key used by the browser to make the request. The second JWT is a KB token and is signed by the browser and contains a hash of the first JWT. The resulting SD-JWT+KB is the presentation token, and enables the application to verify the issuer provided the email address for the user without the issuer learning about the specific application -",
    "The resulting SD-JWT+KB is the presentation token, and enables the application to verify the issuer provided the email address for the user without the issuer learning about the specific application - Issuer: The service that verifies the user controls an email address. A DNS record for the email domain delegates email verification to the issuer. The issuer serves a\n.well-known/email-verification\nmetadata file that contains itsissuance_endpoint\nthat is called to obtain an issuance token, and itsjwks_uri\nthat points to the JWKS file containing the public keys used to verify the SD-JWT. The issuer is identified by its domain, an eTLD+1 (egissuer.example\n). The hostname in all URLs from the issuer's metadata MUST end with the issuer's domain. This identifier is what binds the SD-JWT, the DNS delegation, with the issuer.",
    "This identifier is what binds the SD-JWT, the DNS delegation, with the issuer. ). The hostname in all URLs from the issuer's metadata MUST end with the issuer's domain. This identifier is what binds the SD-JWT, the DNS delegation, with the issuer. Verified Email Release: The user navigates to any website that requires a verified email address and an input field to enter the email address. The user focusses on the input field and the browser provides one or emails for the user to select based on emails the user has provided previously to the browser. The user selects a verified email and the app proceeds having obtained the verified email. Are emails that can be verified decorated by the browser in the autocomplete UI? What UX is presented to the user when the app gets a verified email so the user knows it is already verified? sequenceDiagram\nparticipant U as User\nparticipant B as Browser\nparticipant RP as RP Page\nparticipant RPS as RP Server\nparticipant I as Issuer\nparticipant DNS as DNS\nNote over U,DNS: Step 1: Email Request\nU->>RP: Navigate to site",
    "sequenceDiagram\nparticipant U as User\nparticipant B as Browser\nparticipant RP as RP Page\nparticipant RPS as RP Server\nparticipant I as Issuer\nparticipant DNS as DNS\nNote over U,DNS: Step 1: Email Request\nU->>RP: Navigate to site participant B as Browser\nparticipant RP as RP Page\nparticipant RPS as RP Server\nparticipant I as Issuer\nparticipant DNS as DNS\nNote over U,DNS: Step 1: Email Request\nU->>RP: Navigate to site\nRP->>RPS: Nonce request\nRPS->>RPS: Generate nonce, bind to session\nRPS->>RP: Nonce\nRP->>B: Display page\nNote over U,DNS: Step 2: Email Selection\nU->>RP: Focus on email input field\nRP->>B: Input field focused\nB->>U: Display email address list\nU->>B: Select email address\nNote over U,DNS: Step 3: Token Request\nB->>DNS: DNS TXT lookup<br/>_email-verification.$EMAIL_DOMAIN\nDNS->>B: Return iss=issuer.example\nB->>I: GET /.well-known/email-verification\nI->>B: Return metadata\nB->>B: Generate key pair<br/>Create request token\nB->>I: POST request_token=JWT... Note over U,DNS: Step 4: Token Issuance\nI->>I: Verify request\nI->>I: Generate SD-JWT\nI->>B: {\"issuance_token\":\"SD-JWT\"}\nNote over U,DNS: Step 5: Token Presentation\nB->>B: Verify SD-JWT\nB->>I: GET jwks_uri for public keys\nI->>B: Return JWKS",
    "Note over U,DNS: Step 4: Token Issuance\nI->>I: Verify request\nI->>I: Generate SD-JWT\nI->>B: {\"issuance_token\":\"SD-JWT\"}\nNote over U,DNS: Step 5: Token Presentation\nB->>B: Verify SD-JWT\nB->>I: GET jwks_uri for public keys\nI->>B: Return JWKS I->>I: Verify request\nI->>I: Generate SD-JWT\nI->>B: {\"issuance_token\":\"SD-JWT\"}\nNote over U,DNS: Step 5: Token Presentation\nB->>B: Verify SD-JWT\nB->>I: GET jwks_uri for public keys\nI->>B: Return JWKS\nB->>B: Create KB\nB->>RP: Provide SD-JWT+KB\nNote over U,DNS: Step 6: Token Verification\nRP->>RPS: Send SD-JWT+KB\nRPS->>RPS: Parse SD-JWT+KB\nRPS->>DNS: DNS TXT lookup for email domain\nDNS->>RPS: Return iss=issuer.example\nRPS->>I: GET /.well-known/email-verification\nI->>RPS: Return metadata with jwks_uri\nRPS->>I: GET jwks_uri\nI->>RPS: Return JWKS public keys\nRPS->>RPS: Verify SD-JWT\nRPS->>RPS: Verify KB-JWT\nRPS->>RP: Email verification complete\nUser navigates to a site that will act as the RP. -\n1.1 - the RP Server generates a nonce and binds the nonce to the session. -\n1.2 - the RP Server returns a page that has an input field with the\nautocomplete\nproperty set to\"email\"\nand thenonce\nproperty set the the nonce. If the browser receives anissuance_token",
    "If the browser receives anissuance_token -\n1.2 - the RP Server returns a page that has an input field with the\nautocomplete\nproperty set to\"email\"\nand thenonce\nproperty set the the nonce. If the browser receives anissuance_token\nper 4.4 below, then it sends aemailverifed\nevent that has apresentationToken\nproperty. Following is an example of the HTML in the page:\n<input id=\"email\"\ntype=\"email\"\nautocomplete=\"email\"\nnonce=\"12345677890..random\">\n<script>\nconst input = document.getElementById('email')\ninput.addEventListener('emailverified', e => {\n// e.presentationToken is SD-JWT+KB\nconsole.log({\npresentationToken: e.presentationToken\n})\n})\n</script>\nAuthors are exploring alternative HTML and JS API approaches\n-\n2.1 - User focusses on email input field\n-\n2.2 - The browser displays the list of email addresses it has for the user. Q: Are emails that could be verified decorated for user to understand? - 2.3 - User selects an email address from browser selection, or the user types an email into the field.",
    "- 2.3 - User selects an email address from browser selection, or the user types an email into the field. Q: Are emails that could be verified decorated for user to understand? - 2.3 - User selects an email address from browser selection, or the user types an email into the field. Future: allow user to type in a field so we learn about new emails, or if the user does not want the browser to remember emails, the Email Verification Protocol is still available. In the future when we allow the user to use a passkey to authenticate to the issuer, the user can provide a verified email to a web application using a public computer by authenticating with their passkey and not enter any secrets into the public computer. If the RP has performed (1):\n- 3.1 - the browser parses the email domain ($EMAIL_DOMAIN) from the email address, looks up the\nTXT\nrecord for_email-verification.$EMAIL_DOMAIN\n. The contents of the record MUST start withiss=\nfollowed by the issuer identifier. There MUST be only oneTXT\nrecord for_email-verification.$EMAIL_DOMAIN\n. example record",
    "example record . The contents of the record MUST start withiss=\nfollowed by the issuer identifier. There MUST be only oneTXT\nrecord for_email-verification.$EMAIL_DOMAIN\n. example record\n_email-verification.email-domain.example TXT iss=issuer.example\nThis record states that email-domain.example\nhas delegated email verification to the issuer issuer.example\n. If the email domain and the issuer are the same domain, then the record would be:\n_email-verification.issuer.example TXT iss=issuer.example\nAccess to DNS records and email is often independent of website deployments. This provides assurance that an issuer is truly authorized as an insider with only access to websites on\nissuer.example\ncould setup an issuer that would grant them verified emails for any email atissuer.example\n. - 3.2 - if an issuer is found, the browser loads\nhttps://$ISSUER$/.well-known/email-verification\nand MUST follow redirects to the same path but with a different subdomain of the Issuer.",
    "- 3.2 - if an issuer is found, the browser loads\nhttps://$ISSUER$/.well-known/email-verification\nand MUST follow redirects to the same path but with a different subdomain of the Issuer. . - 3.2 - if an issuer is found, the browser loads\nhttps://$ISSUER$/.well-known/email-verification\nand MUST follow redirects to the same path but with a different subdomain of the Issuer. For example, https://issuer.example/.well-known/email-verification\nmay redirect to https://accounts.issuer.example/.well-known/email-verification\n. -\n3.3 - the browser confirms that the\n.well-known/email-verification\nfile contains JSON that includes the following properties: -\nissuance_endpoint - the API endpoint the browser calls to obtain an SD-JWT\n-\njwks_uri - the URL where the issuer provides its public keys to verify the SD-JWT\n-\nsigning_alg_values_supported - OPTIONAL. JSON array containing a list of the JWS signing algorithms (\"alg\" values) supported by both the browser for request tokens and the issuer for issued tokens. The same algorithm MUST be used for both the\nrequest_token\nandissuance",
    "The same algorithm MUST be used for both the\nrequest_token\nandissuance request_token\nandissuance\nwithin a single issuance flow. Algorithm identifiers MUST be from the IANA \"JSON Web Signature and Encryption Algorithms\" registry. If omitted, \"EdDSA\" is the default. \"EdDSA\" SHOULD be included in the supported algorithms list. The value \"none\" MUST NOT be used. Each of these properties MUST include the issuer domain as the root of their hostname. Following is an example .well-known/email-verification\nfile\n{\n\"issuance_endpoint\": \"https://accounts.issuer.example/email-verification/issuance\",\n\"jwks_uri\": \"https://accounts.issuer.example/email-verification/jwks\",\n\"signing_alg_values_supported\": [\"EdDSA\", \"RS256\"]\n}\n-\n3.4 - the browser generates a fresh private / public key and signs a JWT with the private key that has the public key in the JWT header in the JWK format as a\njwk\nclaim that contains the following claims in the payload:- aud - the issuer\n- iat - time when the JWT was signed\n- jti - unique identifier for the token",
    "Following is an example .well-known/email-verification\nfile\n{\n\"issuance_endpoint\": \"https://accounts.issuer.example/email-verification/issuance\",\n\"jwks_uri\": \"https://accounts.issuer.example/email-verification/jwks\",\n\"signing_alg_values_supported\": [\"EdDSA\", \"RS256\"]\n}\n-\n3.4 - the browser generates a fresh private / public key and signs a JWT with the private key that has the public key in the JWT header in the JWK format as a\njwk\nclaim that contains the following claims in the payload:- aud - the issuer\n- iat - time when the JWT was signed\n- jti - unique identifier for the token jwk\nclaim that contains the following claims in the payload:- aud - the issuer\n- iat - time when the JWT was signed\n- jti - unique identifier for the token\n- email - email address to be verified\nThe browser SHOULD select an algorithm from the issuer's signing_alg_values_supported\narray, or use \"EdDSA\" if the property is not present. An example JWT header:\n{\n\"alg\": \"EdDSA\",\n\"typ\": \"JWT\",\n\"jwk\": {\n\"kty\": \"OKP\",\n\"crv\": \"Ed25519\",\n\"x\": \"11qYAYdk9E6z7mT6rk6j1QnXb6pYq4v9wXb6pYq4v9w\" // base64url-encoded public key\n}\n}\ndo we want to register a new JWT\ntyp\nAn example payload\n{\n\"aud\": \"issuer.example\",\n\"iat\": 1692345600,\n\"email\": \"user@example.com\"\n}\n- 3.5 - the browser POSTs to the\nissuance_endpoint\nof the issuer with 1P cookies with a content-type ofapplication/x-www-form-urlencoded\ncontaining arequest_token\nparameter set to the signed JWT and theSec-Fetch-Dest\nheader set toemail-verification\n. POST /email-verification/issuance HTTP/1.1\nHost: accounts.issuer.example\nCookie: session=...",
    "POST /email-verification/issuance HTTP/1.1\nHost: accounts.issuer.example\nCookie: session=... parameter set to the signed JWT and theSec-Fetch-Dest\nheader set toemail-verification\n. POST /email-verification/issuance HTTP/1.1\nHost: accounts.issuer.example\nCookie: session=...\nContent-Type: application/x-www-form-urlencoded\nSec-Fetch-Dest: email-verification\nrequest_token=eyJhbGciOiJFZERTQSIsInR5cCI6IkpXVC...\nOn receipt of a token request:\n-\n4.1 - the issuer MUST verify the request headers:\nContent-Type\nisapplication/x-www-form-urlencoded\nSec-Fetch-Dest\nisemail-verification\n-\n4.2 - the issuer MUST verify the request_token by:\n- parsing the JWT into header, payload, and signature components\n- confirming the presence of, and extracting the\njwk\nandalg\nfields from the JWT header, and theaud\n,iat\n, andemail\n, claims from the payload - verifying the JWT signature using the\njwk\nwith thealg\nalgorithm - verifying the\naud\nclaim exactly matches the issuer's identifier - verifying the\niat\nclaim is within 60 seconds of the current time - verifying the\nemail",
    "POST /email-verification/issuance HTTP/1.1\nHost: accounts.issuer.example\nCookie: session=...\nContent-Type: application/x-www-form-urlencoded\nSec-Fetch-Dest: email-verification\nrequest_token=eyJhbGciOiJFZERTQSIsInR5cCI6IkpXVC...\nOn receipt of a token request:\n-\n4.1 - the issuer MUST verify the request headers:\nContent-Type\nisapplication/x-www-form-urlencoded\nSec-Fetch-Dest\nisemail-verification\n-\n4.2 - the issuer MUST verify the request_token by:\n- parsing the JWT into header, payload, and signature components\n- confirming the presence of, and extracting the\njwk\nandalg\nfields from the JWT header, and theaud\n,iat\n, andemail\n, claims from the payload - verifying the JWT signature using the\njwk\nwith thealg\nalgorithm - verifying the\naud\nclaim exactly matches the issuer's identifier - verifying the\niat\nclaim is within 60 seconds of the current time - verifying the\nemail jwk\nwith thealg\nalgorithm - verifying the\naud\nclaim exactly matches the issuer's identifier - verifying the\niat\nclaim is within 60 seconds of the current time - verifying the\nemail\nclaim contains a syntactically valid email address\n-\n4.3 - the issuer checks if the cookies sent represent a logged in user, and if the logged in user has control of the email provided in the request_token. If so the issuer generates an SD-JWT with the following properties:\n- Header: MUST contain\nalg\n: signing algorithm (SHOULD match the algorithm from the request_token)kid\n: key identifier of key used to signtyp\nset to \"evp+sd-jwt\"\n- Payload: MUST contain the following claims:\niss\n: the issuer identifieriat\n: issued at timecnf\n: confirmation claim containing the public key from the request_token'sjwk\nfieldemail\n: claim containing the email address from the request_tokenemail_verified\n: claim that email is verified per OpenID Connect 1.0",
    "If so the issuer generates an SD-JWT with the following properties:\n- Header: MUST contain\nalg\n: signing algorithm (SHOULD match the algorithm from the request_token)kid\n: key identifier of key used to signtyp\nset to \"evp+sd-jwt\"\n- Payload: MUST contain the following claims:\niss\n: the issuer identifieriat\n: issued at timecnf\n: confirmation claim containing the public key from the request_token'sjwk\nfieldemail\n: claim containing the email address from the request_tokenemail_verified\n: claim that email is verified per OpenID Connect 1.0 fieldemail\n: claim containing the email address from the request_tokenemail_verified\n: claim that email is verified per OpenID Connect 1.0\n- Signature: MUST be signed with the issuer's private key corresponding to a public key in the\njwks_uri\nidentified bykid\n- Header: MUST contain\nExample header:\n{\n\"alg\": \"EdDSA\",\n\"kid\": \"2024-08-19\",\n\"typ\": \"evp+sd-jwt\"\n}\nExample payload:\n{\n\"iss\": \"issuer.example\",\n\"iat\": 1724083200,\n\"cnf\": {\n\"jwk\": {\n\"kty\": \"OKP\",\n\"crv\": \"Ed25519\",\n\"x\": \"11qYAYdk9E6z7mT6rk6j1QnXb6pYq4v9wXb6pYq4v9w\"\n}\n},\n\"email\": \"user@example.com\",\n\"email_verified\": true\n}\nThe resulting JWT has the ~\nappended to it, making it a valid SD-JWT. - 4.4 - the issuer returns the SD-JWT to the browser as the value of\nissuance_token\nin anapplication/json\nresponse. Example:\nHTTP/1.1 200 OK\nContent-Type: application/json\n{\"issuance_token\":\"eyJhbGciOiJFZERTQSIsImtpZCI6IjIwMjQtMDgtMTkiLCJ0eXAiOiJ3ZWItaWRlbnRpdHkrc2Qtand0In0...\"}",
    "Example:\nHTTP/1.1 200 OK\nContent-Type: application/json\n{\"issuance_token\":\"eyJhbGciOiJFZERTQSIsImtpZCI6IjIwMjQtMDgtMTkiLCJ0eXAiOiJ3ZWItaWRlbnRpdHkrc2Qtand0In0...\"} in anapplication/json\nresponse. Example:\nHTTP/1.1 200 OK\nContent-Type: application/json\n{\"issuance_token\":\"eyJhbGciOiJFZERTQSIsImtpZCI6IjIwMjQtMDgtMTkiLCJ0eXAiOiJ3ZWItaWRlbnRpdHkrc2Qtand0In0...\"}\nIf the issuer cannot process the token request successfully, it MUST return an appropriate HTTP status code with a JSON error response containing an error\nfield and optionally an error_description\nfield. When the request does not include the required Content-Type: application/x-www-form-urlencoded\nheader, the server MUST return the 415 HTTP response code\nWhen the request does not include the required Sec-Fetch-Dest: email-verification\nheader:\nHTTP 400 Bad Request\n{\n\"error\": \"invalid-request\",\n\"error_description\": \"Missing or invalid Sec-Fetch-Dest header\"\n}\nThe error_description\nSHOULD specify that the Sec-Fetch-Dest header is missing or invalid.",
    "When the request does not include the required Content-Type: application/x-www-form-urlencoded\nheader, the server MUST return the 415 HTTP response code\nWhen the request does not include the required Sec-Fetch-Dest: email-verification\nheader:\nHTTP 400 Bad Request\n{\n\"error\": \"invalid-request\",\n\"error_description\": \"Missing or invalid Sec-Fetch-Dest header\"\n}\nThe error_description\nSHOULD specify that the Sec-Fetch-Dest header is missing or invalid. {\n\"error\": \"invalid-request\",\n\"error_description\": \"Missing or invalid Sec-Fetch-Dest header\"\n}\nThe error_description\nSHOULD specify that the Sec-Fetch-Dest header is missing or invalid. When the request lacks valid authentication cookies, contains expired/invalid cookies, or the authenticated user does not have control of the requested email address:\nHTTP 401 Unauthorized\n{\n\"error\": \"authentication_required\",\n\"error_description\": \"User must be authenticated and have control of the requested email address\"\n}\nWhen the request_token\nis malformed, missing required claims, or contains invalid values:\nHTTP 400 Bad Request\n{\n\"error\": \"invalid_request\",\n\"error_description\": \"Invalid or malformed request_token\"\n}\nWhen the request_token\nsignature verification fails or the token structure is invalid:\nHTTP 400 Bad Request\n{\n\"error\": \"invalid_token\",\n\"error_description\": \"Token signature verification failed or token structure is invalid\"\n}\nFor internal server errors or temporary unavailability:",
    "When the request lacks valid authentication cookies, contains expired/invalid cookies, or the authenticated user does not have control of the requested email address:\nHTTP 401 Unauthorized\n{\n\"error\": \"authentication_required\",\n\"error_description\": \"User must be authenticated and have control of the requested email address\"\n}\nWhen the request_token\nis malformed, missing required claims, or contains invalid values:\nHTTP 400 Bad Request\n{\n\"error\": \"invalid_request\",\n\"error_description\": \"Invalid or malformed request_token\"\n}\nWhen the request_token\nsignature verification fails or the token structure is invalid:\nHTTP 400 Bad Request\n{\n\"error\": \"invalid_token\",\n\"error_description\": \"Token signature verification failed or token structure is invalid\"\n}\nFor internal server errors or temporary unavailability: HTTP 400 Bad Request\n{\n\"error\": \"invalid_token\",\n\"error_description\": \"Token signature verification failed or token structure is invalid\"\n}\nFor internal server errors or temporary unavailability:\nHTTP 500 Internal Server Error\n{\n\"error\": \"server_error\",\n\"error_description\": \"Temporary server error, please try again later\"\n}\nIn a future version of this spec, the issuer could prompt the user to login via a URL or with a Passkey request. On receiving the issuance_token\n:\n-\n5.1 - the browser MUST verify the SD-JWT per (SD-JWT spec) by:\n- parsing the SD-JWT into header, payload, and signature components\n- confirming the presence of, and extracting the\nalg\nandkid\nfields from the SD-JWT header, and theiss\n,iat\n,cnf\n,email\n, andemail_verified\nclaims from the payload - parsing the email domain from the\nemail\nclaim and looking up theTXT\nrecord for_email-verification.$EMAIL_DOMAIN\nto verify theiss\nclaim matches the issuer identifier in the DNS record - fetching the issuer's public keys from the",
    "On receiving the issuance_token\n:\n-\n5.1 - the browser MUST verify the SD-JWT per (SD-JWT spec) by:\n- parsing the SD-JWT into header, payload, and signature components\n- confirming the presence of, and extracting the\nalg\nandkid\nfields from the SD-JWT header, and theiss\n,iat\n,cnf\n,email\n, andemail_verified\nclaims from the payload - parsing the email domain from the\nemail\nclaim and looking up theTXT\nrecord for_email-verification.$EMAIL_DOMAIN\nto verify theiss\nclaim matches the issuer identifier in the DNS record - fetching the issuer's public keys from the email\nclaim and looking up theTXT\nrecord for_email-verification.$EMAIL_DOMAIN\nto verify theiss\nclaim matches the issuer identifier in the DNS record - fetching the issuer's public keys from the\njwks_uri\nspecified in the.well-known/email-verification\nfile - verifying the SD-JWT signature using the public key identified by\nkid\nfrom the JWKS with thealg\nalgorithm - verifying the\niat\nclaim is within 60 seconds of the current time - verifying the\nemail\nclaim matches the email address the user selected - verifying the\nemail_verified\nclaim is true\n-\n5.2 - the browser then creates an SD-JWT+KB by:\n- taking the verified SD-JWT from step 5.1 as the base token\n- creating a Key Binding JWT (KB-JWT) with the following structure:\n- Header:\nalg\n: same signing algorithm used by the browser's private keytyp\n: \"kb+jwt\"\n- Payload:\naud\n: the RP's originnonce\n: the nonce from the originalnavigator.credentials.get()\ncalliat\n: current time when creating the KB-JWTsd_hash\n: SHA-256 hash of the SD-JWT",
    "email\nclaim and looking up theTXT\nrecord for_email-verification.$EMAIL_DOMAIN\nto verify theiss\nclaim matches the issuer identifier in the DNS record - fetching the issuer's public keys from the\njwks_uri\nspecified in the.well-known/email-verification\nfile - verifying the SD-JWT signature using the public key identified by\nkid\nfrom the JWKS with thealg\nalgorithm - verifying the\niat\nclaim is within 60 seconds of the current time - verifying the\nemail\nclaim matches the email address the user selected - verifying the\nemail_verified\nclaim is true\n-\n5.2 - the browser then creates an SD-JWT+KB by:\n- taking the verified SD-JWT from step 5.1 as the base token\n- creating a Key Binding JWT (KB-JWT) with the following structure:\n- Header:\nalg\n: same signing algorithm used by the browser's private keytyp\n: \"kb+jwt\"\n- Payload:\naud\n: the RP's originnonce\n: the nonce from the originalnavigator.credentials.get()\ncalliat\n: current time when creating the KB-JWTsd_hash\n: SHA-256 hash of the SD-JWT : \"kb+jwt\"\n- Payload:\naud\n: the RP's originnonce\n: the nonce from the originalnavigator.credentials.get()\ncalliat\n: current time when creating the KB-JWTsd_hash\n: SHA-256 hash of the SD-JWT\n- Header:\n- signing the KB-JWT with the browser's private key (the same key pair generated in step 3.4)\n- concatenating the SD-JWT and the KB-JWT separated by a tilde (~) to form the SD-JWT+KB\nExample KB-JWT header:\n{ \"alg\": \"EdDSA\", \"typ\": \"kb+jwt\" }\nExample KB-JWT payload:\n{ \"aud\": \"https://rp.example\", \"nonce\": \"259c5eae-486d-4b0f-b666-2a5b5ce1c925\", \"salt\": \"kR7fY9mP3xQ8wN2vL5jH6tZ1cB4nM9sD8fG3hJ7kL2p\", \"iat\": 1724083260, \"sd_hash\": \"X9yH0Ajrdm1Oij4tWso9UzzKJvPoDxwmuEcO3XAdRC0\" }\n-\n5.3 - the browser sets a TBD hidden field and fires the TBD event ...\ndetails TBD\nThe RP web page now has the SD-JWT+KB from the event, and passes it to the RP server, or the token was posted to the RP server. details TBD\nThe RP server MUST verify the SD-JWT+KB by:\n-",
    "details TBD\nThe RP server MUST verify the SD-JWT+KB by:\n- details TBD\nThe RP web page now has the SD-JWT+KB from the event, and passes it to the RP server, or the token was posted to the RP server. details TBD\nThe RP server MUST verify the SD-JWT+KB by:\n-\n6.1 - the RP server receives the SD-JWT+KB from the web page\n-\n6.2 - the RP parses the SD-JWT+KB by separating the SD-JWT and KB-JWT components (separated by tilde ~)\n-\n6.3 - the RP verifies the KB-JWT by:\n- parsing the KB-JWT into header, payload, and signature components\n- confirming the presence of, and extracting the\nalg\nfield from the KB-JWT header, and theaud\n,nonce\n,iat\n, andsd_hash\nclaims from the payload - verifying the\naud\nclaim matches the RP's origin - verifying the\nnonce\nclaim matches the nonce from the RP's session with the web page - verifying the\niat\nclaim is within a reasonable time window - computing the SHA-256 hash of the SD-JWT and verifying it matches the\nsd_hash\nclaim\n-\n6.4 - the RP verifies the SD-JWT by:",
    "details TBD\nThe RP server MUST verify the SD-JWT+KB by:\n-\n6.1 - the RP server receives the SD-JWT+KB from the web page\n-\n6.2 - the RP parses the SD-JWT+KB by separating the SD-JWT and KB-JWT components (separated by tilde ~)\n-\n6.3 - the RP verifies the KB-JWT by:\n- parsing the KB-JWT into header, payload, and signature components\n- confirming the presence of, and extracting the\nalg\nfield from the KB-JWT header, and theaud\n,nonce\n,iat\n, andsd_hash\nclaims from the payload - verifying the\naud\nclaim matches the RP's origin - verifying the\nnonce\nclaim matches the nonce from the RP's session with the web page - verifying the\niat\nclaim is within a reasonable time window - computing the SHA-256 hash of the SD-JWT and verifying it matches the\nsd_hash\nclaim\n-\n6.4 - the RP verifies the SD-JWT by: iat\nclaim is within a reasonable time window - computing the SHA-256 hash of the SD-JWT and verifying it matches the\nsd_hash\nclaim\n-\n6.4 - the RP verifies the SD-JWT by:\n- parsing the SD-JWT into header, payload, and signature components\n- confirming the presence of, and extracting the\nalg\nandkid\nfields from the SD-JWT header, and theiss\n,iat\n,cnf\n,email\n, andemail_verified\nclaims from the payload - parsing the email domain from the\nemail\nclaim and looking up theTXT\nrecord for_email-verification.$EMAIL_DOMAIN\nto verify theiss\nclaim matches the issuer identifier in the DNS record - fetching the issuer's public keys from the\njwks_uri\nspecified in the.well-known/email-verification\nfile - verifying the SD-JWT signature using the public key identified by\nkid\nfrom the JWKS with thealg\nalgorithm - verifying the\niss\nclaim exactly matches the issuer identifier from the DNS record - verifying the\niat\nclaim is within a reasonable time window - verifying the\nemail_verified\nclaim is true\n-",
    "iat\nclaim is within a reasonable time window - computing the SHA-256 hash of the SD-JWT and verifying it matches the\nsd_hash\nclaim\n-\n6.4 - the RP verifies the SD-JWT by:\n- parsing the SD-JWT into header, payload, and signature components\n- confirming the presence of, and extracting the\nalg\nandkid\nfields from the SD-JWT header, and theiss\n,iat\n,cnf\n,email\n, andemail_verified\nclaims from the payload - parsing the email domain from the\nemail\nclaim and looking up theTXT\nrecord for_email-verification.$EMAIL_DOMAIN\nto verify theiss\nclaim matches the issuer identifier in the DNS record - fetching the issuer's public keys from the\njwks_uri\nspecified in the.well-known/email-verification\nfile - verifying the SD-JWT signature using the public key identified by\nkid\nfrom the JWKS with thealg\nalgorithm - verifying the\niss\nclaim exactly matches the issuer identifier from the DNS record - verifying the\niat\nclaim is within a reasonable time window - verifying the\nemail_verified\nclaim is true\n- iss\nclaim exactly matches the issuer identifier from the DNS record - verifying the\niat\nclaim is within a reasonable time window - verifying the\nemail_verified\nclaim is true\n-\n6.5 - the RP verifies the KB-JWT signature using the public key from the\ncnf\nclaim in the SD-JWT with thealg\nalgorithm from the KB-JWT header\nBelow are notes capturing some discussions of potential privacy implications. -\nThe email domain operator no longer learns which applications the user is verifying their email address to as the applications are no longer sending an email verification code to the user. By using an SD-JWT+KB, the browser intermediates the request and response so that the issuer does not learn the identity of the RP. -\nThe RP can infer if a user is logged into the issuer as the RP receives a SD-JWT when the user is logged in, and does not when the user is not logged in. -\nThe issuer may learn the user has email at a mail domain it is authoritative for that it did not know the user had.",
    "-\nThe issuer may learn the user has email at a mail domain it is authoritative for that it did not know the user had. -\nThe issuer may learn the user has email at a mail domain it is authoritative for that it did not know the user had. The web page would call an API passing the email address and nonce. It would return a promise that resolves to the SD_JWT or an error response. The API would only be callable after a user gesture such as clicking a button labelled verify on the web page. This provides the web page in more flexibility in how to gather the email address. For example, if the web page is using EVP for login, and the user has used different emails for login and those are stored in cookies, the page can display the list of emails and an option to provide a different one. The user can then select the email they want to use rather than having to type it into a text field.",
    "The user can then select the email they want to use rather than having to type it into a text field. In addition to, or instead of the browser sending cookies to the Issuer, the Issuer could return a WebAuthN request to the browser if it has credentials for the user identified by the email address. The browser would then interact with the user and provide the WebAuthN response to the Issuer, authenticating the user, and the Issuer would then return the SD-JWT. Rather than the DNS TXT record, the Mail Domain would host a JSON file in the .wellknown domain. This creates challenges for the long tail of individually owned domains:\n- would require a domain that is used just for email to now have to support a web server\n- the mail domain is usually an apex domain, which does not support CNAME, complicating hosting a web site",
    "Using bubblewrap to add sandboxing to NetBSD",
    "Using bubblewrap to add sandboxing to NetBSD Google Summer of Code 2025 Reports: Using bubblewrap to add sandboxing to NetBSD\nThis report was written by Vasyl Lanko as part of Google Summer of Code 2025. Introduction\nAs of the time of writing, there is no real sandboxing technique available to NetBSD. There is chroot, which can be considered a weak sandbox because it modifies the root directory of the process, effectively restricting the process' view of the file system, but it doesn't isolate anything else, so all networking, IPC, and mounts inside this restricted file system are the same as of the system, and are accessible. There has already been some research on implementing kernel-level isolation in NetBSD with tools like gaols, mult and netbsd-sandbox, but they haven't been merged to NetBSD. Other operating systems have their own ways to isolate programs, FreeBSD has jails, and Linux has namespaces. Project Goals",
    "Project Goals Project Goals\nThe goal of this project is to bring a new way of sandboxing to NetBSD. More specifically, we want to implement a mechanism like Linux namespaces. These namespaces allow the isolation of parts of the system from a namespace, or, as the user sees it, from an application. NetBSD has compat_linux to run Linux binaries on NetBSD systems, and the implementation of namespaces can also be utilized to emulate namespace-related functionality of Linux binaries. A simple example to visualize our intended result is to consider an application running under an isolated UTS namespace that modifies the hostname. From the system's view, the hostname remains the same old hostname, but from the application's view it sees the modified hostname. Project Implementation\nLinux has 8 namespace types, in this project we will focus on only 2 of them:\n- UTS namespace, it is the simplest so we can focus on building the general namespace infrastructure with little namespace-specific details",
    "Project Implementation\nLinux has 8 namespace types, in this project we will focus on only 2 of them:\n- UTS namespace, it is the simplest so we can focus on building the general namespace infrastructure with little namespace-specific details - UTS namespace, it is the simplest so we can focus on building the general namespace infrastructure with little namespace-specific details\n- mount namespace, it is a prerequisite to most other namespace types because UNIX follows the philosophy of \"everything is a file\", so we need a separate mount namespace to have different configuration files on the same location as the system. Linux creates namespaces via the unshare or clone system calls, and it will also be our way of calling the namespace creation logic. We setup the base for implementing Linux namespaces in the NetBSD kernel using kauth, the subsystem managing all authorization requests inside the kernel. It associates credentials with objects, and because the namespace lifecycle management is related to the credential lifecycle it handles all the credential inheritance and reference counting for us. (Thanks kauth devs!)",
    "(Thanks kauth devs!) We separate the implementation of each namespace in a different secmodel, resulting in a similar framework to Linux which allows the isolation of a single namespace type. Our implementation also allows users to pick whether they want to have namespace support, and of what kind, via compilation flags, just like in Linux. UTS namespace\nUTS stands for UNIX Timesharing System, because it allows multiple users to share a single computer system. Isolating the utsname\ncan be useful to give users the illusion that they have control over the system's hostname, and also, for example, to give different hostnames to virtual servers. The UTS namespace stores the namespace's hostname, domain name, and their lengths. To isolate the utsname\nwe need to first create a copy of the current UTS information, plus we need a variable containing the number of credentials referencing this namespace, or, in simpler terms, the reference count of this namespace.",
    "To isolate the utsname\nwe need to first create a copy of the current UTS information, plus we need a variable containing the number of credentials referencing this namespace, or, in simpler terms, the reference count of this namespace. This namespace specific information needs to be saved somewhere, and for that we use the credential's private_data\nfield, so we can use a UTS_key\nto save and retrieve UTS\nrelated information from the secmodel. The key specifies the type of information we want to retrieve from the private_data\n, hence using a UTS_key\nfor the UTS namespace. The key for each namespace is a fixed value (we don't create a new key for every credential), but the retrieved value for that key from different credentials may be different. We had to modify kernel code that was directly accessing the hostname\nand domainname\nvariables, to instead call get_uts()\n, which retrieves the UTS struct for the namespace of the calling process. We didn't modify occurrences in kernel drivers because drivers are not part of any namespace, so they should still access the system's resources directly. MNT namespace",
    "MNT namespace MNT namespace\nThe MNT namespace isolates mounts across namespaces. It is used to have different versions of mounted filesystems across namespaces, meaning a user inside a mount namespace can mount and unmount whatever they want without affecting or even breaking the system. The mount namespace structure in Linux is fairly complicated. To have something similar in NetBSD we need to be able to control the mounts accessed by each namespace, and for that we need to control what is each namespace's mountlist, this is also enough for unmounting file systems, because in practice we can just hide them. For the mount_namespace, mountlist structure and the number of credentials using the mount namespace are stored in the credential's private data with the MNT_key\n. Similarly to the UTS namespace, we had to modify kernel code to not directly access the mountlist\n, but instead go through a wrapper called get_mountlist()",
    "Similarly to the UTS namespace, we had to modify kernel code to not directly access the mountlist\n, but instead go through a wrapper called get_mountlist() . Similarly to the UTS namespace, we had to modify kernel code to not directly access the mountlist\n, but instead go through a wrapper called get_mountlist()\nwhich returns the correct mountlist for the namespace the calling process resides in. Implementation for the mount namespace is immensely more complex than for the UTS namespace, it involves having a good understanding of both Linux and NetBSD behaviour, and I would frequently find myself wondering how to implement something after reading the Linux man pages, which would lead to me looking for it in the Linux source code, understanding it, then going back to NetBSD source code, trying to implement it, and seeing it's too different to implement in the same way. Project Status\nYou can find all code written during this project in GitHub at maksymlanko/netbsd-src gsoc-bubblewrap\nbranch. Because I intend to continue this work outside of GSoC, I want to reinforce that this was the last commit still during GSoC on gsoc-bubblewrap",
    "Because I intend to continue this work outside of GSoC, I want to reinforce that this was the last commit still during GSoC on gsoc-bubblewrap branch. Because I intend to continue this work outside of GSoC, I want to reinforce that this was the last commit still during GSoC on gsoc-bubblewrap\nbranch and this was the last one for the mnt_ns\nstill WIP branch. The link includes implementation of general namespace code via secmodels, implementation of the UTS namespace and related ATF-tests, and the work-in-progress implementation of mount namespaces. The mount namespace functionality is not finished as it would require much more work than the time available for this project. To complete it, it would be required invasive and non-trivial changes to the original source code, and, of course, more time. Future Work\nAs previously mentioned, Linux has 8 namespace types, it is important to see which of the missing namespaces are considered useful and feasible to implement.",
    "Future Work\nAs previously mentioned, Linux has 8 namespace types, it is important to see which of the missing namespaces are considered useful and feasible to implement. Future Work\nAs previously mentioned, Linux has 8 namespace types, it is important to see which of the missing namespaces are considered useful and feasible to implement. I believe that after mount namespaces it would be interesting to implement PID namespaces as this in combination with mount namespaces would permit process isolation from this sandbox. Afterwards, implementing user namespaces would allow users to get capabilities similar to root\nin the namespace, giving them sudo\npermissions while still restricting system-wide actions like shutting down the machine. A lower hanging fruit is to implement the namespace management functionality, which in Linux is lsns to list existing namespaces, and setns to move the current process to an already existing namespace. Challenges\n- Semantics. Did you know the unmount system call with MNT_FORCE flag in Linux (usually) returns EBUSY, and in NetBSD it forces the unmounting? One of them makes it easier to implement mount namespaces.",
    "One of them makes it easier to implement mount namespaces. - The behaviour of namespaces is not fully specified in the man pages. If something is not clear from the man pages you need to read the source code. - Unexpected need to learn a lot of VFS concepts and their differences in NetBSD and Linux. - There was a much bigger research component than I anticipated. In the end, Linux and NetBSD are different operating systems, implemented in different ways. Linux is complex and it is not trivial to port namespaces to NetBSD. Notes\nThe project is called \"Using bubblewrap to add sandboxing to NetBSD\" and was initially projected to emulate the unshare\nsystem call into compat_linux\n, but, seeing that having namespaces could be useful for NetBSD, and that it would be easy to add to compat_linux\nafterwards, we decided to instead implement namespaces directly in the NetBSD kernel. Implementing other system calls necessary to make the bwrap",
    "Implementing other system calls necessary to make the bwrap afterwards, we decided to instead implement namespaces directly in the NetBSD kernel. Implementing other system calls necessary to make the bwrap\nlinux binary work correctly also wouldn't be as satisfying as implementing namespaces directly into NetBSD, so this was why the project was initially called \"Using bubblewrap to add sandboxing to NetBSD\" but nowadays it would be more accurate to call it \"Sandboxing in NetBSD with Linux-like namespaces\". Thanks\nI am very grateful to Google for Google Summer of Code, because without it I wouldn't have learned so much this summer, wouldn't have met with smart and interesting people, and for sure wouldn't have tried to contribute to a project like NetBSD, even if I always wanted to write operating systems code... But, the biggest thing I will take with me from this project is the confidence to be able to contribute to NetBSD and other open source projects.",
    "But, the biggest thing I will take with me from this project is the confidence to be able to contribute to NetBSD and other open source projects. I would also like to thank the members of the NetBSD organization for helping me throughout this project, and more specifically:\n- Taylor R. Campbell, Harold Gutch and Nia Alarie from IRC, for helping me fix a nasty\nLD_LIBRARY_PATH\nbug I had on my system which wouldn't let me finish compiling NetBSD, and general GSoC recomendations. - Emmanuel Dreyfus from\ntech-kern\n, with whom I discussed ideas for projects and proposal suggestions, and in the end inspired the namespaces project. - Christoph Badura and Leonardo Taccari who volunteered to be my mentors. They took time to research and answer my questions, anticipated possible problems in my approaches, and always pointed me in the right direction, daily, during all of GSoC's period. This project is from the 3 of us.",
    "Montana Becomes First State to Enshrine 'Right to Compute' into Law",
    "Montana Becomes First State to Enshrine 'Right to Compute' into Law Montana has made history as the first state in the U.S. to legally protect its citizens\u2019 right to access and use computational tools and artificial intelligence technologies. Governor Greg Gianforte signed Senate Bill 212, officially known as the Montana Right to Compute Act (MRTCA), into law. The groundbreaking legislation affirms Montanans\u2019 fundamental right to own and operate computational resources \u2014 including hardware, software, and AI tools \u2014 under the state\u2019s constitutional protections for property and free expression. Supporters of the bill say it represents a major step in securing digital freedoms in an increasingly AI-driven world. \u201cMontana is once again leading the way in defending individual liberty,\u201d said Senator Daniel Zolnikov, the bill\u2019s sponsor and a longtime advocate for digital privacy. \u201cWith the Right to Compute Act, we are ensuring that every Montanan can access and control the tools of the future.\u201d",
    "\u201cWith the Right to Compute Act, we are ensuring that every Montanan can access and control the tools of the future.\u201d While the law allows state regulation of computation in the interest of public health and safety, it sets a high bar: any restrictions must be demonstrably necessary and narrowly tailored to serve a compelling interest. Legal experts note that this is one of the most protective standards available under Montana law. The act also includes provisions for AI-controlled critical infrastructure, requiring both a \u201cshutdown mechanism\u201d to allow human control and annual safety reviews \u2014 a move aimed at balancing innovation with public safety concerns. The bill has drawn praise from privacy advocates and tech policy groups. Tanner Avery, Policy Director at the free-market think tank Frontier Institute, called the law a \u201cflag in the ground\u201d for digital rights, adding: \u201cMontana has made clear it will treat any attempt to infringe on fundamental digital freedoms with the utmost scrutiny.\u201d",
    "Tanner Avery, Policy Director at the free-market think tank Frontier Institute, called the law a \u201cflag in the ground\u201d for digital rights, adding: \u201cMontana has made clear it will treat any attempt to infringe on fundamental digital freedoms with the utmost scrutiny.\u201d The MRTCA stands in stark contrast to recent regulatory efforts in other states, such as California, Virginia, and New York, where proposals to rein in AI technologies have either failed or been heavily revised. Montana\u2019s approach leans toward empowering individual users rather than restricting access. The law has already inspired similar efforts in New Hampshire, where lawmakers are pushing a constitutional amendment guaranteeing access to computation. Rep. Keith Ammon, the state\u2019s Majority Floor Leader, praised Montana\u2019s leadership: \u201cThis is the kind of bold move that sets the tone for the rest of the country.\u201d\nNationally, the Right to Compute movement is gaining traction. Spearheaded by the grassroots group RightToCompute.ai, the campaign argues that computation \u2014 like speech and property \u2014 is a fundamental human right. \u201cA computer is an extension of the human capacity to think,\u201d the organization states.",
    "\u201cA computer is an extension of the human capacity to think,\u201d the organization states. The movement is supported by Haltia.AI, a Dubai-based AI startup, and the ASIMOV Protocol, a blockchain consortium advocating for decentralized AI infrastructure. Talal Thabet, Co-Founder of both groups, praised Montana\u2019s law as \u201ca monumental step forward in ensuring individuals retain control of their own data and digital tools.\u201d\nAs debates over AI governance and digital rights continue to evolve, Montana\u2019s bold new law could serve as a blueprint for other states seeking to safeguard freedom in the digital era.",
    "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
    "Zensical \u2013 A modern static site generator built by the Material for MkDocs team Zensical \u2013 A modern static site generator built by the Material for MkDocs team\u00b6\nWe are thrilled to announce Zensical, our next-gen static site generator designed to simplify the process of building documentation sites. Distilled from a decade of experience, Zensical is our effort to overcome the technical limitations of MkDocs, reaching far beyond its capabilities. Zensical is the result of thousands of hours of work \u2013 built from the ground up for a modern and comfortable authoring experience, while making it easy for developers to extend and customize Zensical through its upcoming module system. Our goal is to support docs-as-code workflows with tens of thousands of pages, without compromising performance or usability. To make the transition seamless, compatibility comes first. We're putting significant effort into ensuring a smooth migration from Material for MkDocs for all users. Zensical can natively read mkdocs.yml",
    "Zensical can natively read mkdocs.yml , allowing you to build your existing project with minimal changes. As of now, a subset of plugins is supported, and we're working on feature parity in the coming months. Zensical is fully Open Source, licensed under MIT, and can be used for any purpose, including for commercial use. We're also saying goodbye to our sponsorware model, replacing it with our new offering for professional users: Zensical Spark. This allows us to stay independent, maximizing user value, as we shape the future of Zensical together with you. You can subscribe to our newsletter to stay in the loop. This is the second article in a four-part series:\n- Transforming Material for MkDocs\n- Zensical \u2013 A modern static site generator built by the creators of Material for MkDocs. - What happens to the features in Insiders coming November 11, 2025\n- A path forward for our community coming November 18, 2025\nWhy Zensical?\u00b6",
    "- What happens to the features in Insiders coming November 11, 2025\n- A path forward for our community coming November 18, 2025\nWhy Zensical?\u00b6 - What happens to the features in Insiders coming November 11, 2025\n- A path forward for our community coming November 18, 2025\nWhy Zensical?\u00b6\nSince its initial release in 2016, Material for MkDocs has helped tens of thousands of teams to publish and maintain reliable documentation. However, in recent years, it has become apparent that we were running up against limitations of our core dependency, MkDocs. These limitations proved impossible to overcome as they are deeply rooted in its architecture. We also mentioned in our update on our foundational work that MkDocs must be considered a supply chain risk, since it's unmaintained since August 2024. It has seen no releases in over a year and is accumulating unresolved issues and pull requests. These developments have forced us to cut our ties to MkDocs as a dependency.",
    "These developments have forced us to cut our ties to MkDocs as a dependency. In order to map out a path forward, we went back to the drawing board, talked to dozens of our professional users and thoroughly analyzed the MkDocs ecosystem. We didn't just want to create a fork or port of MkDocs, but decided to rethink static site generation from first principles. With Zensical, we are creating a modern static site generator, which is compatible with your content and customizations, and addresses MkDocs' limitations. While Material for MkDocs is built on top of MkDocs, Zensical consolidates both projects into one coherent stack, covering static site generation, theming, and customization. What you can expect today:\nAlthough we haven't reached full feature parity yet, you can already use Zensical to build your existing Material for MkDocs projects with minimal changes. You can jump to the compatibility section to learn what is already supported. What you can expect\u00b6\nSolid foundation\u00b6",
    "What you can expect\u00b6\nSolid foundation\u00b6 You can jump to the compatibility section to learn what is already supported. What you can expect\u00b6\nSolid foundation\u00b6\nOur goal with Zensical is to create a coherent and modern stack, vertically integrating all parts of the authoring experience (AX), developer experience (DX), and user experience (UX). This gives us a significant competitive advantage over solutions that overly rely on third-party frameworks and dependencies, helping us to create much more robust Open Source software. ZRX, our new differential build engine, creates a solid foundation for Zensical, and is an Open Source project of its own. It's a fresh take on making differential data flows easy to build and a joy to work with. Most engineering effort has gone into ZRX, as it forms the backbone of Zensical, and will allow us to ship features faster.",
    "Most engineering effort has gone into ZRX, as it forms the backbone of Zensical, and will allow us to ship features faster. Following the principle of architectural hoisting, we moved essential, reusable functionality into ZRX, which allows us to keep Zensical's core simple and focused on static site generation. ZRX handles the heavy lifting \u2013 differential builds, caching, and data flow orchestration. With the upcoming module system and component system, both of which are on our public roadmap, Zensical will gain more degrees of freedom in the coming months, allowing you to extend and customize Zensical in ways that were previously impossible with MkDocs. Modern design\u00b6\nZensical brings a fresh, modern design that breaks out of the Materal Design aesthetic, creating a visual foundation that is more easily brandable and adaptable to different use cases. The new design prioritizes clarity, simplicity, and usability, while having a more professional finish:",
    "The new design prioritizes clarity, simplicity, and usability, while having a more professional finish: Right now, the layout and site structure of Zensical match Material for MkDocs closely, as we're focusing on ensuring maximum compatibility. Once we finish work on our upcoming component system, we'll provide an alternative that is much more flexible and adaptable, and can be tailored to different use cases and branding requirements more easily. You can also keep the Material for MkDocs look and feel with a single line of configuration. Blazing-fast search\u00b6\nClient-side search isn't a compromise \u2013 for the vast majority of static sites, it's the best solution, since it's faster, involves zero maintenance, and doesn't require you to pay for a service. As covered in depth in the first part of this series, the current search implementation in Material for MkDocs has severe limitations, and is based on a now unmaintained library, which is why we decided to build a new search engine from scratch. It's based on the same goals as Zensical itself: performance, flexibility, and extensibility.",
    "It's based on the same goals as Zensical itself: performance, flexibility, and extensibility. Disco, our modular and blazing-fast client-side search engine, is exclusively available in Zensical. When you build your site with Zensical, your users will immediately benefit from Disco's improved ranking algorithm, as well as its filtering and aggregation capabilities:\nIn early 2026, we'll be releasing Disco as a standalone Open Source project. With the feedback of our professional users in Zensical Spark, we're going to evolve the search experience, turning Disco into a highly configurable and customizable search engine that adapts to your needs. You can subscribe to our newsletter to receive news about Disco. Authoring experience\u00b6\nSlow feedback loops can be a major pain point when writing documentation. Almost all of us know the feeling of waiting for the static site generator to finish building the site, just to see a small change reflected in the output. With Zensical, we're finally addressing this issue.",
    "With Zensical, we're finally addressing this issue. It's important to understand that we're not yet utilizing the differential capabilities of ZRX to the fullest extent, as we're forced to make several compromises to ensure maximum compatibility with Material for MkDocs at the moment. Markdown rendering needs to go through Python Markdown, which forces us to pay for extra marshalling costs. While the initial build can sometimes be slower than with MkDocs, repeated builds \u2013 especially when serving the site \u2013 are already 4 to 5x faster, as only changed files need to be rebuilt. We're also working on a new Markdown toolchain based on a CommonMark-compliant parser written in Rust, which will make Markdown processing significantly faster. We'll be tackling this as part of the upcoming component system, which we'll start working on in early 2026. Once our new Markdown toolchain is ready, we'll provide automated tools to translate between Python Markdown and CommonMark, so you don't need to manually migrate your content.",
    "Once our new Markdown toolchain is ready, we'll provide automated tools to translate between Python Markdown and CommonMark, so you don't need to manually migrate your content. Maximum compatibility\u00b6\nCompatibility with Material for MkDocs is our top priority. We understand that switching to a new static site generator can be challenging, especially for large projects with many customizations. Therefore, we've put significant effort into ensuring that Zensical understands mkdocs.yml\nconfiguration files, so that you can build your projects with minimal changes. This means your existing Markdown files, template overrides, CSS and JavaScript extensions don't need to be touched, primarily because we did not change the generated HTML, and rely on Python Markdown for processing your content. However, plugins are a different story. In MkDocs, practically all plugins have side effects, making it impossible to parallelize builds. We started from first principles and asked: what should extensibility look like in a modern static site generator? Our answer is the upcoming module system, which takes a fundamentally different approach based on four core principles:",
    "Our answer is the upcoming module system, which takes a fundamentally different approach based on four core principles: - Modules can inject, extend, and re-define functionality\n- Modules are deterministic through topological ordering\n- Modules foster reusability, with the possibility to remix them\n- Modules can cooperate through well-defined contracts\nWe're working on shipping essential functionality as provided by MkDocs plugins as built-in modules. In early 2026, we will open the module system to third-party developers, so they can start building their own modules, as we see Zensical as the heart of a thriving ecosystem. Zensical Spark\u00b6\nZensical Spark, our offering for professionals, is the result of countless calls with professional users of Material for MkDocs. From startups to large enterprises, we enable organizations to realize complex projects in diverse environments. For this, we've created Zensical Spark as a collaborative space. If you're a professional user, Zensical Spark is for you, since:\n-",
    "If you're a professional user, Zensical Spark is for you, since:\n- -\nYou can be confident that Zensical will continue to be developed and maintained in the long term as a set of interconnected and sustainable OSI-compliant Open Source projects. -\nYou can receive the support you need to successfully use, configure and customize Zensical in your organization, receiving first-class support from the Zensical team. -\nYou can influence the future development of Zensical by participating in our new approach to Open Source software development, helping us to build exactly what you need. Let's talk! If you're working in a professional context, reach out to contact@zensical.org to schedule a call and learn how Zensical Spark enables your team to transition to Zensical smoothly and have a voice in its continued development. You should also consider joining the waiting list, since seats are limited. We're growing our team\u00b6\nWe're also excited to announce that we're growing our team:\nTimoth\u00e9e Mazzucotelli, also known as @pawamoy, is joining Zensical!",
    "We're growing our team\u00b6\nWe're also excited to announce that we're growing our team:\nTimoth\u00e9e Mazzucotelli, also known as @pawamoy, is joining Zensical! We're growing our team\u00b6\nWe're also excited to announce that we're growing our team:\nTimoth\u00e9e Mazzucotelli, also known as @pawamoy, is joining Zensical! At Zensical, Tim is focusing on providing the same seamless experience for generating API reference documentation from source code (via docstrings) as he has done with mkdocstrings, the second biggest project in the MkDocs ecosystem. With his expertise, and Zensical's new stack, we'll be pushing the boundaries of what's possible with API reference documentation. Goodbye, GitHub Sponsors\u00b6\nThank you! To all of you who have supported us over the years through GitHub Sponsors \u2013 we are incredibly grateful for your support. It has been invaluable in helping us to build, maintain and evolve Material for MkDocs, and we couldn't have done it without you. Seriously, thank you!",
    "Seriously, thank you! Material for MkDocs gave us something invaluable: experience building for tens of thousands of users, and the opportunity to build a team around Open Source software. It showed us that making a living from Open Source isn't just possible \u2013 we grew it into one of the largest sponsorware projects on GitHub and inspired others to pursue similar paths. Now we're breaking new ground. Zensical is our next chapter, and we're professionalizing how we approach Open Source development. Our vision is to make Zensical free for everyone to use while building a sustainable business around it through our new approach. This transition means saying goodbye to GitHub Sponsors. It has served us exceptionally well, but as we professionalize and scale, we're making the leap from personal project to company \u2013 building a business and team that can meet the growing demands of professional users while staying true to our values. We're doubling down on Open Source, developing software for everyone.",
    "We're doubling down on Open Source, developing software for everyone. We're doubling down on Open Source, developing software for everyone. If you want to continue supporting our work, please subscribe to our newsletter. We'll be providing new methods to support us in the coming months, with the possibility of getting exclusive goodies. Looking Ahead\u00b6\nMaterial for MkDocs grew organically in a pot that eventually became too small. With Zensical, we're building on solid foundations designed to grow with us \u2013 and with you. Material for MkDocs is now in maintenance mode\nWe want to be transparent about the risks of staying on Material for MkDocs. With MkDocs unmaintained and facing fundamental supply chain concerns, we cannot guarantee Material for MkDocs will continue working reliably in the future. We're aware that transitioning takes time, which is why we commit to support it at least for the next 12 months, fixing critical bugs and security vulnerabilities as needed, but the path forward is with Zensical.",
    "We're aware that transitioning takes time, which is why we commit to support it at least for the next 12 months, fixing critical bugs and security vulnerabilities as needed, but the path forward is with Zensical. If documentation plays a critical role in your organization, and you're worried how this might affect your business, consider joining Zensical Spark, or feel free to schedule a call by reaching out at contact@zensical.org. Where we'll be in 12 months\u00b6\nOver the next 12 months, following our phased transition strategy, we'll reach Phase 2 and 3 \u2013 introducing our module system and component system, as well as CommonMark support. By replacing Python Markdown with a Rust-based Markdown parser, we'll unlock performance improvements and the modularity needed for flexible templating. This is where Zensical truly starts to unfold its capabilities. Zensical is already powering real projects due to extensive compatibility with Material for MkDocs. We're actively working on closing the gap to reach full feature parity. You can install Zensical now, and build your existing Material for MkDocs projects with it. If you run into a bug, please don't hesitate to open an issue \u2013 we're here to help.",
    "If you run into a bug, please don't hesitate to open an issue \u2013 we're here to help. You can install Zensical now, and build your existing Material for MkDocs projects with it. If you run into a bug, please don't hesitate to open an issue \u2013 we're here to help. Connect with us\u00b6\nIf you have questions we haven't addressed, please reach out to us at contact@zensical.org. We're currently collecting questions from the community about Zensical, and will address them in an FAQ section as part of our documentation in the coming weeks. We're incredibly thankful that you have been part of our journey so far. With Zensical, we're embarking on a new chapter, and we couldn't be more excited to have you with us. You can subscribe to our newsletter to stay in the loop.",
    "I Am Mark Zuckerberg",
    "I Am Mark Zuckerberg Welcome to iammarkzuckerg.com\nNo, not THAT Mark Zuckerberg-this one's busy helping Hoosiers, not launching social networks. Relax, you haven't accidentally logged into Facebook or the Metaverse. You're on the site of Mark S. Zuckerberg, Indiana's original bearer of the name, proud bankruptcy attorney, and frequent recipient of confused emails from people seeking tech support or handouts of money. What I Really Do:\n- Help people obtain a fresh financial start (no passwords required)\n- Offer dependable, human-involved advice (my artificial intelligence is powered by coffee)\n- Answer local legal questions, not privacy scandals\nReal Zuckerberg Facts:\n- Shares a name, not fortune, with the Facebook founder\n- Gets mistaken daily for a tech billionaire\n- Has written zero social media apps, but plenty of court briefs\nFun Fact:\nIn Indiana, saying \"I'm Mark Zuckerberg\" gets more laughs than likes. But if you need trustworthy bankruptcy help, you're in exactly the right place!",
    "But if you need trustworthy bankruptcy help, you're in exactly the right place! Fun Fact:\nIn Indiana, saying \"I'm Mark Zuckerberg\" gets more laughs than likes. But if you need trustworthy bankruptcy help, you're in exactly the right place! Click around, get to know your (non-billionaire) local Mark, and remember: No login required. Click Here to See How Other\nWebsites Have Reacted to This\nInteresting Things That Have Happened to Me Because My Name is Mark Zuckerberg\nFor a complete list of things that have happened to Mark Zuckerberg click here\nLike I said, I don't wish Mark E. Zuckerberg any ill will at all. I hope the best for him, but let me tell you this: I will rule the search for \"Mark Zuckerberg bankruptcy\". And if he does fall upon difficult financial times, and happens to be in Indiana, I will gladly handle his case in honor of our eponymy.",
    "Ironclad \u2013 formally verified, real-time capable, Unix-like OS kernel",
    "Ironclad \u2013 formally verified, real-time capable, Unix-like OS kernel Ironclad is a (partially) formally verified, real-time capable, UNIX-like operating system kernel for general-purpose and embedded uses. It is written in SPARK and Ada, and is comprised of 100% free software. Ironclad features a familiar POSIX-compatible interface, true simultaneous preemptive multitasking, Mandatory Access Control (MAC), and support for hard real-time scheduling. Ironclad is fully open source and distributed under the GPLv3, ensuring it remains free. No firmware blobs are needed or shipped with the kernel. Every piece of the stack is open source. SPARK's state of the art formal verification is employed for ensuring absence of errors and correctness of big portions of Ironclad, like cryptography, MAC, and user-facing facilities. Ported to several platforms and boards, and designed to be easily portable to many more. Dependency on only the GNU toolchain allows for easy cross-compilation.",
    "Dependency on only the GNU toolchain allows for easy cross-compilation. Ported to several platforms and boards, and designed to be easily portable to many more. Dependency on only the GNU toolchain allows for easy cross-compilation. Ironclad will always be free for use, study, and modification, so, to support the project, we rely on the use of donations and grants. Every contribution makes a difference and allows us to do more. This project is funded through NGI Zero Core, a fund established by NLnet with financial support from the European Commission's Next Generation Internet program. Learn more at the NLnet project page. Additionally, we would like to thank the following organizations:",
    "The Manuscripts of Edsger W. Dijkstra",
    "The Manuscripts of Edsger W. Dijkstra Home\nNumerical EWD Index: 00xx 01xx 02xx 03xx 04xx 05xx 06xx 07xx 08xx 09xx 10xx 11xx 12xx 13xx\nBibTeX index\nMC Reports\nOther documents\nTranscriptions\nVideo and Audio\nExternal links\nIn addition, Dijkstra was intensely interested in teaching, and in the relationships between academic computing science and the software industry. During his forty-plus years as a computing scientist, which included positions in both academia and industry, Dijkstra\u2019s contributions brought him many prizes and awards, including computing science\u2019s highest honor, the ACM Turing Award.",
    "During his forty-plus years as a computing scientist, which included positions in both academia and industry, Dijkstra\u2019s contributions brought him many prizes and awards, including computing science\u2019s highest honor, the ACM Turing Award. Like most of us, Dijkstra always believed it a scientist\u2019s duty to maintain a lively correspondence with his scientific colleagues. To a greater extent than most of us, he put that conviction into practice. For over four decades, he mailed copies of his consecutively numbered technical notes, trip reports, insightful observations, and pungent commentaries, known collectively as \u201cEWDs\u201d, to several dozen recipients in academia and industry. Thanks to the ubiquity of the photocopier and the wide interest in Dijkstra\u2019s writings, the informal circulation of many of the EWDs eventually reached into the thousands.",
    "Thanks to the ubiquity of the photocopier and the wide interest in Dijkstra\u2019s writings, the informal circulation of many of the EWDs eventually reached into the thousands. Although most of Dijkstra\u2019s publications began life as EWD manuscripts, the great majority of his manuscripts remain unpublished. They have been inaccessible to many potential readers, and those who have received copies have been unable to cite them in their own work. To alleviate both of these problems, the department has collected over a thousand of the manuscripts in this permanent web site, in the form of PDF bitmap documents (to read them, you\u2019ll need a copy of Acrobat Reader). We hope you will find it convenient, useful, inspiring, and enjoyable. The original manuscripts, along with diaries, correspondence, photographs, and other papers, are housed at The Center for American History of The University of Texas at Austin. Each manuscript file is accessible through either of two indexes:\n0. BibTeX index. Each entry includes all the available bibliographic data. 1. Ad-hoc indexes. These contain titles only, but are faster if you know what you\u2019re looking for.",
    "These contain titles only, but are faster if you know what you\u2019re looking for. 0. BibTeX index. Each entry includes all the available bibliographic data. 1. Ad-hoc indexes. These contain titles only, but are faster if you know what you\u2019re looking for. EWD-numbered documents (This index gives an approximate correspondence between manuscripts\u2019 EWD numbers and the year in which they appeared.) Technical reports from the Mathematical Centre (now CWI: Centrum voor Wiskunde en Informatica) PhD thesis (5.3 MB) Other documents\nEWD-numbered documents (This index gives an approximate correspondence between manuscripts\u2019 EWD numbers and the year in which they appeared.) Technical reports from the Mathematical Centre (now CWI: Centrum voor Wiskunde en Informatica)\nPhD thesis (5.3 MB)\nYou can find a table relating EWD numbers to publication years here. Many of the privately circulated manuscripts collected here were subsequently published; their copyrights are held by their respective publishers.",
    "Many of the privately circulated manuscripts collected here were subsequently published; their copyrights are held by their respective publishers. Many of the privately circulated manuscripts collected here were subsequently published; their copyrights are held by their respective publishers. A growing number of the PDF bitmap documents have been transcribed to make them searchable and accessible to visitors who are visually impaired. A few of the manuscripts written in Dutch have been translated into English, and one \u2014EWD1036\u2014 has been translated into Spanish. EWD28 has been translated from English into Russian. For these transcriptions and translations we are grateful to over sixty contributors. Volunteers willing to transcribe manuscripts are always welcome (Note: doing EWDs justice in translation has turned out to be too difficult, so we are no longer soliciting translations).",
    "Volunteers willing to transcribe manuscripts are always welcome (Note: doing EWDs justice in translation has turned out to be too difficult, so we are no longer soliciting translations). Proofreading Each transcription gets a cursory scan as it\u2019s prepared for uploading, but since a web page can always be updated, I don\u2019t strive for (unattainable) perfection before installing it. On the web, proofreading is a game that can be played by every reader; if you spot an error, please\nA compilation of cross-references has been contributed by Diethard Michaelis. As its author notes, the collection is incomplete, and all readers are invited to add to it. Dijkstra often returned to topics about which he had already written, when he had something new to say or even just a better way of saying it. When Dijkstra himself didn\u2019t provide the backward references, we indicate the relationship by \"see also\" links in the index, leaving the judgment of the extent to which the earlier EWD is superseded by the later one to the reader. Any reader who notices such a relationship is invited to",
    "Any reader who notices such a relationship is invited to We have begun adding summaries of the EWDs. This innovation was suggested by G\u00fcnter Rote, who contributed the first dozen summaries. Additional contributions of summaries\u2014especially summaries in English of EWDs in Dutch\u2014are most welcome. Copyrights in most EWDs are held by his children, one of whom \u2014 \u2014 handles requests for permission to publish reproductions. The exceptions are documents that were published, and whose copyrights are held by their publishers; those documents are listed here, and each one is provided with a cover page identifying the copyright holder. Because the original manuscripts are in possession of the Briscoe Center for American History at The University of Texas, the Center\u2019s policies are also applicable. In addition to the manuscripts, you may enjoy some recordings of Dijkstra lectures and interviews.",
    "In addition to the manuscripts, you may enjoy some recordings of Dijkstra lectures and interviews. In addition to the manuscripts, you may enjoy some recordings of Dijkstra lectures and interviews. An interview with Dijkstra (Spanish translation here) was conducted in 1985 by Rogier F. van Vlissingen, who has also written a personal reflection on \u201cDijkstra\u2019s sense of what computer science and programming are and what they aren\u2019t.\u201d\nAnother interview was conducted by Philip L. Frana in August 2001. A transcript is available in the on-line collection of the Charles Babbage Institute.",
    "A transcript is available in the on-line collection of the Charles Babbage Institute. Another interview was conducted by Philip L. Frana in August 2001. A transcript is available in the on-line collection of the Charles Babbage Institute. To mark the occasion of Dijkstra\u2019s retirement in November 1999 from the Schlumberger Centennial Chair in Computer Sciences, which he had occupied since 1984, and to celebrate his forty-plus years of seminal contributions to computing science, the Department of Computer Sciences organized a symposium, In Pursuit of Simplicity, which took place on his birthday in May 2000. The symposium\u2019s program (10 MB) contains an outline of Dijkstra\u2019s career, as well as a collection of quotes culled from his writings, from his blackboard, and from what others have said about him. Banquet speeches by David Gries, Fred Schneider, Krzysztof Apt, W.M. Turski, and H. Richards were recorded on a video. Dijkstra\u2019s death in August 2002 was marked by many obituaries and memorials, including the Computer Sciences department\u2019s memorial celebration.",
    "Dijkstra\u2019s death in August 2002 was marked by many obituaries and memorials, including the Computer Sciences department\u2019s memorial celebration. Dijkstra\u2019s death in August 2002 was marked by many obituaries and memorials, including the Computer Sciences department\u2019s memorial celebration. A remembrance of Dijkstra was posted in May 2008 by Maarten van Emden (thanks to Tristram Brelstaff for noting it). In 2021 Krzysztof R. Apt and Tony Hoare edited a commemoration of Edsger Dijkstra written by more than twenty computer scientists who knew him as a colleague, teacher, and friend. A blog devoted to Dijkstra\u2019s works and thoughts has been created, and is being maintained, by the historian of computing Edgar G. Daylight. An article by Daylight, \u201cDijkstra\u2019s Rallying Cry for Generalization: the Advent of the Recursive Procedure, late 1950s - early 1960s,\u201d appeared in The Computer Journal, March 2011.",
    "An article by Daylight, \u201cDijkstra\u2019s Rallying Cry for Generalization: the Advent of the Recursive Procedure, late 1950s - early 1960s,\u201d appeared in The Computer Journal, March 2011. In his blog A Programmer\u2019s Place, Maarten van Emden has an entry entitled \u201cAnother scoop by Dijkstra?\u201d. The entry describes Dijkstra\u2019s \u201cremarkable insight [in \u201cNotes on Structured Programming\u201d (EWD 249)] that resolves the stand-off between the Sieve of Eratosthenes (efficient in terms of time, but not memory) and the method of Trial Division (efficient in terms of memory, but not time)\u201d by applying the Assembly-line Principle. The Edsger W. Dijkstra Prize in Distributed Computing honors Dijkstra\u2019s \u201cfoundational work on concurrency primitives (such as the semaphore), concurrency problems (such as mutual exclusion and deadlock), reasoning about concurrent systems, and self-stabilization [, which] comprises one of the most important supports upon which the field of distributed computing is built.\u201d\nA series of annual lectures in memory of Dijkstra commenced at The University of Texas in October 2010.",
    "The Edsger W. Dijkstra Prize in Distributed Computing honors Dijkstra\u2019s \u201cfoundational work on concurrency primitives (such as the semaphore), concurrency problems (such as mutual exclusion and deadlock), reasoning about concurrent systems, and self-stabilization [, which] comprises one of the most important supports upon which the field of distributed computing is built.\u201d\nA series of annual lectures in memory of Dijkstra commenced at The University of Texas in October 2010. A series of annual lectures in memory of Dijkstra commenced at The University of Texas in October 2010. Recent significant changes in the site are listed here; the most recent change was posted on 30 March 2021. The folks who contributed most significantly to the site\u2019s creation are acknowledged here. Comments and suggestions about the site are always welcome; please email them to the\nIf you find this site interesting, you may also be interested in another site:\nDiscipline in Thought which is a website dedicated to disciplined thinking, calculational mathematics, and mathematical methodology. The members of this site are markedly influenced by the works of EWD, and the material shared through the website continues in the traditions set by EWD (among others). Revised 2020-01-12",
    "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology",
    "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology How I spent two decades tracking down the creators of a 1987 USENET game and learned modern packaging tools in the process. The Discovery: A Digital Time Capsule from 1987\nPicture this: October 26, 1987. The Berlin Wall still stands, the World Wide Web is just text, and software is distributed through USENET newsgroups in text files split across multiple posts. On that day, Edward Barlow posted something special to comp.sources.games\n:\n\u201cconquest \u2013 middle earth multi-player game, Part01/05\u201d\nThat\u2019s how Ed Barlow announced it at the time, before quickly changed the name to Conquer. This was Conquer \u2013 a sophisticated multi-player strategy game that would influence countless others. Players controlled nations in Middle Earth, managing resources, armies, magic systems, and diplomatic relations. What made it remarkable wasn\u2019t just the gameplay, but how it was built and distributed in an era when \u201copen source\u201d wasn\u2019t even a term yet. Chapter 0: University Days.",
    "Chapter 0: University Days. Chapter 0: University Days. It was during these days, in the middle of the 90s, that my fellow students and I spent hours experimenting with terminals in the Computer Unix Labs, USENET, links, news, msgs, and of course: conquer. That game was a gem that required to be the leader of a country, and with a map representing as characters each player could control their elven kingdom, orcish empire, or human armies to fight each other while controlling all the details of the economy. But by 2006, this piece of computing history was trapped in legal limbo. Chapter 1: The Quest Begins (2006)\nAs a university student in Spain in the early \u201990s, I\u2019d encountered Conquer in the Unix labs. Fast forward to 2006, and I realized this pioneering game was at risk of being lost forever. The source code existed, scattered across ancient USENET archives, but its licensing was unclear \u2013 typical of the \u201cpost it and see what happens\u201d era of early internet software distribution.",
    "The source code existed, scattered across ancient USENET archives, but its licensing was unclear \u2013 typical of the \u201cpost it and see what happens\u201d era of early internet software distribution. I started what I thought would be a simple project: get permission from the original authors to relicense the code under GPL so it could be properly preserved and packaged for modern Linux distributions. Simple, right? Chapter 2: Digital Detective Work\nFinding Edward Barlow and Adam Bryant in 2006 was like archaeological work. Email addresses from the 1980s were long dead. USENET posts provided few clues. I scoured old university directories, googled fragments of names, and followed digital breadcrumbs across decades-old forums. The breakthrough came through pure persistence and a bit of luck. After months of searching, I managed to contact Ed Barlow. His response was refreshingly casual: \u201cYes i delegated it all to adam aeons ago. Im easy on it all\u2026. copyleft didnt exist when i wrote it and it was all for fun so\u2026\u201d\nBut there was a catch \u2013 I needed permission from Adam Bryant too, and he seemed to have vanished into the digital ether. Chapter 3: The Long Wait (2006-2011)",
    "Chapter 3: The Long Wait (2006-2011) But there was a catch \u2013 I needed permission from Adam Bryant too, and he seemed to have vanished into the digital ether. Chapter 3: The Long Wait (2006-2011)\nI documented everything on the Debian Legal mailing lists, created a GNU Savannah task (#5945), and even wrote blog posts hoping Adam would find them. The legal experts were clear: I needed explicit written permission from both copyright holders. Years passed. The project stalled. Then, on February 23, 2011, something magical happened. My phone buzzed with a contact form submission:\n\u201cI heard news of the request to release the code. I grant permission to release the code under GPL.\u201d \u2013 Adam Bryant\nHe had found one of my articles online and reached out on his own. Chapter 4: The Plot Twist \u2013 Version 5 Emerges (2025)",
    "Chapter 4: The Plot Twist \u2013 Version 5 Emerges (2025) He had found one of my articles online and reached out on his own. Chapter 4: The Plot Twist \u2013 Version 5 Emerges (2025)\nFast forward to 2025, and Stephen Smoogen contacts me about my relicesing efforts in 2006 and how he was particularly interested in reviving: Conquer Version 5 \u2013 a complete rewrite by Adam with advanced features like automatic data conversion, enhanced stability, and sophisticated administrative tools. This wasn\u2019t just an update; it was a complete reimagining of the game. But V5 had a different legal history. In the \u201990s, there had been commercial arrangements. Would Adam agree to GPL this version too? His response: \u201cI have no issues with applying a new GPL license to Version 5 as well.\u201d\nChapter 5: The Missing Piece \u2013 PostScript Magic",
    "His response: \u201cI have no issues with applying a new GPL license to Version 5 as well.\u201d\nChapter 5: The Missing Piece \u2013 PostScript Magic His response: \u201cI have no issues with applying a new GPL license to Version 5 as well.\u201d\nChapter 5: The Missing Piece \u2013 PostScript Magic\nJust when I thought the story was complete, I discovered another contributor: MaF, who had created PostScript utilities for generating printable game maps \u2013 a crucial feature in the pre-GUI era when players needed physical printouts to strategize. Tracking down MaF in 2025 led me to his company, where he\u2019s now Director of Product Security. His response: \u201cOh, that was a long time ago. But yes, that was me. And I have no problem with relicensing it to GPL.\u201d\nRichard Caley: More Than Just a Legal Footnote\nBut not all searches end with an answer. Some end with silence. My investigation of Richard Caley followed the same digital breadcrumbs. I traced him to the University of Edinburgh, where he worked on speech synthesis. I found his technical contributions to FreeBSD. But the trail went cold around 2005.",
    "But the trail went cold around 2005. Then I found him \u2013 not in a USENET archive, but on the front page of his own website, preserved exactly as he left it in web.archive.org. \u201cRichard Caley suffered a fatal heart attack on the 22nd of April, 2005. He was only 41, but had been an undiagnosed diabetic, probably for some considerable time. His web pages remain as he left them.\u201d\nReading those words felt different from finding a historical record. This wasn\u2019t archival research \u2013 this was walking into someone\u2019s house years after they\u2019d gone and finding a note on the table. The page continued:\n\u201cOver and above his tremendous ability with computers and programming, Richard had a keen mind and knowledge of an extraordinary range of topics, both of which he used in frequent contributions to on-line discussions. Despite his unique approach to speling, his prolific contributions to various news group debates informed and amused many over the years.\u201d\nThe \u201cCaleyisms\u201d \u2013 The Man Behind the Code",
    "Despite his unique approach to speling, his prolific contributions to various news group debates informed and amused many over the years.\u201d\nThe \u201cCaleyisms\u201d \u2013 The Man Behind the Code The \u201cCaleyisms\u201d \u2013 The Man Behind the Code\nAnd then I discovered his \u201cCaleyisms\u201d \u2013 a curated collection of his most brilliant USENET responses that revealed not just a programmer, but a person:\nWhat\u2019s a shell suit? \u201cOil company executive.\u201d\nHow do you prepare for a pyroclastic flow hitting Edinburgh? \u201cHang 1000 battered Mars bars on strings and stand back?\u201d\nOn his book addiction:\n\u201cI never got the hang of libraries, they keep wanting the things back and get upset when they need a crowbar to force it out of my hands.\u201d\nHis humor was dry, intelligent, and uniquely British. In technical discussions, he could be brutally precise:\n\u201cLack of proper punctuation, spacing, line breaks, capitalisation etc. is like bad handwriting, it doesn\u2019t make it impossible to read what was written, just harder. But you probably write in green crayon anyway.\u201d\nA Digital Office Preserved",
    "But you probably write in green crayon anyway.\u201d\nA Digital Office Preserved A Digital Office Preserved\nExploring his preserved website felt like walking through his digital office. The directory structure revealed his passions: FreeBSD how-tos, POVRAY experiments, wallpaper images, technical projects. His self-deprecating humor shone through in his \u201cAbout\u201d section:\n\u201cThankfully I don\u2019t have a photograph to inflict on you. Just use the picture of Iman Bowie to the left and then imagine someone who looks exactly the opposite in every possible way. This probably explains why she is married to David Bowie and I\u2019m not.\u201d\nHere was a complete person \u2013 technical director at Interactive Information Ltd, speech synthesis researcher, FreeBSD enthusiast, Kate Bush fan, and a wit who brightened countless online discussions. The legal reality was harsh: Richard\u2019s contributions to Conquer couldn\u2019t be relicensed. The university couldn\u2019t help contact heirs due to privacy laws. His friends had preserved his memory with a simple ASCII tribute at the end of his page:\n^_^\n(O O)",
    "His friends had preserved his memory with a simple ASCII tribute at the end of his page:\n^_^\n(O O) His friends had preserved his memory with a simple ASCII tribute at the end of his page:\n^_^\n(O O)\n\\_/@@\\\n\\\\~~/\n~~\n- RJC RIP\nIn the Conquer project documentation, Richard Caley isn\u2019t remembered as a \u201cproblem case\u201d or \u201cunlicensable code.\u201d He\u2019s honored as the vibrant person he was \u2013 the brilliant mind behind the \u201cCaleyisms,\u201d the researcher who contributed to speech synthesis, the FreeBSD advocate, and the witty participant in early online communities whose words continue to amuse and inform, decades after he wrote them. Chapter 6: Modern Renaissance \u2013 Enter GitHub, CICD and Modern Distributions\nHere\u2019s where the story gets really interesting. While working on preserving these Unix classics, I decided to learn modern packaging techniques. I chose to implement both APK (Alpine Linux) and Debian packaging for the games.",
    "I chose to implement both APK (Alpine Linux) and Debian packaging for the games. For APK packages, I used Melange \u2013 a sophisticated build system that creates provenance-tracked, reproducible packages for the Wolfi \u201cundistro\u201d. The irony? I discovered this tool when some friend started to work for the company that created it. Chapter 7: The Technical Journey: From USENET to Modern CI/CD\nThe transformation has been remarkable:\n1987 Original:\n- Distributed as split USENET posts\n- Manual compilation with system-specific Makefiles\n- No version control or automated testing\n2025 Revival:\n# Modern CI/CD with GitHub Actions\n- name: Build APK package\nrun: melange build conquer.yaml\n- name: Build Debian package\nrun: dpkg-buildpackage -b\nKey Modern Additions:\n- GPLv3 relicensing\n- Make building system modernization\n- C Codebase partially updated to support modern ANSI C99 specification\n- Debian packaging\n- APK packaging with Melange\nYou can see the complete transformation in the repositories:\n- Conquer v4 \u2013 The original classic\n- Conquer v5 \u2013 The advanced rewrite",
    "Chapter 7: The Technical Journey: From USENET to Modern CI/CD\nThe transformation has been remarkable:\n1987 Original:\n- Distributed as split USENET posts\n- Manual compilation with system-specific Makefiles\n- No version control or automated testing\n2025 Revival:\n# Modern CI/CD with GitHub Actions\n- name: Build APK package\nrun: melange build conquer.yaml\n- name: Build Debian package\nrun: dpkg-buildpackage -b\nKey Modern Additions:\n- GPLv3 relicensing\n- Make building system modernization\n- C Codebase partially updated to support modern ANSI C99 specification\n- Debian packaging\n- APK packaging with Melange\nYou can see the complete transformation in the repositories:\n- Conquer v4 \u2013 The original classic\n- Conquer v5 \u2013 The advanced rewrite - Debian packaging\n- APK packaging with Melange\nYou can see the complete transformation in the repositories:\n- Conquer v4 \u2013 The original classic\n- Conquer v5 \u2013 The advanced rewrite\nOriginal Conquer v4 code, by Ed Barlow and Adam Bryant\n(Conquer running in docker container alongside Apache, Curses to WebSockets output thanks to ttyd. Now we can play through the web!) Conquer Version 5 \u2013 The evolution of the classical Conquer, by Adam Bryant\nChapter 8: The Human Element: Why This Matters\nThis isn\u2019t just about preserving old games \u2013 it\u2019s about preserving the story of computing itself. Ed Barlow and Adam Bryant were pioneers who built sophisticated multiplayer experiences when most people had never heard of the internet. They distributed software through USENET because that\u2019s what you did \u2013 you shared cool things with the community.",
    "They distributed software through USENET because that\u2019s what you did \u2013 you shared cool things with the community. Martin Forssen\u2019s PostScript utilities represent the ingenuity of early developers who solved problems with whatever tools were available. Want to visualize your game state? Write a PostScript generator! The 20-year relicensing effort demonstrates something crucial about open source: it\u2019s not just about code, it\u2019s about community and continuity. Every time someone maintains a legacy project, documents its history, or tracks down long-lost contributors, they\u2019re weaving the threads that connect computing\u2019s past to its future. Lessons for Modern Developers\n- Document everything: Those casual USENET posts became crucial legal evidence decades later\n- License clearly: Ed\u2019s comment that \u201ccopyleft didnt exist when i wrote it\u201d highlights how licensing landscapes evolve\n- Community matters: Adam found my articles because the community was talking about preservation\n- Technical debt is temporal: What seems like legacy tech today might be tomorrow\u2019s archaeological treasure",
    "Lessons for Modern Developers\n- Document everything: Those casual USENET posts became crucial legal evidence decades later\n- License clearly: Ed\u2019s comment that \u201ccopyleft didnt exist when i wrote it\u201d highlights how licensing landscapes evolve\n- Community matters: Adam found my articles because the community was talking about preservation\n- Technical debt is temporal: What seems like legacy tech today might be tomorrow\u2019s archaeological treasure - Technical debt is temporal: What seems like legacy tech today might be tomorrow\u2019s archaeological treasure\n- Modern tools can revive ancient code: Melange and modern CI/CD gave 1987 software a 2025 renaissance\nThe Continuing Story\nBoth Conquer games are now fully GPL v3 licensed and available with modern packaging. They represent not just playable software, but a complete case study in software archaeology, legal frameworks for preservation, and the evolution of development practices across four decades. The next chapter? Teaching these classic strategy games to a new generation of developers and gamers, while demonstrating that proper legal frameworks and modern tooling can give any historical software a second life. Sometimes the best way to learn cutting-edge technology is by applying it to preserve computing history. What historical software deserves preservation in your field? Have you ever traced the lineage of code back to its original creators?",
    "Have you ever traced the lineage of code back to its original creators? What historical software deserves preservation in your field? Have you ever traced the lineage of code back to its original creators? #FreeSoftware #OpenSource #SoftwarePreservation #Unix #GNU #Linux #Packaging #Melange #TechHistory #GameDevelopment #Unix #USENET #GPL #FST #Debian #ncurses #terminal #shell\nRead this article in Spanish / Lee este art\u00edculo en espa\u00f1ol:\nhttps://vejeta.com/conquer-una-odisea-de-20-anos-en-arqueologia-digital/\nThis article was originally written in both English and Spanish, with additional insights and cultural context in the Spanish version.",
    "Visualize FastAPI endpoints with FastAPI-Voyager\n\nLoading\u2026\nFastAPI Voyager\n{{ state.version }}\nscroll to zoom in/out\ndouble click node to view details. shift + click to see schema's dependencies without unrelated nodes. {{ tag.name }}\n{{ tag.routes.length }}\n{{ route.name }}\nNo routes\n{{ dumpJson }}\nImport core data JSON",
    "Email verification protocol",
    "Email verification protocol Verifying control of an email address is a frequent activity on the web today and is used both to prove the user has provided a valid email address, and as a means of authenticating the user when returning to an application. Verification is performed by either:\n-\nSending the user a link they click on or a verification code. This requires the user to switch from the application they are using to their email address and having to wait for the email arrive, and then perform the verification action. This friction often causes drop off in users completing the task. There are privacy implications as the email transmission informs the mail service the applications the user is using and when they used them. -",
    "- -\nThe user logs in with a social login provider such as Apple or Google that provide a verified email address. This requires the application to have set up a relationship with each social provider, and the user to be using one of those services and wanting to share the additional profile information that is also provided in the OpenID Connect flow. The Email Verification Protocol enables a web application to obtain a verified email address without sending an email, and without the user leaving the web page they are on. To enable the functionality, the mail domain delegates email verification to an issuer that has authentication cookies for the user. When the user provides an email to the HTML form field, the browser calls the issuer passing authentication cookies, the issuer returns a token, which the browser verifies and updates and provides to the web application. The web application then verifies the token and has a verified email address for the user.",
    "The web application then verifies the token and has a verified email address for the user. User privacy is enhanced as the issuer does not learn which web application is making the request as the request is mediated by the browser. -\nSD-JWT+KB token: The selective disclosure json web token with key binding is specified in Selective Disclosure for JWT. This protocol does not use the selective disclosure features, it uses the key binding feature which enables a separation of token issuance and token presentation. The SD-JWT+KB is a token composed of two JWTs separated by the\n~\ncharacter. The first JWT is an SD-JWT aka the issuance token and is signed by the issuer and contains theemail\nandemail_verified\nclaims for the user, and the public key used by the browser to make the request. The second JWT is a KB token and is signed by the browser and contains a hash of the first JWT. The resulting SD-JWT+KB is the presentation token, and enables the application to verify the issuer provided the email address for the user without the issuer learning about the specific application -",
    "The resulting SD-JWT+KB is the presentation token, and enables the application to verify the issuer provided the email address for the user without the issuer learning about the specific application - Issuer: The service that verifies the user controls an email address. A DNS record for the email domain delegates email verification to the issuer. The issuer serves a\n.well-known/email-verification\nmetadata file that contains itsissuance_endpoint\nthat is called to obtain an issuance token, and itsjwks_uri\nthat points to the JWKS file containing the public keys used to verify the SD-JWT. The issuer is identified by its domain, an eTLD+1 (egissuer.example\n). The hostname in all URLs from the issuer's metadata MUST end with the issuer's domain. This identifier is what binds the SD-JWT, the DNS delegation, with the issuer.",
    "This identifier is what binds the SD-JWT, the DNS delegation, with the issuer. ). The hostname in all URLs from the issuer's metadata MUST end with the issuer's domain. This identifier is what binds the SD-JWT, the DNS delegation, with the issuer. Verified Email Release: The user navigates to any website that requires a verified email address and an input field to enter the email address. The user focusses on the input field and the browser provides one or emails for the user to select based on emails the user has provided previously to the browser. The user selects a verified email and the app proceeds having obtained the verified email. Are emails that can be verified decorated by the browser in the autocomplete UI? What UX is presented to the user when the app gets a verified email so the user knows it is already verified? sequenceDiagram\nparticipant U as User\nparticipant B as Browser\nparticipant RP as RP Page\nparticipant RPS as RP Server\nparticipant I as Issuer\nparticipant DNS as DNS\nNote over U,DNS: Step 1: Email Request\nU->>RP: Navigate to site",
    "sequenceDiagram\nparticipant U as User\nparticipant B as Browser\nparticipant RP as RP Page\nparticipant RPS as RP Server\nparticipant I as Issuer\nparticipant DNS as DNS\nNote over U,DNS: Step 1: Email Request\nU->>RP: Navigate to site participant B as Browser\nparticipant RP as RP Page\nparticipant RPS as RP Server\nparticipant I as Issuer\nparticipant DNS as DNS\nNote over U,DNS: Step 1: Email Request\nU->>RP: Navigate to site\nRP->>RPS: Nonce request\nRPS->>RPS: Generate nonce, bind to session\nRPS->>RP: Nonce\nRP->>B: Display page\nNote over U,DNS: Step 2: Email Selection\nU->>RP: Focus on email input field\nRP->>B: Input field focused\nB->>U: Display email address list\nU->>B: Select email address\nNote over U,DNS: Step 3: Token Request\nB->>DNS: DNS TXT lookup<br/>_email-verification.$EMAIL_DOMAIN\nDNS->>B: Return iss=issuer.example\nB->>I: GET /.well-known/email-verification\nI->>B: Return metadata\nB->>B: Generate key pair<br/>Create request token\nB->>I: POST request_token=JWT... Note over U,DNS: Step 4: Token Issuance\nI->>I: Verify request\nI->>I: Generate SD-JWT\nI->>B: {\"issuance_token\":\"SD-JWT\"}\nNote over U,DNS: Step 5: Token Presentation\nB->>B: Verify SD-JWT\nB->>I: GET jwks_uri for public keys\nI->>B: Return JWKS",
    "Note over U,DNS: Step 4: Token Issuance\nI->>I: Verify request\nI->>I: Generate SD-JWT\nI->>B: {\"issuance_token\":\"SD-JWT\"}\nNote over U,DNS: Step 5: Token Presentation\nB->>B: Verify SD-JWT\nB->>I: GET jwks_uri for public keys\nI->>B: Return JWKS I->>I: Verify request\nI->>I: Generate SD-JWT\nI->>B: {\"issuance_token\":\"SD-JWT\"}\nNote over U,DNS: Step 5: Token Presentation\nB->>B: Verify SD-JWT\nB->>I: GET jwks_uri for public keys\nI->>B: Return JWKS\nB->>B: Create KB\nB->>RP: Provide SD-JWT+KB\nNote over U,DNS: Step 6: Token Verification\nRP->>RPS: Send SD-JWT+KB\nRPS->>RPS: Parse SD-JWT+KB\nRPS->>DNS: DNS TXT lookup for email domain\nDNS->>RPS: Return iss=issuer.example\nRPS->>I: GET /.well-known/email-verification\nI->>RPS: Return metadata with jwks_uri\nRPS->>I: GET jwks_uri\nI->>RPS: Return JWKS public keys\nRPS->>RPS: Verify SD-JWT\nRPS->>RPS: Verify KB-JWT\nRPS->>RP: Email verification complete\nUser navigates to a site that will act as the RP. -\n1.1 - the RP Server generates a nonce and binds the nonce to the session. -\n1.2 - the RP Server returns a page that has an input field with the\nautocomplete\nproperty set to\"email\"\nand thenonce\nproperty set the the nonce. If the browser receives anissuance_token",
    "If the browser receives anissuance_token -\n1.2 - the RP Server returns a page that has an input field with the\nautocomplete\nproperty set to\"email\"\nand thenonce\nproperty set the the nonce. If the browser receives anissuance_token\nper 4.4 below, then it sends aemailverifed\nevent that has apresentationToken\nproperty. Following is an example of the HTML in the page:\n<input id=\"email\"\ntype=\"email\"\nautocomplete=\"email\"\nnonce=\"12345677890..random\">\n<script>\nconst input = document.getElementById('email')\ninput.addEventListener('emailverified', e => {\n// e.presentationToken is SD-JWT+KB\nconsole.log({\npresentationToken: e.presentationToken\n})\n})\n</script>\nAuthors are exploring alternative HTML and JS API approaches\n-\n2.1 - User focusses on email input field\n-\n2.2 - The browser displays the list of email addresses it has for the user. Q: Are emails that could be verified decorated for user to understand? - 2.3 - User selects an email address from browser selection, or the user types an email into the field.",
    "- 2.3 - User selects an email address from browser selection, or the user types an email into the field. Q: Are emails that could be verified decorated for user to understand? - 2.3 - User selects an email address from browser selection, or the user types an email into the field. Future: allow user to type in a field so we learn about new emails, or if the user does not want the browser to remember emails, the Email Verification Protocol is still available. In the future when we allow the user to use a passkey to authenticate to the issuer, the user can provide a verified email to a web application using a public computer by authenticating with their passkey and not enter any secrets into the public computer. If the RP has performed (1):\n- 3.1 - the browser parses the email domain ($EMAIL_DOMAIN) from the email address, looks up the\nTXT\nrecord for_email-verification.$EMAIL_DOMAIN\n. The contents of the record MUST start withiss=\nfollowed by the issuer identifier. There MUST be only oneTXT\nrecord for_email-verification.$EMAIL_DOMAIN\n. example record",
    "example record . The contents of the record MUST start withiss=\nfollowed by the issuer identifier. There MUST be only oneTXT\nrecord for_email-verification.$EMAIL_DOMAIN\n. example record\n_email-verification.email-domain.example TXT iss=issuer.example\nThis record states that email-domain.example\nhas delegated email verification to the issuer issuer.example\n. If the email domain and the issuer are the same domain, then the record would be:\n_email-verification.issuer.example TXT iss=issuer.example\nAccess to DNS records and email is often independent of website deployments. This provides assurance that an issuer is truly authorized as an insider with only access to websites on\nissuer.example\ncould setup an issuer that would grant them verified emails for any email atissuer.example\n. - 3.2 - if an issuer is found, the browser loads\nhttps://$ISSUER$/.well-known/email-verification\nand MUST follow redirects to the same path but with a different subdomain of the Issuer.",
    "- 3.2 - if an issuer is found, the browser loads\nhttps://$ISSUER$/.well-known/email-verification\nand MUST follow redirects to the same path but with a different subdomain of the Issuer. . - 3.2 - if an issuer is found, the browser loads\nhttps://$ISSUER$/.well-known/email-verification\nand MUST follow redirects to the same path but with a different subdomain of the Issuer. For example, https://issuer.example/.well-known/email-verification\nmay redirect to https://accounts.issuer.example/.well-known/email-verification\n. -\n3.3 - the browser confirms that the\n.well-known/email-verification\nfile contains JSON that includes the following properties: -\nissuance_endpoint - the API endpoint the browser calls to obtain an SD-JWT\n-\njwks_uri - the URL where the issuer provides its public keys to verify the SD-JWT\n-\nsigning_alg_values_supported - OPTIONAL. JSON array containing a list of the JWS signing algorithms (\"alg\" values) supported by both the browser for request tokens and the issuer for issued tokens. The same algorithm MUST be used for both the\nrequest_token\nandissuance",
    "The same algorithm MUST be used for both the\nrequest_token\nandissuance request_token\nandissuance\nwithin a single issuance flow. Algorithm identifiers MUST be from the IANA \"JSON Web Signature and Encryption Algorithms\" registry. If omitted, \"EdDSA\" is the default. \"EdDSA\" SHOULD be included in the supported algorithms list. The value \"none\" MUST NOT be used. Each of these properties MUST include the issuer domain as the root of their hostname. Following is an example .well-known/email-verification\nfile\n{\n\"issuance_endpoint\": \"https://accounts.issuer.example/email-verification/issuance\",\n\"jwks_uri\": \"https://accounts.issuer.example/email-verification/jwks\",\n\"signing_alg_values_supported\": [\"EdDSA\", \"RS256\"]\n}\n-\n3.4 - the browser generates a fresh private / public key and signs a JWT with the private key that has the public key in the JWT header in the JWK format as a\njwk\nclaim that contains the following claims in the payload:- aud - the issuer\n- iat - time when the JWT was signed\n- jti - unique identifier for the token",
    "Following is an example .well-known/email-verification\nfile\n{\n\"issuance_endpoint\": \"https://accounts.issuer.example/email-verification/issuance\",\n\"jwks_uri\": \"https://accounts.issuer.example/email-verification/jwks\",\n\"signing_alg_values_supported\": [\"EdDSA\", \"RS256\"]\n}\n-\n3.4 - the browser generates a fresh private / public key and signs a JWT with the private key that has the public key in the JWT header in the JWK format as a\njwk\nclaim that contains the following claims in the payload:- aud - the issuer\n- iat - time when the JWT was signed\n- jti - unique identifier for the token jwk\nclaim that contains the following claims in the payload:- aud - the issuer\n- iat - time when the JWT was signed\n- jti - unique identifier for the token\n- email - email address to be verified\nThe browser SHOULD select an algorithm from the issuer's signing_alg_values_supported\narray, or use \"EdDSA\" if the property is not present. An example JWT header:\n{\n\"alg\": \"EdDSA\",\n\"typ\": \"JWT\",\n\"jwk\": {\n\"kty\": \"OKP\",\n\"crv\": \"Ed25519\",\n\"x\": \"11qYAYdk9E6z7mT6rk6j1QnXb6pYq4v9wXb6pYq4v9w\" // base64url-encoded public key\n}\n}\ndo we want to register a new JWT\ntyp\nAn example payload\n{\n\"aud\": \"issuer.example\",\n\"iat\": 1692345600,\n\"email\": \"user@example.com\"\n}\n- 3.5 - the browser POSTs to the\nissuance_endpoint\nof the issuer with 1P cookies with a content-type ofapplication/x-www-form-urlencoded\ncontaining arequest_token\nparameter set to the signed JWT and theSec-Fetch-Dest\nheader set toemail-verification\n. POST /email-verification/issuance HTTP/1.1\nHost: accounts.issuer.example\nCookie: session=...",
    "POST /email-verification/issuance HTTP/1.1\nHost: accounts.issuer.example\nCookie: session=... parameter set to the signed JWT and theSec-Fetch-Dest\nheader set toemail-verification\n. POST /email-verification/issuance HTTP/1.1\nHost: accounts.issuer.example\nCookie: session=...\nContent-Type: application/x-www-form-urlencoded\nSec-Fetch-Dest: email-verification\nrequest_token=eyJhbGciOiJFZERTQSIsInR5cCI6IkpXVC...\nOn receipt of a token request:\n-\n4.1 - the issuer MUST verify the request headers:\nContent-Type\nisapplication/x-www-form-urlencoded\nSec-Fetch-Dest\nisemail-verification\n-\n4.2 - the issuer MUST verify the request_token by:\n- parsing the JWT into header, payload, and signature components\n- confirming the presence of, and extracting the\njwk\nandalg\nfields from the JWT header, and theaud\n,iat\n, andemail\n, claims from the payload - verifying the JWT signature using the\njwk\nwith thealg\nalgorithm - verifying the\naud\nclaim exactly matches the issuer's identifier - verifying the\niat\nclaim is within 60 seconds of the current time - verifying the\nemail",
    "POST /email-verification/issuance HTTP/1.1\nHost: accounts.issuer.example\nCookie: session=...\nContent-Type: application/x-www-form-urlencoded\nSec-Fetch-Dest: email-verification\nrequest_token=eyJhbGciOiJFZERTQSIsInR5cCI6IkpXVC...\nOn receipt of a token request:\n-\n4.1 - the issuer MUST verify the request headers:\nContent-Type\nisapplication/x-www-form-urlencoded\nSec-Fetch-Dest\nisemail-verification\n-\n4.2 - the issuer MUST verify the request_token by:\n- parsing the JWT into header, payload, and signature components\n- confirming the presence of, and extracting the\njwk\nandalg\nfields from the JWT header, and theaud\n,iat\n, andemail\n, claims from the payload - verifying the JWT signature using the\njwk\nwith thealg\nalgorithm - verifying the\naud\nclaim exactly matches the issuer's identifier - verifying the\niat\nclaim is within 60 seconds of the current time - verifying the\nemail jwk\nwith thealg\nalgorithm - verifying the\naud\nclaim exactly matches the issuer's identifier - verifying the\niat\nclaim is within 60 seconds of the current time - verifying the\nemail\nclaim contains a syntactically valid email address\n-\n4.3 - the issuer checks if the cookies sent represent a logged in user, and if the logged in user has control of the email provided in the request_token. If so the issuer generates an SD-JWT with the following properties:\n- Header: MUST contain\nalg\n: signing algorithm (SHOULD match the algorithm from the request_token)kid\n: key identifier of key used to signtyp\nset to \"evp+sd-jwt\"\n- Payload: MUST contain the following claims:\niss\n: the issuer identifieriat\n: issued at timecnf\n: confirmation claim containing the public key from the request_token'sjwk\nfieldemail\n: claim containing the email address from the request_tokenemail_verified\n: claim that email is verified per OpenID Connect 1.0",
    "If so the issuer generates an SD-JWT with the following properties:\n- Header: MUST contain\nalg\n: signing algorithm (SHOULD match the algorithm from the request_token)kid\n: key identifier of key used to signtyp\nset to \"evp+sd-jwt\"\n- Payload: MUST contain the following claims:\niss\n: the issuer identifieriat\n: issued at timecnf\n: confirmation claim containing the public key from the request_token'sjwk\nfieldemail\n: claim containing the email address from the request_tokenemail_verified\n: claim that email is verified per OpenID Connect 1.0 fieldemail\n: claim containing the email address from the request_tokenemail_verified\n: claim that email is verified per OpenID Connect 1.0\n- Signature: MUST be signed with the issuer's private key corresponding to a public key in the\njwks_uri\nidentified bykid\n- Header: MUST contain\nExample header:\n{\n\"alg\": \"EdDSA\",\n\"kid\": \"2024-08-19\",\n\"typ\": \"evp+sd-jwt\"\n}\nExample payload:\n{\n\"iss\": \"issuer.example\",\n\"iat\": 1724083200,\n\"cnf\": {\n\"jwk\": {\n\"kty\": \"OKP\",\n\"crv\": \"Ed25519\",\n\"x\": \"11qYAYdk9E6z7mT6rk6j1QnXb6pYq4v9wXb6pYq4v9w\"\n}\n},\n\"email\": \"user@example.com\",\n\"email_verified\": true\n}\nThe resulting JWT has the ~\nappended to it, making it a valid SD-JWT. - 4.4 - the issuer returns the SD-JWT to the browser as the value of\nissuance_token\nin anapplication/json\nresponse. Example:\nHTTP/1.1 200 OK\nContent-Type: application/json\n{\"issuance_token\":\"eyJhbGciOiJFZERTQSIsImtpZCI6IjIwMjQtMDgtMTkiLCJ0eXAiOiJ3ZWItaWRlbnRpdHkrc2Qtand0In0...\"}",
    "Example:\nHTTP/1.1 200 OK\nContent-Type: application/json\n{\"issuance_token\":\"eyJhbGciOiJFZERTQSIsImtpZCI6IjIwMjQtMDgtMTkiLCJ0eXAiOiJ3ZWItaWRlbnRpdHkrc2Qtand0In0...\"} in anapplication/json\nresponse. Example:\nHTTP/1.1 200 OK\nContent-Type: application/json\n{\"issuance_token\":\"eyJhbGciOiJFZERTQSIsImtpZCI6IjIwMjQtMDgtMTkiLCJ0eXAiOiJ3ZWItaWRlbnRpdHkrc2Qtand0In0...\"}\nIf the issuer cannot process the token request successfully, it MUST return an appropriate HTTP status code with a JSON error response containing an error\nfield and optionally an error_description\nfield. When the request does not include the required Content-Type: application/x-www-form-urlencoded\nheader, the server MUST return the 415 HTTP response code\nWhen the request does not include the required Sec-Fetch-Dest: email-verification\nheader:\nHTTP 400 Bad Request\n{\n\"error\": \"invalid-request\",\n\"error_description\": \"Missing or invalid Sec-Fetch-Dest header\"\n}\nThe error_description\nSHOULD specify that the Sec-Fetch-Dest header is missing or invalid.",
    "When the request does not include the required Content-Type: application/x-www-form-urlencoded\nheader, the server MUST return the 415 HTTP response code\nWhen the request does not include the required Sec-Fetch-Dest: email-verification\nheader:\nHTTP 400 Bad Request\n{\n\"error\": \"invalid-request\",\n\"error_description\": \"Missing or invalid Sec-Fetch-Dest header\"\n}\nThe error_description\nSHOULD specify that the Sec-Fetch-Dest header is missing or invalid. {\n\"error\": \"invalid-request\",\n\"error_description\": \"Missing or invalid Sec-Fetch-Dest header\"\n}\nThe error_description\nSHOULD specify that the Sec-Fetch-Dest header is missing or invalid. When the request lacks valid authentication cookies, contains expired/invalid cookies, or the authenticated user does not have control of the requested email address:\nHTTP 401 Unauthorized\n{\n\"error\": \"authentication_required\",\n\"error_description\": \"User must be authenticated and have control of the requested email address\"\n}\nWhen the request_token\nis malformed, missing required claims, or contains invalid values:\nHTTP 400 Bad Request\n{\n\"error\": \"invalid_request\",\n\"error_description\": \"Invalid or malformed request_token\"\n}\nWhen the request_token\nsignature verification fails or the token structure is invalid:\nHTTP 400 Bad Request\n{\n\"error\": \"invalid_token\",\n\"error_description\": \"Token signature verification failed or token structure is invalid\"\n}\nFor internal server errors or temporary unavailability:",
    "When the request lacks valid authentication cookies, contains expired/invalid cookies, or the authenticated user does not have control of the requested email address:\nHTTP 401 Unauthorized\n{\n\"error\": \"authentication_required\",\n\"error_description\": \"User must be authenticated and have control of the requested email address\"\n}\nWhen the request_token\nis malformed, missing required claims, or contains invalid values:\nHTTP 400 Bad Request\n{\n\"error\": \"invalid_request\",\n\"error_description\": \"Invalid or malformed request_token\"\n}\nWhen the request_token\nsignature verification fails or the token structure is invalid:\nHTTP 400 Bad Request\n{\n\"error\": \"invalid_token\",\n\"error_description\": \"Token signature verification failed or token structure is invalid\"\n}\nFor internal server errors or temporary unavailability: HTTP 400 Bad Request\n{\n\"error\": \"invalid_token\",\n\"error_description\": \"Token signature verification failed or token structure is invalid\"\n}\nFor internal server errors or temporary unavailability:\nHTTP 500 Internal Server Error\n{\n\"error\": \"server_error\",\n\"error_description\": \"Temporary server error, please try again later\"\n}\nIn a future version of this spec, the issuer could prompt the user to login via a URL or with a Passkey request. On receiving the issuance_token\n:\n-\n5.1 - the browser MUST verify the SD-JWT per (SD-JWT spec) by:\n- parsing the SD-JWT into header, payload, and signature components\n- confirming the presence of, and extracting the\nalg\nandkid\nfields from the SD-JWT header, and theiss\n,iat\n,cnf\n,email\n, andemail_verified\nclaims from the payload - parsing the email domain from the\nemail\nclaim and looking up theTXT\nrecord for_email-verification.$EMAIL_DOMAIN\nto verify theiss\nclaim matches the issuer identifier in the DNS record - fetching the issuer's public keys from the",
    "On receiving the issuance_token\n:\n-\n5.1 - the browser MUST verify the SD-JWT per (SD-JWT spec) by:\n- parsing the SD-JWT into header, payload, and signature components\n- confirming the presence of, and extracting the\nalg\nandkid\nfields from the SD-JWT header, and theiss\n,iat\n,cnf\n,email\n, andemail_verified\nclaims from the payload - parsing the email domain from the\nemail\nclaim and looking up theTXT\nrecord for_email-verification.$EMAIL_DOMAIN\nto verify theiss\nclaim matches the issuer identifier in the DNS record - fetching the issuer's public keys from the email\nclaim and looking up theTXT\nrecord for_email-verification.$EMAIL_DOMAIN\nto verify theiss\nclaim matches the issuer identifier in the DNS record - fetching the issuer's public keys from the\njwks_uri\nspecified in the.well-known/email-verification\nfile - verifying the SD-JWT signature using the public key identified by\nkid\nfrom the JWKS with thealg\nalgorithm - verifying the\niat\nclaim is within 60 seconds of the current time - verifying the\nemail\nclaim matches the email address the user selected - verifying the\nemail_verified\nclaim is true\n-\n5.2 - the browser then creates an SD-JWT+KB by:\n- taking the verified SD-JWT from step 5.1 as the base token\n- creating a Key Binding JWT (KB-JWT) with the following structure:\n- Header:\nalg\n: same signing algorithm used by the browser's private keytyp\n: \"kb+jwt\"\n- Payload:\naud\n: the RP's originnonce\n: the nonce from the originalnavigator.credentials.get()\ncalliat\n: current time when creating the KB-JWTsd_hash\n: SHA-256 hash of the SD-JWT",
    "email\nclaim and looking up theTXT\nrecord for_email-verification.$EMAIL_DOMAIN\nto verify theiss\nclaim matches the issuer identifier in the DNS record - fetching the issuer's public keys from the\njwks_uri\nspecified in the.well-known/email-verification\nfile - verifying the SD-JWT signature using the public key identified by\nkid\nfrom the JWKS with thealg\nalgorithm - verifying the\niat\nclaim is within 60 seconds of the current time - verifying the\nemail\nclaim matches the email address the user selected - verifying the\nemail_verified\nclaim is true\n-\n5.2 - the browser then creates an SD-JWT+KB by:\n- taking the verified SD-JWT from step 5.1 as the base token\n- creating a Key Binding JWT (KB-JWT) with the following structure:\n- Header:\nalg\n: same signing algorithm used by the browser's private keytyp\n: \"kb+jwt\"\n- Payload:\naud\n: the RP's originnonce\n: the nonce from the originalnavigator.credentials.get()\ncalliat\n: current time when creating the KB-JWTsd_hash\n: SHA-256 hash of the SD-JWT : \"kb+jwt\"\n- Payload:\naud\n: the RP's originnonce\n: the nonce from the originalnavigator.credentials.get()\ncalliat\n: current time when creating the KB-JWTsd_hash\n: SHA-256 hash of the SD-JWT\n- Header:\n- signing the KB-JWT with the browser's private key (the same key pair generated in step 3.4)\n- concatenating the SD-JWT and the KB-JWT separated by a tilde (~) to form the SD-JWT+KB\nExample KB-JWT header:\n{ \"alg\": \"EdDSA\", \"typ\": \"kb+jwt\" }\nExample KB-JWT payload:\n{ \"aud\": \"https://rp.example\", \"nonce\": \"259c5eae-486d-4b0f-b666-2a5b5ce1c925\", \"salt\": \"kR7fY9mP3xQ8wN2vL5jH6tZ1cB4nM9sD8fG3hJ7kL2p\", \"iat\": 1724083260, \"sd_hash\": \"X9yH0Ajrdm1Oij4tWso9UzzKJvPoDxwmuEcO3XAdRC0\" }\n-\n5.3 - the browser sets a TBD hidden field and fires the TBD event ...\ndetails TBD\nThe RP web page now has the SD-JWT+KB from the event, and passes it to the RP server, or the token was posted to the RP server. details TBD\nThe RP server MUST verify the SD-JWT+KB by:\n-",
    "details TBD\nThe RP server MUST verify the SD-JWT+KB by:\n- details TBD\nThe RP web page now has the SD-JWT+KB from the event, and passes it to the RP server, or the token was posted to the RP server. details TBD\nThe RP server MUST verify the SD-JWT+KB by:\n-\n6.1 - the RP server receives the SD-JWT+KB from the web page\n-\n6.2 - the RP parses the SD-JWT+KB by separating the SD-JWT and KB-JWT components (separated by tilde ~)\n-\n6.3 - the RP verifies the KB-JWT by:\n- parsing the KB-JWT into header, payload, and signature components\n- confirming the presence of, and extracting the\nalg\nfield from the KB-JWT header, and theaud\n,nonce\n,iat\n, andsd_hash\nclaims from the payload - verifying the\naud\nclaim matches the RP's origin - verifying the\nnonce\nclaim matches the nonce from the RP's session with the web page - verifying the\niat\nclaim is within a reasonable time window - computing the SHA-256 hash of the SD-JWT and verifying it matches the\nsd_hash\nclaim\n-\n6.4 - the RP verifies the SD-JWT by:",
    "details TBD\nThe RP server MUST verify the SD-JWT+KB by:\n-\n6.1 - the RP server receives the SD-JWT+KB from the web page\n-\n6.2 - the RP parses the SD-JWT+KB by separating the SD-JWT and KB-JWT components (separated by tilde ~)\n-\n6.3 - the RP verifies the KB-JWT by:\n- parsing the KB-JWT into header, payload, and signature components\n- confirming the presence of, and extracting the\nalg\nfield from the KB-JWT header, and theaud\n,nonce\n,iat\n, andsd_hash\nclaims from the payload - verifying the\naud\nclaim matches the RP's origin - verifying the\nnonce\nclaim matches the nonce from the RP's session with the web page - verifying the\niat\nclaim is within a reasonable time window - computing the SHA-256 hash of the SD-JWT and verifying it matches the\nsd_hash\nclaim\n-\n6.4 - the RP verifies the SD-JWT by: iat\nclaim is within a reasonable time window - computing the SHA-256 hash of the SD-JWT and verifying it matches the\nsd_hash\nclaim\n-\n6.4 - the RP verifies the SD-JWT by:\n- parsing the SD-JWT into header, payload, and signature components\n- confirming the presence of, and extracting the\nalg\nandkid\nfields from the SD-JWT header, and theiss\n,iat\n,cnf\n,email\n, andemail_verified\nclaims from the payload - parsing the email domain from the\nemail\nclaim and looking up theTXT\nrecord for_email-verification.$EMAIL_DOMAIN\nto verify theiss\nclaim matches the issuer identifier in the DNS record - fetching the issuer's public keys from the\njwks_uri\nspecified in the.well-known/email-verification\nfile - verifying the SD-JWT signature using the public key identified by\nkid\nfrom the JWKS with thealg\nalgorithm - verifying the\niss\nclaim exactly matches the issuer identifier from the DNS record - verifying the\niat\nclaim is within a reasonable time window - verifying the\nemail_verified\nclaim is true\n-",
    "iat\nclaim is within a reasonable time window - computing the SHA-256 hash of the SD-JWT and verifying it matches the\nsd_hash\nclaim\n-\n6.4 - the RP verifies the SD-JWT by:\n- parsing the SD-JWT into header, payload, and signature components\n- confirming the presence of, and extracting the\nalg\nandkid\nfields from the SD-JWT header, and theiss\n,iat\n,cnf\n,email\n, andemail_verified\nclaims from the payload - parsing the email domain from the\nemail\nclaim and looking up theTXT\nrecord for_email-verification.$EMAIL_DOMAIN\nto verify theiss\nclaim matches the issuer identifier in the DNS record - fetching the issuer's public keys from the\njwks_uri\nspecified in the.well-known/email-verification\nfile - verifying the SD-JWT signature using the public key identified by\nkid\nfrom the JWKS with thealg\nalgorithm - verifying the\niss\nclaim exactly matches the issuer identifier from the DNS record - verifying the\niat\nclaim is within a reasonable time window - verifying the\nemail_verified\nclaim is true\n- iss\nclaim exactly matches the issuer identifier from the DNS record - verifying the\niat\nclaim is within a reasonable time window - verifying the\nemail_verified\nclaim is true\n-\n6.5 - the RP verifies the KB-JWT signature using the public key from the\ncnf\nclaim in the SD-JWT with thealg\nalgorithm from the KB-JWT header\nBelow are notes capturing some discussions of potential privacy implications. -\nThe email domain operator no longer learns which applications the user is verifying their email address to as the applications are no longer sending an email verification code to the user. By using an SD-JWT+KB, the browser intermediates the request and response so that the issuer does not learn the identity of the RP. -\nThe RP can infer if a user is logged into the issuer as the RP receives a SD-JWT when the user is logged in, and does not when the user is not logged in. -\nThe issuer may learn the user has email at a mail domain it is authoritative for that it did not know the user had.",
    "-\nThe issuer may learn the user has email at a mail domain it is authoritative for that it did not know the user had. -\nThe issuer may learn the user has email at a mail domain it is authoritative for that it did not know the user had. The web page would call an API passing the email address and nonce. It would return a promise that resolves to the SD_JWT or an error response. The API would only be callable after a user gesture such as clicking a button labelled verify on the web page. This provides the web page in more flexibility in how to gather the email address. For example, if the web page is using EVP for login, and the user has used different emails for login and those are stored in cookies, the page can display the list of emails and an option to provide a different one. The user can then select the email they want to use rather than having to type it into a text field.",
    "The user can then select the email they want to use rather than having to type it into a text field. In addition to, or instead of the browser sending cookies to the Issuer, the Issuer could return a WebAuthN request to the browser if it has credentials for the user identified by the email address. The browser would then interact with the user and provide the WebAuthN response to the Issuer, authenticating the user, and the Issuer would then return the SD-JWT. Rather than the DNS TXT record, the Mail Domain would host a JSON file in the .wellknown domain. This creates challenges for the long tail of individually owned domains:\n- would require a domain that is used just for email to now have to support a web server\n- the mail domain is usually an apex domain, which does not support CNAME, complicating hosting a web site",
    "Using bubblewrap to add sandboxing to NetBSD",
    "Using bubblewrap to add sandboxing to NetBSD Google Summer of Code 2025 Reports: Using bubblewrap to add sandboxing to NetBSD\nThis report was written by Vasyl Lanko as part of Google Summer of Code 2025. Introduction\nAs of the time of writing, there is no real sandboxing technique available to NetBSD. There is chroot, which can be considered a weak sandbox because it modifies the root directory of the process, effectively restricting the process' view of the file system, but it doesn't isolate anything else, so all networking, IPC, and mounts inside this restricted file system are the same as of the system, and are accessible. There has already been some research on implementing kernel-level isolation in NetBSD with tools like gaols, mult and netbsd-sandbox, but they haven't been merged to NetBSD. Other operating systems have their own ways to isolate programs, FreeBSD has jails, and Linux has namespaces. Project Goals",
    "Project Goals Project Goals\nThe goal of this project is to bring a new way of sandboxing to NetBSD. More specifically, we want to implement a mechanism like Linux namespaces. These namespaces allow the isolation of parts of the system from a namespace, or, as the user sees it, from an application. NetBSD has compat_linux to run Linux binaries on NetBSD systems, and the implementation of namespaces can also be utilized to emulate namespace-related functionality of Linux binaries. A simple example to visualize our intended result is to consider an application running under an isolated UTS namespace that modifies the hostname. From the system's view, the hostname remains the same old hostname, but from the application's view it sees the modified hostname. Project Implementation\nLinux has 8 namespace types, in this project we will focus on only 2 of them:\n- UTS namespace, it is the simplest so we can focus on building the general namespace infrastructure with little namespace-specific details",
    "Project Implementation\nLinux has 8 namespace types, in this project we will focus on only 2 of them:\n- UTS namespace, it is the simplest so we can focus on building the general namespace infrastructure with little namespace-specific details - UTS namespace, it is the simplest so we can focus on building the general namespace infrastructure with little namespace-specific details\n- mount namespace, it is a prerequisite to most other namespace types because UNIX follows the philosophy of \"everything is a file\", so we need a separate mount namespace to have different configuration files on the same location as the system. Linux creates namespaces via the unshare or clone system calls, and it will also be our way of calling the namespace creation logic. We setup the base for implementing Linux namespaces in the NetBSD kernel using kauth, the subsystem managing all authorization requests inside the kernel. It associates credentials with objects, and because the namespace lifecycle management is related to the credential lifecycle it handles all the credential inheritance and reference counting for us. (Thanks kauth devs!)",
    "(Thanks kauth devs!) We separate the implementation of each namespace in a different secmodel, resulting in a similar framework to Linux which allows the isolation of a single namespace type. Our implementation also allows users to pick whether they want to have namespace support, and of what kind, via compilation flags, just like in Linux. UTS namespace\nUTS stands for UNIX Timesharing System, because it allows multiple users to share a single computer system. Isolating the utsname\ncan be useful to give users the illusion that they have control over the system's hostname, and also, for example, to give different hostnames to virtual servers. The UTS namespace stores the namespace's hostname, domain name, and their lengths. To isolate the utsname\nwe need to first create a copy of the current UTS information, plus we need a variable containing the number of credentials referencing this namespace, or, in simpler terms, the reference count of this namespace.",
    "To isolate the utsname\nwe need to first create a copy of the current UTS information, plus we need a variable containing the number of credentials referencing this namespace, or, in simpler terms, the reference count of this namespace. This namespace specific information needs to be saved somewhere, and for that we use the credential's private_data\nfield, so we can use a UTS_key\nto save and retrieve UTS\nrelated information from the secmodel. The key specifies the type of information we want to retrieve from the private_data\n, hence using a UTS_key\nfor the UTS namespace. The key for each namespace is a fixed value (we don't create a new key for every credential), but the retrieved value for that key from different credentials may be different. We had to modify kernel code that was directly accessing the hostname\nand domainname\nvariables, to instead call get_uts()\n, which retrieves the UTS struct for the namespace of the calling process. We didn't modify occurrences in kernel drivers because drivers are not part of any namespace, so they should still access the system's resources directly. MNT namespace",
    "MNT namespace MNT namespace\nThe MNT namespace isolates mounts across namespaces. It is used to have different versions of mounted filesystems across namespaces, meaning a user inside a mount namespace can mount and unmount whatever they want without affecting or even breaking the system. The mount namespace structure in Linux is fairly complicated. To have something similar in NetBSD we need to be able to control the mounts accessed by each namespace, and for that we need to control what is each namespace's mountlist, this is also enough for unmounting file systems, because in practice we can just hide them. For the mount_namespace, mountlist structure and the number of credentials using the mount namespace are stored in the credential's private data with the MNT_key\n. Similarly to the UTS namespace, we had to modify kernel code to not directly access the mountlist\n, but instead go through a wrapper called get_mountlist()",
    "Similarly to the UTS namespace, we had to modify kernel code to not directly access the mountlist\n, but instead go through a wrapper called get_mountlist() . Similarly to the UTS namespace, we had to modify kernel code to not directly access the mountlist\n, but instead go through a wrapper called get_mountlist()\nwhich returns the correct mountlist for the namespace the calling process resides in. Implementation for the mount namespace is immensely more complex than for the UTS namespace, it involves having a good understanding of both Linux and NetBSD behaviour, and I would frequently find myself wondering how to implement something after reading the Linux man pages, which would lead to me looking for it in the Linux source code, understanding it, then going back to NetBSD source code, trying to implement it, and seeing it's too different to implement in the same way. Project Status\nYou can find all code written during this project in GitHub at maksymlanko/netbsd-src gsoc-bubblewrap\nbranch. Because I intend to continue this work outside of GSoC, I want to reinforce that this was the last commit still during GSoC on gsoc-bubblewrap",
    "Because I intend to continue this work outside of GSoC, I want to reinforce that this was the last commit still during GSoC on gsoc-bubblewrap branch. Because I intend to continue this work outside of GSoC, I want to reinforce that this was the last commit still during GSoC on gsoc-bubblewrap\nbranch and this was the last one for the mnt_ns\nstill WIP branch. The link includes implementation of general namespace code via secmodels, implementation of the UTS namespace and related ATF-tests, and the work-in-progress implementation of mount namespaces. The mount namespace functionality is not finished as it would require much more work than the time available for this project. To complete it, it would be required invasive and non-trivial changes to the original source code, and, of course, more time. Future Work\nAs previously mentioned, Linux has 8 namespace types, it is important to see which of the missing namespaces are considered useful and feasible to implement.",
    "Future Work\nAs previously mentioned, Linux has 8 namespace types, it is important to see which of the missing namespaces are considered useful and feasible to implement. Future Work\nAs previously mentioned, Linux has 8 namespace types, it is important to see which of the missing namespaces are considered useful and feasible to implement. I believe that after mount namespaces it would be interesting to implement PID namespaces as this in combination with mount namespaces would permit process isolation from this sandbox. Afterwards, implementing user namespaces would allow users to get capabilities similar to root\nin the namespace, giving them sudo\npermissions while still restricting system-wide actions like shutting down the machine. A lower hanging fruit is to implement the namespace management functionality, which in Linux is lsns to list existing namespaces, and setns to move the current process to an already existing namespace. Challenges\n- Semantics. Did you know the unmount system call with MNT_FORCE flag in Linux (usually) returns EBUSY, and in NetBSD it forces the unmounting? One of them makes it easier to implement mount namespaces.",
    "One of them makes it easier to implement mount namespaces. - The behaviour of namespaces is not fully specified in the man pages. If something is not clear from the man pages you need to read the source code. - Unexpected need to learn a lot of VFS concepts and their differences in NetBSD and Linux. - There was a much bigger research component than I anticipated. In the end, Linux and NetBSD are different operating systems, implemented in different ways. Linux is complex and it is not trivial to port namespaces to NetBSD. Notes\nThe project is called \"Using bubblewrap to add sandboxing to NetBSD\" and was initially projected to emulate the unshare\nsystem call into compat_linux\n, but, seeing that having namespaces could be useful for NetBSD, and that it would be easy to add to compat_linux\nafterwards, we decided to instead implement namespaces directly in the NetBSD kernel. Implementing other system calls necessary to make the bwrap",
    "Implementing other system calls necessary to make the bwrap afterwards, we decided to instead implement namespaces directly in the NetBSD kernel. Implementing other system calls necessary to make the bwrap\nlinux binary work correctly also wouldn't be as satisfying as implementing namespaces directly into NetBSD, so this was why the project was initially called \"Using bubblewrap to add sandboxing to NetBSD\" but nowadays it would be more accurate to call it \"Sandboxing in NetBSD with Linux-like namespaces\". Thanks\nI am very grateful to Google for Google Summer of Code, because without it I wouldn't have learned so much this summer, wouldn't have met with smart and interesting people, and for sure wouldn't have tried to contribute to a project like NetBSD, even if I always wanted to write operating systems code... But, the biggest thing I will take with me from this project is the confidence to be able to contribute to NetBSD and other open source projects.",
    "But, the biggest thing I will take with me from this project is the confidence to be able to contribute to NetBSD and other open source projects. I would also like to thank the members of the NetBSD organization for helping me throughout this project, and more specifically:\n- Taylor R. Campbell, Harold Gutch and Nia Alarie from IRC, for helping me fix a nasty\nLD_LIBRARY_PATH\nbug I had on my system which wouldn't let me finish compiling NetBSD, and general GSoC recomendations. - Emmanuel Dreyfus from\ntech-kern\n, with whom I discussed ideas for projects and proposal suggestions, and in the end inspired the namespaces project. - Christoph Badura and Leonardo Taccari who volunteered to be my mentors. They took time to research and answer my questions, anticipated possible problems in my approaches, and always pointed me in the right direction, daily, during all of GSoC's period. This project is from the 3 of us.",
    "Montana Becomes First State to Enshrine 'Right to Compute' into Law",
    "Montana Becomes First State to Enshrine 'Right to Compute' into Law Montana has made history as the first state in the U.S. to legally protect its citizens\u2019 right to access and use computational tools and artificial intelligence technologies. Governor Greg Gianforte signed Senate Bill 212, officially known as the Montana Right to Compute Act (MRTCA), into law. The groundbreaking legislation affirms Montanans\u2019 fundamental right to own and operate computational resources \u2014 including hardware, software, and AI tools \u2014 under the state\u2019s constitutional protections for property and free expression. Supporters of the bill say it represents a major step in securing digital freedoms in an increasingly AI-driven world. \u201cMontana is once again leading the way in defending individual liberty,\u201d said Senator Daniel Zolnikov, the bill\u2019s sponsor and a longtime advocate for digital privacy. \u201cWith the Right to Compute Act, we are ensuring that every Montanan can access and control the tools of the future.\u201d",
    "\u201cWith the Right to Compute Act, we are ensuring that every Montanan can access and control the tools of the future.\u201d While the law allows state regulation of computation in the interest of public health and safety, it sets a high bar: any restrictions must be demonstrably necessary and narrowly tailored to serve a compelling interest. Legal experts note that this is one of the most protective standards available under Montana law. The act also includes provisions for AI-controlled critical infrastructure, requiring both a \u201cshutdown mechanism\u201d to allow human control and annual safety reviews \u2014 a move aimed at balancing innovation with public safety concerns. The bill has drawn praise from privacy advocates and tech policy groups. Tanner Avery, Policy Director at the free-market think tank Frontier Institute, called the law a \u201cflag in the ground\u201d for digital rights, adding: \u201cMontana has made clear it will treat any attempt to infringe on fundamental digital freedoms with the utmost scrutiny.\u201d",
    "Tanner Avery, Policy Director at the free-market think tank Frontier Institute, called the law a \u201cflag in the ground\u201d for digital rights, adding: \u201cMontana has made clear it will treat any attempt to infringe on fundamental digital freedoms with the utmost scrutiny.\u201d The MRTCA stands in stark contrast to recent regulatory efforts in other states, such as California, Virginia, and New York, where proposals to rein in AI technologies have either failed or been heavily revised. Montana\u2019s approach leans toward empowering individual users rather than restricting access. The law has already inspired similar efforts in New Hampshire, where lawmakers are pushing a constitutional amendment guaranteeing access to computation. Rep. Keith Ammon, the state\u2019s Majority Floor Leader, praised Montana\u2019s leadership: \u201cThis is the kind of bold move that sets the tone for the rest of the country.\u201d\nNationally, the Right to Compute movement is gaining traction. Spearheaded by the grassroots group RightToCompute.ai, the campaign argues that computation \u2014 like speech and property \u2014 is a fundamental human right. \u201cA computer is an extension of the human capacity to think,\u201d the organization states.",
    "\u201cA computer is an extension of the human capacity to think,\u201d the organization states. The movement is supported by Haltia.AI, a Dubai-based AI startup, and the ASIMOV Protocol, a blockchain consortium advocating for decentralized AI infrastructure. Talal Thabet, Co-Founder of both groups, praised Montana\u2019s law as \u201ca monumental step forward in ensuring individuals retain control of their own data and digital tools.\u201d\nAs debates over AI governance and digital rights continue to evolve, Montana\u2019s bold new law could serve as a blueprint for other states seeking to safeguard freedom in the digital era.",
    "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
    "Zensical \u2013 A modern static site generator built by the Material for MkDocs team Zensical \u2013 A modern static site generator built by the Material for MkDocs team\u00b6\nWe are thrilled to announce Zensical, our next-gen static site generator designed to simplify the process of building documentation sites. Distilled from a decade of experience, Zensical is our effort to overcome the technical limitations of MkDocs, reaching far beyond its capabilities. Zensical is the result of thousands of hours of work \u2013 built from the ground up for a modern and comfortable authoring experience, while making it easy for developers to extend and customize Zensical through its upcoming module system. Our goal is to support docs-as-code workflows with tens of thousands of pages, without compromising performance or usability. To make the transition seamless, compatibility comes first. We're putting significant effort into ensuring a smooth migration from Material for MkDocs for all users. Zensical can natively read mkdocs.yml",
    "Zensical can natively read mkdocs.yml , allowing you to build your existing project with minimal changes. As of now, a subset of plugins is supported, and we're working on feature parity in the coming months. Zensical is fully Open Source, licensed under MIT, and can be used for any purpose, including for commercial use. We're also saying goodbye to our sponsorware model, replacing it with our new offering for professional users: Zensical Spark. This allows us to stay independent, maximizing user value, as we shape the future of Zensical together with you. You can subscribe to our newsletter to stay in the loop. This is the second article in a four-part series:\n- Transforming Material for MkDocs\n- Zensical \u2013 A modern static site generator built by the creators of Material for MkDocs. - What happens to the features in Insiders coming November 11, 2025\n- A path forward for our community coming November 18, 2025\nWhy Zensical?\u00b6",
    "- What happens to the features in Insiders coming November 11, 2025\n- A path forward for our community coming November 18, 2025\nWhy Zensical?\u00b6 - What happens to the features in Insiders coming November 11, 2025\n- A path forward for our community coming November 18, 2025\nWhy Zensical?\u00b6\nSince its initial release in 2016, Material for MkDocs has helped tens of thousands of teams to publish and maintain reliable documentation. However, in recent years, it has become apparent that we were running up against limitations of our core dependency, MkDocs. These limitations proved impossible to overcome as they are deeply rooted in its architecture. We also mentioned in our update on our foundational work that MkDocs must be considered a supply chain risk, since it's unmaintained since August 2024. It has seen no releases in over a year and is accumulating unresolved issues and pull requests. These developments have forced us to cut our ties to MkDocs as a dependency.",
    "These developments have forced us to cut our ties to MkDocs as a dependency. In order to map out a path forward, we went back to the drawing board, talked to dozens of our professional users and thoroughly analyzed the MkDocs ecosystem. We didn't just want to create a fork or port of MkDocs, but decided to rethink static site generation from first principles. With Zensical, we are creating a modern static site generator, which is compatible with your content and customizations, and addresses MkDocs' limitations. While Material for MkDocs is built on top of MkDocs, Zensical consolidates both projects into one coherent stack, covering static site generation, theming, and customization. What you can expect today:\nAlthough we haven't reached full feature parity yet, you can already use Zensical to build your existing Material for MkDocs projects with minimal changes. You can jump to the compatibility section to learn what is already supported. What you can expect\u00b6\nSolid foundation\u00b6",
    "What you can expect\u00b6\nSolid foundation\u00b6 You can jump to the compatibility section to learn what is already supported. What you can expect\u00b6\nSolid foundation\u00b6\nOur goal with Zensical is to create a coherent and modern stack, vertically integrating all parts of the authoring experience (AX), developer experience (DX), and user experience (UX). This gives us a significant competitive advantage over solutions that overly rely on third-party frameworks and dependencies, helping us to create much more robust Open Source software. ZRX, our new differential build engine, creates a solid foundation for Zensical, and is an Open Source project of its own. It's a fresh take on making differential data flows easy to build and a joy to work with. Most engineering effort has gone into ZRX, as it forms the backbone of Zensical, and will allow us to ship features faster.",
    "Most engineering effort has gone into ZRX, as it forms the backbone of Zensical, and will allow us to ship features faster. Following the principle of architectural hoisting, we moved essential, reusable functionality into ZRX, which allows us to keep Zensical's core simple and focused on static site generation. ZRX handles the heavy lifting \u2013 differential builds, caching, and data flow orchestration. With the upcoming module system and component system, both of which are on our public roadmap, Zensical will gain more degrees of freedom in the coming months, allowing you to extend and customize Zensical in ways that were previously impossible with MkDocs. Modern design\u00b6\nZensical brings a fresh, modern design that breaks out of the Materal Design aesthetic, creating a visual foundation that is more easily brandable and adaptable to different use cases. The new design prioritizes clarity, simplicity, and usability, while having a more professional finish:",
    "The new design prioritizes clarity, simplicity, and usability, while having a more professional finish: Right now, the layout and site structure of Zensical match Material for MkDocs closely, as we're focusing on ensuring maximum compatibility. Once we finish work on our upcoming component system, we'll provide an alternative that is much more flexible and adaptable, and can be tailored to different use cases and branding requirements more easily. You can also keep the Material for MkDocs look and feel with a single line of configuration. Blazing-fast search\u00b6\nClient-side search isn't a compromise \u2013 for the vast majority of static sites, it's the best solution, since it's faster, involves zero maintenance, and doesn't require you to pay for a service. As covered in depth in the first part of this series, the current search implementation in Material for MkDocs has severe limitations, and is based on a now unmaintained library, which is why we decided to build a new search engine from scratch. It's based on the same goals as Zensical itself: performance, flexibility, and extensibility.",
    "It's based on the same goals as Zensical itself: performance, flexibility, and extensibility. Disco, our modular and blazing-fast client-side search engine, is exclusively available in Zensical. When you build your site with Zensical, your users will immediately benefit from Disco's improved ranking algorithm, as well as its filtering and aggregation capabilities:\nIn early 2026, we'll be releasing Disco as a standalone Open Source project. With the feedback of our professional users in Zensical Spark, we're going to evolve the search experience, turning Disco into a highly configurable and customizable search engine that adapts to your needs. You can subscribe to our newsletter to receive news about Disco. Authoring experience\u00b6\nSlow feedback loops can be a major pain point when writing documentation. Almost all of us know the feeling of waiting for the static site generator to finish building the site, just to see a small change reflected in the output. With Zensical, we're finally addressing this issue.",
    "With Zensical, we're finally addressing this issue. It's important to understand that we're not yet utilizing the differential capabilities of ZRX to the fullest extent, as we're forced to make several compromises to ensure maximum compatibility with Material for MkDocs at the moment. Markdown rendering needs to go through Python Markdown, which forces us to pay for extra marshalling costs. While the initial build can sometimes be slower than with MkDocs, repeated builds \u2013 especially when serving the site \u2013 are already 4 to 5x faster, as only changed files need to be rebuilt. We're also working on a new Markdown toolchain based on a CommonMark-compliant parser written in Rust, which will make Markdown processing significantly faster. We'll be tackling this as part of the upcoming component system, which we'll start working on in early 2026. Once our new Markdown toolchain is ready, we'll provide automated tools to translate between Python Markdown and CommonMark, so you don't need to manually migrate your content.",
    "Once our new Markdown toolchain is ready, we'll provide automated tools to translate between Python Markdown and CommonMark, so you don't need to manually migrate your content. Maximum compatibility\u00b6\nCompatibility with Material for MkDocs is our top priority. We understand that switching to a new static site generator can be challenging, especially for large projects with many customizations. Therefore, we've put significant effort into ensuring that Zensical understands mkdocs.yml\nconfiguration files, so that you can build your projects with minimal changes. This means your existing Markdown files, template overrides, CSS and JavaScript extensions don't need to be touched, primarily because we did not change the generated HTML, and rely on Python Markdown for processing your content. However, plugins are a different story. In MkDocs, practically all plugins have side effects, making it impossible to parallelize builds. We started from first principles and asked: what should extensibility look like in a modern static site generator? Our answer is the upcoming module system, which takes a fundamentally different approach based on four core principles:",
    "Our answer is the upcoming module system, which takes a fundamentally different approach based on four core principles: - Modules can inject, extend, and re-define functionality\n- Modules are deterministic through topological ordering\n- Modules foster reusability, with the possibility to remix them\n- Modules can cooperate through well-defined contracts\nWe're working on shipping essential functionality as provided by MkDocs plugins as built-in modules. In early 2026, we will open the module system to third-party developers, so they can start building their own modules, as we see Zensical as the heart of a thriving ecosystem. Zensical Spark\u00b6\nZensical Spark, our offering for professionals, is the result of countless calls with professional users of Material for MkDocs. From startups to large enterprises, we enable organizations to realize complex projects in diverse environments. For this, we've created Zensical Spark as a collaborative space. If you're a professional user, Zensical Spark is for you, since:\n-",
    "If you're a professional user, Zensical Spark is for you, since:\n- -\nYou can be confident that Zensical will continue to be developed and maintained in the long term as a set of interconnected and sustainable OSI-compliant Open Source projects. -\nYou can receive the support you need to successfully use, configure and customize Zensical in your organization, receiving first-class support from the Zensical team. -\nYou can influence the future development of Zensical by participating in our new approach to Open Source software development, helping us to build exactly what you need. Let's talk! If you're working in a professional context, reach out to contact@zensical.org to schedule a call and learn how Zensical Spark enables your team to transition to Zensical smoothly and have a voice in its continued development. You should also consider joining the waiting list, since seats are limited. We're growing our team\u00b6\nWe're also excited to announce that we're growing our team:\nTimoth\u00e9e Mazzucotelli, also known as @pawamoy, is joining Zensical!",
    "We're growing our team\u00b6\nWe're also excited to announce that we're growing our team:\nTimoth\u00e9e Mazzucotelli, also known as @pawamoy, is joining Zensical! We're growing our team\u00b6\nWe're also excited to announce that we're growing our team:\nTimoth\u00e9e Mazzucotelli, also known as @pawamoy, is joining Zensical! At Zensical, Tim is focusing on providing the same seamless experience for generating API reference documentation from source code (via docstrings) as he has done with mkdocstrings, the second biggest project in the MkDocs ecosystem. With his expertise, and Zensical's new stack, we'll be pushing the boundaries of what's possible with API reference documentation. Goodbye, GitHub Sponsors\u00b6\nThank you! To all of you who have supported us over the years through GitHub Sponsors \u2013 we are incredibly grateful for your support. It has been invaluable in helping us to build, maintain and evolve Material for MkDocs, and we couldn't have done it without you. Seriously, thank you!",
    "Seriously, thank you! Material for MkDocs gave us something invaluable: experience building for tens of thousands of users, and the opportunity to build a team around Open Source software. It showed us that making a living from Open Source isn't just possible \u2013 we grew it into one of the largest sponsorware projects on GitHub and inspired others to pursue similar paths. Now we're breaking new ground. Zensical is our next chapter, and we're professionalizing how we approach Open Source development. Our vision is to make Zensical free for everyone to use while building a sustainable business around it through our new approach. This transition means saying goodbye to GitHub Sponsors. It has served us exceptionally well, but as we professionalize and scale, we're making the leap from personal project to company \u2013 building a business and team that can meet the growing demands of professional users while staying true to our values. We're doubling down on Open Source, developing software for everyone.",
    "We're doubling down on Open Source, developing software for everyone. We're doubling down on Open Source, developing software for everyone. If you want to continue supporting our work, please subscribe to our newsletter. We'll be providing new methods to support us in the coming months, with the possibility of getting exclusive goodies. Looking Ahead\u00b6\nMaterial for MkDocs grew organically in a pot that eventually became too small. With Zensical, we're building on solid foundations designed to grow with us \u2013 and with you. Material for MkDocs is now in maintenance mode\nWe want to be transparent about the risks of staying on Material for MkDocs. With MkDocs unmaintained and facing fundamental supply chain concerns, we cannot guarantee Material for MkDocs will continue working reliably in the future. We're aware that transitioning takes time, which is why we commit to support it at least for the next 12 months, fixing critical bugs and security vulnerabilities as needed, but the path forward is with Zensical.",
    "We're aware that transitioning takes time, which is why we commit to support it at least for the next 12 months, fixing critical bugs and security vulnerabilities as needed, but the path forward is with Zensical. If documentation plays a critical role in your organization, and you're worried how this might affect your business, consider joining Zensical Spark, or feel free to schedule a call by reaching out at contact@zensical.org. Where we'll be in 12 months\u00b6\nOver the next 12 months, following our phased transition strategy, we'll reach Phase 2 and 3 \u2013 introducing our module system and component system, as well as CommonMark support. By replacing Python Markdown with a Rust-based Markdown parser, we'll unlock performance improvements and the modularity needed for flexible templating. This is where Zensical truly starts to unfold its capabilities. Zensical is already powering real projects due to extensive compatibility with Material for MkDocs. We're actively working on closing the gap to reach full feature parity. You can install Zensical now, and build your existing Material for MkDocs projects with it. If you run into a bug, please don't hesitate to open an issue \u2013 we're here to help.",
    "If you run into a bug, please don't hesitate to open an issue \u2013 we're here to help. You can install Zensical now, and build your existing Material for MkDocs projects with it. If you run into a bug, please don't hesitate to open an issue \u2013 we're here to help. Connect with us\u00b6\nIf you have questions we haven't addressed, please reach out to us at contact@zensical.org. We're currently collecting questions from the community about Zensical, and will address them in an FAQ section as part of our documentation in the coming weeks. We're incredibly thankful that you have been part of our journey so far. With Zensical, we're embarking on a new chapter, and we couldn't be more excited to have you with us. You can subscribe to our newsletter to stay in the loop.",
    "I Am Mark Zuckerberg",
    "I Am Mark Zuckerberg Welcome to iammarkzuckerg.com\nNo, not THAT Mark Zuckerberg-this one's busy helping Hoosiers, not launching social networks. Relax, you haven't accidentally logged into Facebook or the Metaverse. You're on the site of Mark S. Zuckerberg, Indiana's original bearer of the name, proud bankruptcy attorney, and frequent recipient of confused emails from people seeking tech support or handouts of money. What I Really Do:\n- Help people obtain a fresh financial start (no passwords required)\n- Offer dependable, human-involved advice (my artificial intelligence is powered by coffee)\n- Answer local legal questions, not privacy scandals\nReal Zuckerberg Facts:\n- Shares a name, not fortune, with the Facebook founder\n- Gets mistaken daily for a tech billionaire\n- Has written zero social media apps, but plenty of court briefs\nFun Fact:\nIn Indiana, saying \"I'm Mark Zuckerberg\" gets more laughs than likes. But if you need trustworthy bankruptcy help, you're in exactly the right place!",
    "But if you need trustworthy bankruptcy help, you're in exactly the right place! Fun Fact:\nIn Indiana, saying \"I'm Mark Zuckerberg\" gets more laughs than likes. But if you need trustworthy bankruptcy help, you're in exactly the right place! Click around, get to know your (non-billionaire) local Mark, and remember: No login required. Click Here to See How Other\nWebsites Have Reacted to This\nInteresting Things That Have Happened to Me Because My Name is Mark Zuckerberg\nFor a complete list of things that have happened to Mark Zuckerberg click here\nLike I said, I don't wish Mark E. Zuckerberg any ill will at all. I hope the best for him, but let me tell you this: I will rule the search for \"Mark Zuckerberg bankruptcy\". And if he does fall upon difficult financial times, and happens to be in Indiana, I will gladly handle his case in honor of our eponymy.",
    "Ironclad \u2013 formally verified, real-time capable, Unix-like OS kernel",
    "Ironclad \u2013 formally verified, real-time capable, Unix-like OS kernel Ironclad is a (partially) formally verified, real-time capable, UNIX-like operating system kernel for general-purpose and embedded uses. It is written in SPARK and Ada, and is comprised of 100% free software. Ironclad features a familiar POSIX-compatible interface, true simultaneous preemptive multitasking, Mandatory Access Control (MAC), and support for hard real-time scheduling. Ironclad is fully open source and distributed under the GPLv3, ensuring it remains free. No firmware blobs are needed or shipped with the kernel. Every piece of the stack is open source. SPARK's state of the art formal verification is employed for ensuring absence of errors and correctness of big portions of Ironclad, like cryptography, MAC, and user-facing facilities. Ported to several platforms and boards, and designed to be easily portable to many more. Dependency on only the GNU toolchain allows for easy cross-compilation.",
    "Dependency on only the GNU toolchain allows for easy cross-compilation. Ported to several platforms and boards, and designed to be easily portable to many more. Dependency on only the GNU toolchain allows for easy cross-compilation. Ironclad will always be free for use, study, and modification, so, to support the project, we rely on the use of donations and grants. Every contribution makes a difference and allows us to do more. This project is funded through NGI Zero Core, a fund established by NLnet with financial support from the European Commission's Next Generation Internet program. Learn more at the NLnet project page. Additionally, we would like to thank the following organizations:",
    "The Manuscripts of Edsger W. Dijkstra",
    "The Manuscripts of Edsger W. Dijkstra Home\nNumerical EWD Index: 00xx 01xx 02xx 03xx 04xx 05xx 06xx 07xx 08xx 09xx 10xx 11xx 12xx 13xx\nBibTeX index\nMC Reports\nOther documents\nTranscriptions\nVideo and Audio\nExternal links\nIn addition, Dijkstra was intensely interested in teaching, and in the relationships between academic computing science and the software industry. During his forty-plus years as a computing scientist, which included positions in both academia and industry, Dijkstra\u2019s contributions brought him many prizes and awards, including computing science\u2019s highest honor, the ACM Turing Award.",
    "During his forty-plus years as a computing scientist, which included positions in both academia and industry, Dijkstra\u2019s contributions brought him many prizes and awards, including computing science\u2019s highest honor, the ACM Turing Award. Like most of us, Dijkstra always believed it a scientist\u2019s duty to maintain a lively correspondence with his scientific colleagues. To a greater extent than most of us, he put that conviction into practice. For over four decades, he mailed copies of his consecutively numbered technical notes, trip reports, insightful observations, and pungent commentaries, known collectively as \u201cEWDs\u201d, to several dozen recipients in academia and industry. Thanks to the ubiquity of the photocopier and the wide interest in Dijkstra\u2019s writings, the informal circulation of many of the EWDs eventually reached into the thousands.",
    "Thanks to the ubiquity of the photocopier and the wide interest in Dijkstra\u2019s writings, the informal circulation of many of the EWDs eventually reached into the thousands. Although most of Dijkstra\u2019s publications began life as EWD manuscripts, the great majority of his manuscripts remain unpublished. They have been inaccessible to many potential readers, and those who have received copies have been unable to cite them in their own work. To alleviate both of these problems, the department has collected over a thousand of the manuscripts in this permanent web site, in the form of PDF bitmap documents (to read them, you\u2019ll need a copy of Acrobat Reader). We hope you will find it convenient, useful, inspiring, and enjoyable. The original manuscripts, along with diaries, correspondence, photographs, and other papers, are housed at The Center for American History of The University of Texas at Austin. Each manuscript file is accessible through either of two indexes:\n0. BibTeX index. Each entry includes all the available bibliographic data. 1. Ad-hoc indexes. These contain titles only, but are faster if you know what you\u2019re looking for.",
    "These contain titles only, but are faster if you know what you\u2019re looking for. 0. BibTeX index. Each entry includes all the available bibliographic data. 1. Ad-hoc indexes. These contain titles only, but are faster if you know what you\u2019re looking for. EWD-numbered documents (This index gives an approximate correspondence between manuscripts\u2019 EWD numbers and the year in which they appeared.) Technical reports from the Mathematical Centre (now CWI: Centrum voor Wiskunde en Informatica) PhD thesis (5.3 MB) Other documents\nEWD-numbered documents (This index gives an approximate correspondence between manuscripts\u2019 EWD numbers and the year in which they appeared.) Technical reports from the Mathematical Centre (now CWI: Centrum voor Wiskunde en Informatica)\nPhD thesis (5.3 MB)\nYou can find a table relating EWD numbers to publication years here. Many of the privately circulated manuscripts collected here were subsequently published; their copyrights are held by their respective publishers.",
    "Many of the privately circulated manuscripts collected here were subsequently published; their copyrights are held by their respective publishers. Many of the privately circulated manuscripts collected here were subsequently published; their copyrights are held by their respective publishers. A growing number of the PDF bitmap documents have been transcribed to make them searchable and accessible to visitors who are visually impaired. A few of the manuscripts written in Dutch have been translated into English, and one \u2014EWD1036\u2014 has been translated into Spanish. EWD28 has been translated from English into Russian. For these transcriptions and translations we are grateful to over sixty contributors. Volunteers willing to transcribe manuscripts are always welcome (Note: doing EWDs justice in translation has turned out to be too difficult, so we are no longer soliciting translations).",
    "Volunteers willing to transcribe manuscripts are always welcome (Note: doing EWDs justice in translation has turned out to be too difficult, so we are no longer soliciting translations). Proofreading Each transcription gets a cursory scan as it\u2019s prepared for uploading, but since a web page can always be updated, I don\u2019t strive for (unattainable) perfection before installing it. On the web, proofreading is a game that can be played by every reader; if you spot an error, please\nA compilation of cross-references has been contributed by Diethard Michaelis. As its author notes, the collection is incomplete, and all readers are invited to add to it. Dijkstra often returned to topics about which he had already written, when he had something new to say or even just a better way of saying it. When Dijkstra himself didn\u2019t provide the backward references, we indicate the relationship by \"see also\" links in the index, leaving the judgment of the extent to which the earlier EWD is superseded by the later one to the reader. Any reader who notices such a relationship is invited to",
    "Any reader who notices such a relationship is invited to We have begun adding summaries of the EWDs. This innovation was suggested by G\u00fcnter Rote, who contributed the first dozen summaries. Additional contributions of summaries\u2014especially summaries in English of EWDs in Dutch\u2014are most welcome. Copyrights in most EWDs are held by his children, one of whom \u2014 \u2014 handles requests for permission to publish reproductions. The exceptions are documents that were published, and whose copyrights are held by their publishers; those documents are listed here, and each one is provided with a cover page identifying the copyright holder. Because the original manuscripts are in possession of the Briscoe Center for American History at The University of Texas, the Center\u2019s policies are also applicable. In addition to the manuscripts, you may enjoy some recordings of Dijkstra lectures and interviews.",
    "In addition to the manuscripts, you may enjoy some recordings of Dijkstra lectures and interviews. In addition to the manuscripts, you may enjoy some recordings of Dijkstra lectures and interviews. An interview with Dijkstra (Spanish translation here) was conducted in 1985 by Rogier F. van Vlissingen, who has also written a personal reflection on \u201cDijkstra\u2019s sense of what computer science and programming are and what they aren\u2019t.\u201d\nAnother interview was conducted by Philip L. Frana in August 2001. A transcript is available in the on-line collection of the Charles Babbage Institute.",
    "A transcript is available in the on-line collection of the Charles Babbage Institute. Another interview was conducted by Philip L. Frana in August 2001. A transcript is available in the on-line collection of the Charles Babbage Institute. To mark the occasion of Dijkstra\u2019s retirement in November 1999 from the Schlumberger Centennial Chair in Computer Sciences, which he had occupied since 1984, and to celebrate his forty-plus years of seminal contributions to computing science, the Department of Computer Sciences organized a symposium, In Pursuit of Simplicity, which took place on his birthday in May 2000. The symposium\u2019s program (10 MB) contains an outline of Dijkstra\u2019s career, as well as a collection of quotes culled from his writings, from his blackboard, and from what others have said about him. Banquet speeches by David Gries, Fred Schneider, Krzysztof Apt, W.M. Turski, and H. Richards were recorded on a video. Dijkstra\u2019s death in August 2002 was marked by many obituaries and memorials, including the Computer Sciences department\u2019s memorial celebration.",
    "Dijkstra\u2019s death in August 2002 was marked by many obituaries and memorials, including the Computer Sciences department\u2019s memorial celebration. Dijkstra\u2019s death in August 2002 was marked by many obituaries and memorials, including the Computer Sciences department\u2019s memorial celebration. A remembrance of Dijkstra was posted in May 2008 by Maarten van Emden (thanks to Tristram Brelstaff for noting it). In 2021 Krzysztof R. Apt and Tony Hoare edited a commemoration of Edsger Dijkstra written by more than twenty computer scientists who knew him as a colleague, teacher, and friend. A blog devoted to Dijkstra\u2019s works and thoughts has been created, and is being maintained, by the historian of computing Edgar G. Daylight. An article by Daylight, \u201cDijkstra\u2019s Rallying Cry for Generalization: the Advent of the Recursive Procedure, late 1950s - early 1960s,\u201d appeared in The Computer Journal, March 2011.",
    "An article by Daylight, \u201cDijkstra\u2019s Rallying Cry for Generalization: the Advent of the Recursive Procedure, late 1950s - early 1960s,\u201d appeared in The Computer Journal, March 2011. In his blog A Programmer\u2019s Place, Maarten van Emden has an entry entitled \u201cAnother scoop by Dijkstra?\u201d. The entry describes Dijkstra\u2019s \u201cremarkable insight [in \u201cNotes on Structured Programming\u201d (EWD 249)] that resolves the stand-off between the Sieve of Eratosthenes (efficient in terms of time, but not memory) and the method of Trial Division (efficient in terms of memory, but not time)\u201d by applying the Assembly-line Principle. The Edsger W. Dijkstra Prize in Distributed Computing honors Dijkstra\u2019s \u201cfoundational work on concurrency primitives (such as the semaphore), concurrency problems (such as mutual exclusion and deadlock), reasoning about concurrent systems, and self-stabilization [, which] comprises one of the most important supports upon which the field of distributed computing is built.\u201d\nA series of annual lectures in memory of Dijkstra commenced at The University of Texas in October 2010.",
    "The Edsger W. Dijkstra Prize in Distributed Computing honors Dijkstra\u2019s \u201cfoundational work on concurrency primitives (such as the semaphore), concurrency problems (such as mutual exclusion and deadlock), reasoning about concurrent systems, and self-stabilization [, which] comprises one of the most important supports upon which the field of distributed computing is built.\u201d\nA series of annual lectures in memory of Dijkstra commenced at The University of Texas in October 2010. A series of annual lectures in memory of Dijkstra commenced at The University of Texas in October 2010. Recent significant changes in the site are listed here; the most recent change was posted on 30 March 2021. The folks who contributed most significantly to the site\u2019s creation are acknowledged here. Comments and suggestions about the site are always welcome; please email them to the\nIf you find this site interesting, you may also be interested in another site:\nDiscipline in Thought which is a website dedicated to disciplined thinking, calculational mathematics, and mathematical methodology. The members of this site are markedly influenced by the works of EWD, and the material shared through the website continues in the traditions set by EWD (among others). Revised 2020-01-12",
    "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology",
    "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology How I spent two decades tracking down the creators of a 1987 USENET game and learned modern packaging tools in the process. The Discovery: A Digital Time Capsule from 1987\nPicture this: October 26, 1987. The Berlin Wall still stands, the World Wide Web is just text, and software is distributed through USENET newsgroups in text files split across multiple posts. On that day, Edward Barlow posted something special to comp.sources.games\n:\n\u201cconquest \u2013 middle earth multi-player game, Part01/05\u201d\nThat\u2019s how Ed Barlow announced it at the time, before quickly changed the name to Conquer. This was Conquer \u2013 a sophisticated multi-player strategy game that would influence countless others. Players controlled nations in Middle Earth, managing resources, armies, magic systems, and diplomatic relations. What made it remarkable wasn\u2019t just the gameplay, but how it was built and distributed in an era when \u201copen source\u201d wasn\u2019t even a term yet. Chapter 0: University Days.",
    "Chapter 0: University Days. Chapter 0: University Days. It was during these days, in the middle of the 90s, that my fellow students and I spent hours experimenting with terminals in the Computer Unix Labs, USENET, links, news, msgs, and of course: conquer. That game was a gem that required to be the leader of a country, and with a map representing as characters each player could control their elven kingdom, orcish empire, or human armies to fight each other while controlling all the details of the economy. But by 2006, this piece of computing history was trapped in legal limbo. Chapter 1: The Quest Begins (2006)\nAs a university student in Spain in the early \u201990s, I\u2019d encountered Conquer in the Unix labs. Fast forward to 2006, and I realized this pioneering game was at risk of being lost forever. The source code existed, scattered across ancient USENET archives, but its licensing was unclear \u2013 typical of the \u201cpost it and see what happens\u201d era of early internet software distribution.",
    "The source code existed, scattered across ancient USENET archives, but its licensing was unclear \u2013 typical of the \u201cpost it and see what happens\u201d era of early internet software distribution. I started what I thought would be a simple project: get permission from the original authors to relicense the code under GPL so it could be properly preserved and packaged for modern Linux distributions. Simple, right? Chapter 2: Digital Detective Work\nFinding Edward Barlow and Adam Bryant in 2006 was like archaeological work. Email addresses from the 1980s were long dead. USENET posts provided few clues. I scoured old university directories, googled fragments of names, and followed digital breadcrumbs across decades-old forums. The breakthrough came through pure persistence and a bit of luck. After months of searching, I managed to contact Ed Barlow. His response was refreshingly casual: \u201cYes i delegated it all to adam aeons ago. Im easy on it all\u2026. copyleft didnt exist when i wrote it and it was all for fun so\u2026\u201d\nBut there was a catch \u2013 I needed permission from Adam Bryant too, and he seemed to have vanished into the digital ether. Chapter 3: The Long Wait (2006-2011)",
    "Chapter 3: The Long Wait (2006-2011) But there was a catch \u2013 I needed permission from Adam Bryant too, and he seemed to have vanished into the digital ether. Chapter 3: The Long Wait (2006-2011)\nI documented everything on the Debian Legal mailing lists, created a GNU Savannah task (#5945), and even wrote blog posts hoping Adam would find them. The legal experts were clear: I needed explicit written permission from both copyright holders. Years passed. The project stalled. Then, on February 23, 2011, something magical happened. My phone buzzed with a contact form submission:\n\u201cI heard news of the request to release the code. I grant permission to release the code under GPL.\u201d \u2013 Adam Bryant\nHe had found one of my articles online and reached out on his own. Chapter 4: The Plot Twist \u2013 Version 5 Emerges (2025)",
    "Chapter 4: The Plot Twist \u2013 Version 5 Emerges (2025) He had found one of my articles online and reached out on his own. Chapter 4: The Plot Twist \u2013 Version 5 Emerges (2025)\nFast forward to 2025, and Stephen Smoogen contacts me about my relicesing efforts in 2006 and how he was particularly interested in reviving: Conquer Version 5 \u2013 a complete rewrite by Adam with advanced features like automatic data conversion, enhanced stability, and sophisticated administrative tools. This wasn\u2019t just an update; it was a complete reimagining of the game. But V5 had a different legal history. In the \u201990s, there had been commercial arrangements. Would Adam agree to GPL this version too? His response: \u201cI have no issues with applying a new GPL license to Version 5 as well.\u201d\nChapter 5: The Missing Piece \u2013 PostScript Magic",
    "His response: \u201cI have no issues with applying a new GPL license to Version 5 as well.\u201d\nChapter 5: The Missing Piece \u2013 PostScript Magic His response: \u201cI have no issues with applying a new GPL license to Version 5 as well.\u201d\nChapter 5: The Missing Piece \u2013 PostScript Magic\nJust when I thought the story was complete, I discovered another contributor: MaF, who had created PostScript utilities for generating printable game maps \u2013 a crucial feature in the pre-GUI era when players needed physical printouts to strategize. Tracking down MaF in 2025 led me to his company, where he\u2019s now Director of Product Security. His response: \u201cOh, that was a long time ago. But yes, that was me. And I have no problem with relicensing it to GPL.\u201d\nRichard Caley: More Than Just a Legal Footnote\nBut not all searches end with an answer. Some end with silence. My investigation of Richard Caley followed the same digital breadcrumbs. I traced him to the University of Edinburgh, where he worked on speech synthesis. I found his technical contributions to FreeBSD. But the trail went cold around 2005.",
    "But the trail went cold around 2005. Then I found him \u2013 not in a USENET archive, but on the front page of his own website, preserved exactly as he left it in web.archive.org. \u201cRichard Caley suffered a fatal heart attack on the 22nd of April, 2005. He was only 41, but had been an undiagnosed diabetic, probably for some considerable time. His web pages remain as he left them.\u201d\nReading those words felt different from finding a historical record. This wasn\u2019t archival research \u2013 this was walking into someone\u2019s house years after they\u2019d gone and finding a note on the table. The page continued:\n\u201cOver and above his tremendous ability with computers and programming, Richard had a keen mind and knowledge of an extraordinary range of topics, both of which he used in frequent contributions to on-line discussions. Despite his unique approach to speling, his prolific contributions to various news group debates informed and amused many over the years.\u201d\nThe \u201cCaleyisms\u201d \u2013 The Man Behind the Code",
    "Despite his unique approach to speling, his prolific contributions to various news group debates informed and amused many over the years.\u201d\nThe \u201cCaleyisms\u201d \u2013 The Man Behind the Code The \u201cCaleyisms\u201d \u2013 The Man Behind the Code\nAnd then I discovered his \u201cCaleyisms\u201d \u2013 a curated collection of his most brilliant USENET responses that revealed not just a programmer, but a person:\nWhat\u2019s a shell suit? \u201cOil company executive.\u201d\nHow do you prepare for a pyroclastic flow hitting Edinburgh? \u201cHang 1000 battered Mars bars on strings and stand back?\u201d\nOn his book addiction:\n\u201cI never got the hang of libraries, they keep wanting the things back and get upset when they need a crowbar to force it out of my hands.\u201d\nHis humor was dry, intelligent, and uniquely British. In technical discussions, he could be brutally precise:\n\u201cLack of proper punctuation, spacing, line breaks, capitalisation etc. is like bad handwriting, it doesn\u2019t make it impossible to read what was written, just harder. But you probably write in green crayon anyway.\u201d\nA Digital Office Preserved",
    "But you probably write in green crayon anyway.\u201d\nA Digital Office Preserved A Digital Office Preserved\nExploring his preserved website felt like walking through his digital office. The directory structure revealed his passions: FreeBSD how-tos, POVRAY experiments, wallpaper images, technical projects. His self-deprecating humor shone through in his \u201cAbout\u201d section:\n\u201cThankfully I don\u2019t have a photograph to inflict on you. Just use the picture of Iman Bowie to the left and then imagine someone who looks exactly the opposite in every possible way. This probably explains why she is married to David Bowie and I\u2019m not.\u201d\nHere was a complete person \u2013 technical director at Interactive Information Ltd, speech synthesis researcher, FreeBSD enthusiast, Kate Bush fan, and a wit who brightened countless online discussions. The legal reality was harsh: Richard\u2019s contributions to Conquer couldn\u2019t be relicensed. The university couldn\u2019t help contact heirs due to privacy laws. His friends had preserved his memory with a simple ASCII tribute at the end of his page:\n^_^\n(O O)",
    "His friends had preserved his memory with a simple ASCII tribute at the end of his page:\n^_^\n(O O) His friends had preserved his memory with a simple ASCII tribute at the end of his page:\n^_^\n(O O)\n\\_/@@\\\n\\\\~~/\n~~\n- RJC RIP\nIn the Conquer project documentation, Richard Caley isn\u2019t remembered as a \u201cproblem case\u201d or \u201cunlicensable code.\u201d He\u2019s honored as the vibrant person he was \u2013 the brilliant mind behind the \u201cCaleyisms,\u201d the researcher who contributed to speech synthesis, the FreeBSD advocate, and the witty participant in early online communities whose words continue to amuse and inform, decades after he wrote them. Chapter 6: Modern Renaissance \u2013 Enter GitHub, CICD and Modern Distributions\nHere\u2019s where the story gets really interesting. While working on preserving these Unix classics, I decided to learn modern packaging techniques. I chose to implement both APK (Alpine Linux) and Debian packaging for the games.",
    "I chose to implement both APK (Alpine Linux) and Debian packaging for the games. For APK packages, I used Melange \u2013 a sophisticated build system that creates provenance-tracked, reproducible packages for the Wolfi \u201cundistro\u201d. The irony? I discovered this tool when some friend started to work for the company that created it. Chapter 7: The Technical Journey: From USENET to Modern CI/CD\nThe transformation has been remarkable:\n1987 Original:\n- Distributed as split USENET posts\n- Manual compilation with system-specific Makefiles\n- No version control or automated testing\n2025 Revival:\n# Modern CI/CD with GitHub Actions\n- name: Build APK package\nrun: melange build conquer.yaml\n- name: Build Debian package\nrun: dpkg-buildpackage -b\nKey Modern Additions:\n- GPLv3 relicensing\n- Make building system modernization\n- C Codebase partially updated to support modern ANSI C99 specification\n- Debian packaging\n- APK packaging with Melange\nYou can see the complete transformation in the repositories:\n- Conquer v4 \u2013 The original classic\n- Conquer v5 \u2013 The advanced rewrite",
    "Chapter 7: The Technical Journey: From USENET to Modern CI/CD\nThe transformation has been remarkable:\n1987 Original:\n- Distributed as split USENET posts\n- Manual compilation with system-specific Makefiles\n- No version control or automated testing\n2025 Revival:\n# Modern CI/CD with GitHub Actions\n- name: Build APK package\nrun: melange build conquer.yaml\n- name: Build Debian package\nrun: dpkg-buildpackage -b\nKey Modern Additions:\n- GPLv3 relicensing\n- Make building system modernization\n- C Codebase partially updated to support modern ANSI C99 specification\n- Debian packaging\n- APK packaging with Melange\nYou can see the complete transformation in the repositories:\n- Conquer v4 \u2013 The original classic\n- Conquer v5 \u2013 The advanced rewrite - Debian packaging\n- APK packaging with Melange\nYou can see the complete transformation in the repositories:\n- Conquer v4 \u2013 The original classic\n- Conquer v5 \u2013 The advanced rewrite\nOriginal Conquer v4 code, by Ed Barlow and Adam Bryant\n(Conquer running in docker container alongside Apache, Curses to WebSockets output thanks to ttyd. Now we can play through the web!) Conquer Version 5 \u2013 The evolution of the classical Conquer, by Adam Bryant\nChapter 8: The Human Element: Why This Matters\nThis isn\u2019t just about preserving old games \u2013 it\u2019s about preserving the story of computing itself. Ed Barlow and Adam Bryant were pioneers who built sophisticated multiplayer experiences when most people had never heard of the internet. They distributed software through USENET because that\u2019s what you did \u2013 you shared cool things with the community.",
    "They distributed software through USENET because that\u2019s what you did \u2013 you shared cool things with the community. Martin Forssen\u2019s PostScript utilities represent the ingenuity of early developers who solved problems with whatever tools were available. Want to visualize your game state? Write a PostScript generator! The 20-year relicensing effort demonstrates something crucial about open source: it\u2019s not just about code, it\u2019s about community and continuity. Every time someone maintains a legacy project, documents its history, or tracks down long-lost contributors, they\u2019re weaving the threads that connect computing\u2019s past to its future. Lessons for Modern Developers\n- Document everything: Those casual USENET posts became crucial legal evidence decades later\n- License clearly: Ed\u2019s comment that \u201ccopyleft didnt exist when i wrote it\u201d highlights how licensing landscapes evolve\n- Community matters: Adam found my articles because the community was talking about preservation\n- Technical debt is temporal: What seems like legacy tech today might be tomorrow\u2019s archaeological treasure",
    "Lessons for Modern Developers\n- Document everything: Those casual USENET posts became crucial legal evidence decades later\n- License clearly: Ed\u2019s comment that \u201ccopyleft didnt exist when i wrote it\u201d highlights how licensing landscapes evolve\n- Community matters: Adam found my articles because the community was talking about preservation\n- Technical debt is temporal: What seems like legacy tech today might be tomorrow\u2019s archaeological treasure - Technical debt is temporal: What seems like legacy tech today might be tomorrow\u2019s archaeological treasure\n- Modern tools can revive ancient code: Melange and modern CI/CD gave 1987 software a 2025 renaissance\nThe Continuing Story\nBoth Conquer games are now fully GPL v3 licensed and available with modern packaging. They represent not just playable software, but a complete case study in software archaeology, legal frameworks for preservation, and the evolution of development practices across four decades. The next chapter? Teaching these classic strategy games to a new generation of developers and gamers, while demonstrating that proper legal frameworks and modern tooling can give any historical software a second life. Sometimes the best way to learn cutting-edge technology is by applying it to preserve computing history. What historical software deserves preservation in your field? Have you ever traced the lineage of code back to its original creators?",
    "Have you ever traced the lineage of code back to its original creators? What historical software deserves preservation in your field? Have you ever traced the lineage of code back to its original creators? #FreeSoftware #OpenSource #SoftwarePreservation #Unix #GNU #Linux #Packaging #Melange #TechHistory #GameDevelopment #Unix #USENET #GPL #FST #Debian #ncurses #terminal #shell\nRead this article in Spanish / Lee este art\u00edculo en espa\u00f1ol:\nhttps://vejeta.com/conquer-una-odisea-de-20-anos-en-arqueologia-digital/\nThis article was originally written in both English and Spanish, with additional insights and cultural context in the Spanish version.",
    "Visualize FastAPI endpoints with FastAPI-Voyager\n\nLoading\u2026\nFastAPI Voyager\n{{ state.version }}\nscroll to zoom in/out\ndouble click node to view details. shift + click to see schema's dependencies without unrelated nodes. {{ tag.name }}\n{{ tag.routes.length }}\n{{ route.name }}\nNo routes\n{{ dumpJson }}\nImport core data JSON",
    "Email verification protocol",
    "Email verification protocol Verifying control of an email address is a frequent activity on the web today and is used both to prove the user has provided a valid email address, and as a means of authenticating the user when returning to an application. Verification is performed by either:\n-\nSending the user a link they click on or a verification code. This requires the user to switch from the application they are using to their email address and having to wait for the email arrive, and then perform the verification action. This friction often causes drop off in users completing the task. There are privacy implications as the email transmission informs the mail service the applications the user is using and when they used them. -",
    "- -\nThe user logs in with a social login provider such as Apple or Google that provide a verified email address. This requires the application to have set up a relationship with each social provider, and the user to be using one of those services and wanting to share the additional profile information that is also provided in the OpenID Connect flow. The Email Verification Protocol enables a web application to obtain a verified email address without sending an email, and without the user leaving the web page they are on. To enable the functionality, the mail domain delegates email verification to an issuer that has authentication cookies for the user. When the user provides an email to the HTML form field, the browser calls the issuer passing authentication cookies, the issuer returns a token, which the browser verifies and updates and provides to the web application. The web application then verifies the token and has a verified email address for the user.",
    "The web application then verifies the token and has a verified email address for the user. User privacy is enhanced as the issuer does not learn which web application is making the request as the request is mediated by the browser. -\nSD-JWT+KB token: The selective disclosure json web token with key binding is specified in Selective Disclosure for JWT. This protocol does not use the selective disclosure features, it uses the key binding feature which enables a separation of token issuance and token presentation. The SD-JWT+KB is a token composed of two JWTs separated by the\n~\ncharacter. The first JWT is an SD-JWT aka the issuance token and is signed by the issuer and contains theemail\nandemail_verified\nclaims for the user, and the public key used by the browser to make the request. The second JWT is a KB token and is signed by the browser and contains a hash of the first JWT. The resulting SD-JWT+KB is the presentation token, and enables the application to verify the issuer provided the email address for the user without the issuer learning about the specific application -",
    "The resulting SD-JWT+KB is the presentation token, and enables the application to verify the issuer provided the email address for the user without the issuer learning about the specific application - Issuer: The service that verifies the user controls an email address. A DNS record for the email domain delegates email verification to the issuer. The issuer serves a\n.well-known/email-verification\nmetadata file that contains itsissuance_endpoint\nthat is called to obtain an issuance token, and itsjwks_uri\nthat points to the JWKS file containing the public keys used to verify the SD-JWT. The issuer is identified by its domain, an eTLD+1 (egissuer.example\n). The hostname in all URLs from the issuer's metadata MUST end with the issuer's domain. This identifier is what binds the SD-JWT, the DNS delegation, with the issuer.",
    "This identifier is what binds the SD-JWT, the DNS delegation, with the issuer. ). The hostname in all URLs from the issuer's metadata MUST end with the issuer's domain. This identifier is what binds the SD-JWT, the DNS delegation, with the issuer. Verified Email Release: The user navigates to any website that requires a verified email address and an input field to enter the email address. The user focusses on the input field and the browser provides one or emails for the user to select based on emails the user has provided previously to the browser. The user selects a verified email and the app proceeds having obtained the verified email. Are emails that can be verified decorated by the browser in the autocomplete UI? What UX is presented to the user when the app gets a verified email so the user knows it is already verified? sequenceDiagram\nparticipant U as User\nparticipant B as Browser\nparticipant RP as RP Page\nparticipant RPS as RP Server\nparticipant I as Issuer\nparticipant DNS as DNS\nNote over U,DNS: Step 1: Email Request\nU->>RP: Navigate to site",
    "sequenceDiagram\nparticipant U as User\nparticipant B as Browser\nparticipant RP as RP Page\nparticipant RPS as RP Server\nparticipant I as Issuer\nparticipant DNS as DNS\nNote over U,DNS: Step 1: Email Request\nU->>RP: Navigate to site participant B as Browser\nparticipant RP as RP Page\nparticipant RPS as RP Server\nparticipant I as Issuer\nparticipant DNS as DNS\nNote over U,DNS: Step 1: Email Request\nU->>RP: Navigate to site\nRP->>RPS: Nonce request\nRPS->>RPS: Generate nonce, bind to session\nRPS->>RP: Nonce\nRP->>B: Display page\nNote over U,DNS: Step 2: Email Selection\nU->>RP: Focus on email input field\nRP->>B: Input field focused\nB->>U: Display email address list\nU->>B: Select email address\nNote over U,DNS: Step 3: Token Request\nB->>DNS: DNS TXT lookup<br/>_email-verification.$EMAIL_DOMAIN\nDNS->>B: Return iss=issuer.example\nB->>I: GET /.well-known/email-verification\nI->>B: Return metadata\nB->>B: Generate key pair<br/>Create request token\nB->>I: POST request_token=JWT... Note over U,DNS: Step 4: Token Issuance\nI->>I: Verify request\nI->>I: Generate SD-JWT\nI->>B: {\"issuance_token\":\"SD-JWT\"}\nNote over U,DNS: Step 5: Token Presentation\nB->>B: Verify SD-JWT\nB->>I: GET jwks_uri for public keys\nI->>B: Return JWKS",
    "Note over U,DNS: Step 4: Token Issuance\nI->>I: Verify request\nI->>I: Generate SD-JWT\nI->>B: {\"issuance_token\":\"SD-JWT\"}\nNote over U,DNS: Step 5: Token Presentation\nB->>B: Verify SD-JWT\nB->>I: GET jwks_uri for public keys\nI->>B: Return JWKS I->>I: Verify request\nI->>I: Generate SD-JWT\nI->>B: {\"issuance_token\":\"SD-JWT\"}\nNote over U,DNS: Step 5: Token Presentation\nB->>B: Verify SD-JWT\nB->>I: GET jwks_uri for public keys\nI->>B: Return JWKS\nB->>B: Create KB\nB->>RP: Provide SD-JWT+KB\nNote over U,DNS: Step 6: Token Verification\nRP->>RPS: Send SD-JWT+KB\nRPS->>RPS: Parse SD-JWT+KB\nRPS->>DNS: DNS TXT lookup for email domain\nDNS->>RPS: Return iss=issuer.example\nRPS->>I: GET /.well-known/email-verification\nI->>RPS: Return metadata with jwks_uri\nRPS->>I: GET jwks_uri\nI->>RPS: Return JWKS public keys\nRPS->>RPS: Verify SD-JWT\nRPS->>RPS: Verify KB-JWT\nRPS->>RP: Email verification complete\nUser navigates to a site that will act as the RP. -\n1.1 - the RP Server generates a nonce and binds the nonce to the session. -\n1.2 - the RP Server returns a page that has an input field with the\nautocomplete\nproperty set to\"email\"\nand thenonce\nproperty set the the nonce. If the browser receives anissuance_token",
    "If the browser receives anissuance_token -\n1.2 - the RP Server returns a page that has an input field with the\nautocomplete\nproperty set to\"email\"\nand thenonce\nproperty set the the nonce. If the browser receives anissuance_token\nper 4.4 below, then it sends aemailverifed\nevent that has apresentationToken\nproperty. Following is an example of the HTML in the page:\n<input id=\"email\"\ntype=\"email\"\nautocomplete=\"email\"\nnonce=\"12345677890..random\">\n<script>\nconst input = document.getElementById('email')\ninput.addEventListener('emailverified', e => {\n// e.presentationToken is SD-JWT+KB\nconsole.log({\npresentationToken: e.presentationToken\n})\n})\n</script>\nAuthors are exploring alternative HTML and JS API approaches\n-\n2.1 - User focusses on email input field\n-\n2.2 - The browser displays the list of email addresses it has for the user. Q: Are emails that could be verified decorated for user to understand? - 2.3 - User selects an email address from browser selection, or the user types an email into the field.",
    "- 2.3 - User selects an email address from browser selection, or the user types an email into the field. Q: Are emails that could be verified decorated for user to understand? - 2.3 - User selects an email address from browser selection, or the user types an email into the field. Future: allow user to type in a field so we learn about new emails, or if the user does not want the browser to remember emails, the Email Verification Protocol is still available. In the future when we allow the user to use a passkey to authenticate to the issuer, the user can provide a verified email to a web application using a public computer by authenticating with their passkey and not enter any secrets into the public computer. If the RP has performed (1):\n- 3.1 - the browser parses the email domain ($EMAIL_DOMAIN) from the email address, looks up the\nTXT\nrecord for_email-verification.$EMAIL_DOMAIN\n. The contents of the record MUST start withiss=\nfollowed by the issuer identifier. There MUST be only oneTXT\nrecord for_email-verification.$EMAIL_DOMAIN\n. example record",
    "example record . The contents of the record MUST start withiss=\nfollowed by the issuer identifier. There MUST be only oneTXT\nrecord for_email-verification.$EMAIL_DOMAIN\n. example record\n_email-verification.email-domain.example TXT iss=issuer.example\nThis record states that email-domain.example\nhas delegated email verification to the issuer issuer.example\n. If the email domain and the issuer are the same domain, then the record would be:\n_email-verification.issuer.example TXT iss=issuer.example\nAccess to DNS records and email is often independent of website deployments. This provides assurance that an issuer is truly authorized as an insider with only access to websites on\nissuer.example\ncould setup an issuer that would grant them verified emails for any email atissuer.example\n. - 3.2 - if an issuer is found, the browser loads\nhttps://$ISSUER$/.well-known/email-verification\nand MUST follow redirects to the same path but with a different subdomain of the Issuer.",
    "- 3.2 - if an issuer is found, the browser loads\nhttps://$ISSUER$/.well-known/email-verification\nand MUST follow redirects to the same path but with a different subdomain of the Issuer. . - 3.2 - if an issuer is found, the browser loads\nhttps://$ISSUER$/.well-known/email-verification\nand MUST follow redirects to the same path but with a different subdomain of the Issuer. For example, https://issuer.example/.well-known/email-verification\nmay redirect to https://accounts.issuer.example/.well-known/email-verification\n. -\n3.3 - the browser confirms that the\n.well-known/email-verification\nfile contains JSON that includes the following properties: -\nissuance_endpoint - the API endpoint the browser calls to obtain an SD-JWT\n-\njwks_uri - the URL where the issuer provides its public keys to verify the SD-JWT\n-\nsigning_alg_values_supported - OPTIONAL. JSON array containing a list of the JWS signing algorithms (\"alg\" values) supported by both the browser for request tokens and the issuer for issued tokens. The same algorithm MUST be used for both the\nrequest_token\nandissuance",
    "The same algorithm MUST be used for both the\nrequest_token\nandissuance request_token\nandissuance\nwithin a single issuance flow. Algorithm identifiers MUST be from the IANA \"JSON Web Signature and Encryption Algorithms\" registry. If omitted, \"EdDSA\" is the default. \"EdDSA\" SHOULD be included in the supported algorithms list. The value \"none\" MUST NOT be used. Each of these properties MUST include the issuer domain as the root of their hostname. Following is an example .well-known/email-verification\nfile\n{\n\"issuance_endpoint\": \"https://accounts.issuer.example/email-verification/issuance\",\n\"jwks_uri\": \"https://accounts.issuer.example/email-verification/jwks\",\n\"signing_alg_values_supported\": [\"EdDSA\", \"RS256\"]\n}\n-\n3.4 - the browser generates a fresh private / public key and signs a JWT with the private key that has the public key in the JWT header in the JWK format as a\njwk\nclaim that contains the following claims in the payload:- aud - the issuer\n- iat - time when the JWT was signed\n- jti - unique identifier for the token",
    "Following is an example .well-known/email-verification\nfile\n{\n\"issuance_endpoint\": \"https://accounts.issuer.example/email-verification/issuance\",\n\"jwks_uri\": \"https://accounts.issuer.example/email-verification/jwks\",\n\"signing_alg_values_supported\": [\"EdDSA\", \"RS256\"]\n}\n-\n3.4 - the browser generates a fresh private / public key and signs a JWT with the private key that has the public key in the JWT header in the JWK format as a\njwk\nclaim that contains the following claims in the payload:- aud - the issuer\n- iat - time when the JWT was signed\n- jti - unique identifier for the token jwk\nclaim that contains the following claims in the payload:- aud - the issuer\n- iat - time when the JWT was signed\n- jti - unique identifier for the token\n- email - email address to be verified\nThe browser SHOULD select an algorithm from the issuer's signing_alg_values_supported\narray, or use \"EdDSA\" if the property is not present. An example JWT header:\n{\n\"alg\": \"EdDSA\",\n\"typ\": \"JWT\",\n\"jwk\": {\n\"kty\": \"OKP\",\n\"crv\": \"Ed25519\",\n\"x\": \"11qYAYdk9E6z7mT6rk6j1QnXb6pYq4v9wXb6pYq4v9w\" // base64url-encoded public key\n}\n}\ndo we want to register a new JWT\ntyp\nAn example payload\n{\n\"aud\": \"issuer.example\",\n\"iat\": 1692345600,\n\"email\": \"user@example.com\"\n}\n- 3.5 - the browser POSTs to the\nissuance_endpoint\nof the issuer with 1P cookies with a content-type ofapplication/x-www-form-urlencoded\ncontaining arequest_token\nparameter set to the signed JWT and theSec-Fetch-Dest\nheader set toemail-verification\n. POST /email-verification/issuance HTTP/1.1\nHost: accounts.issuer.example\nCookie: session=...",
    "POST /email-verification/issuance HTTP/1.1\nHost: accounts.issuer.example\nCookie: session=... parameter set to the signed JWT and theSec-Fetch-Dest\nheader set toemail-verification\n. POST /email-verification/issuance HTTP/1.1\nHost: accounts.issuer.example\nCookie: session=...\nContent-Type: application/x-www-form-urlencoded\nSec-Fetch-Dest: email-verification\nrequest_token=eyJhbGciOiJFZERTQSIsInR5cCI6IkpXVC...\nOn receipt of a token request:\n-\n4.1 - the issuer MUST verify the request headers:\nContent-Type\nisapplication/x-www-form-urlencoded\nSec-Fetch-Dest\nisemail-verification\n-\n4.2 - the issuer MUST verify the request_token by:\n- parsing the JWT into header, payload, and signature components\n- confirming the presence of, and extracting the\njwk\nandalg\nfields from the JWT header, and theaud\n,iat\n, andemail\n, claims from the payload - verifying the JWT signature using the\njwk\nwith thealg\nalgorithm - verifying the\naud\nclaim exactly matches the issuer's identifier - verifying the\niat\nclaim is within 60 seconds of the current time - verifying the\nemail",
    "POST /email-verification/issuance HTTP/1.1\nHost: accounts.issuer.example\nCookie: session=...\nContent-Type: application/x-www-form-urlencoded\nSec-Fetch-Dest: email-verification\nrequest_token=eyJhbGciOiJFZERTQSIsInR5cCI6IkpXVC...\nOn receipt of a token request:\n-\n4.1 - the issuer MUST verify the request headers:\nContent-Type\nisapplication/x-www-form-urlencoded\nSec-Fetch-Dest\nisemail-verification\n-\n4.2 - the issuer MUST verify the request_token by:\n- parsing the JWT into header, payload, and signature components\n- confirming the presence of, and extracting the\njwk\nandalg\nfields from the JWT header, and theaud\n,iat\n, andemail\n, claims from the payload - verifying the JWT signature using the\njwk\nwith thealg\nalgorithm - verifying the\naud\nclaim exactly matches the issuer's identifier - verifying the\niat\nclaim is within 60 seconds of the current time - verifying the\nemail jwk\nwith thealg\nalgorithm - verifying the\naud\nclaim exactly matches the issuer's identifier - verifying the\niat\nclaim is within 60 seconds of the current time - verifying the\nemail\nclaim contains a syntactically valid email address\n-\n4.3 - the issuer checks if the cookies sent represent a logged in user, and if the logged in user has control of the email provided in the request_token. If so the issuer generates an SD-JWT with the following properties:\n- Header: MUST contain\nalg\n: signing algorithm (SHOULD match the algorithm from the request_token)kid\n: key identifier of key used to signtyp\nset to \"evp+sd-jwt\"\n- Payload: MUST contain the following claims:\niss\n: the issuer identifieriat\n: issued at timecnf\n: confirmation claim containing the public key from the request_token'sjwk\nfieldemail\n: claim containing the email address from the request_tokenemail_verified\n: claim that email is verified per OpenID Connect 1.0",
    "If so the issuer generates an SD-JWT with the following properties:\n- Header: MUST contain\nalg\n: signing algorithm (SHOULD match the algorithm from the request_token)kid\n: key identifier of key used to signtyp\nset to \"evp+sd-jwt\"\n- Payload: MUST contain the following claims:\niss\n: the issuer identifieriat\n: issued at timecnf\n: confirmation claim containing the public key from the request_token'sjwk\nfieldemail\n: claim containing the email address from the request_tokenemail_verified\n: claim that email is verified per OpenID Connect 1.0 fieldemail\n: claim containing the email address from the request_tokenemail_verified\n: claim that email is verified per OpenID Connect 1.0\n- Signature: MUST be signed with the issuer's private key corresponding to a public key in the\njwks_uri\nidentified bykid\n- Header: MUST contain\nExample header:\n{\n\"alg\": \"EdDSA\",\n\"kid\": \"2024-08-19\",\n\"typ\": \"evp+sd-jwt\"\n}\nExample payload:\n{\n\"iss\": \"issuer.example\",\n\"iat\": 1724083200,\n\"cnf\": {\n\"jwk\": {\n\"kty\": \"OKP\",\n\"crv\": \"Ed25519\",\n\"x\": \"11qYAYdk9E6z7mT6rk6j1QnXb6pYq4v9wXb6pYq4v9w\"\n}\n},\n\"email\": \"user@example.com\",\n\"email_verified\": true\n}\nThe resulting JWT has the ~\nappended to it, making it a valid SD-JWT. - 4.4 - the issuer returns the SD-JWT to the browser as the value of\nissuance_token\nin anapplication/json\nresponse. Example:\nHTTP/1.1 200 OK\nContent-Type: application/json\n{\"issuance_token\":\"eyJhbGciOiJFZERTQSIsImtpZCI6IjIwMjQtMDgtMTkiLCJ0eXAiOiJ3ZWItaWRlbnRpdHkrc2Qtand0In0...\"}",
    "Example:\nHTTP/1.1 200 OK\nContent-Type: application/json\n{\"issuance_token\":\"eyJhbGciOiJFZERTQSIsImtpZCI6IjIwMjQtMDgtMTkiLCJ0eXAiOiJ3ZWItaWRlbnRpdHkrc2Qtand0In0...\"} in anapplication/json\nresponse. Example:\nHTTP/1.1 200 OK\nContent-Type: application/json\n{\"issuance_token\":\"eyJhbGciOiJFZERTQSIsImtpZCI6IjIwMjQtMDgtMTkiLCJ0eXAiOiJ3ZWItaWRlbnRpdHkrc2Qtand0In0...\"}\nIf the issuer cannot process the token request successfully, it MUST return an appropriate HTTP status code with a JSON error response containing an error\nfield and optionally an error_description\nfield. When the request does not include the required Content-Type: application/x-www-form-urlencoded\nheader, the server MUST return the 415 HTTP response code\nWhen the request does not include the required Sec-Fetch-Dest: email-verification\nheader:\nHTTP 400 Bad Request\n{\n\"error\": \"invalid-request\",\n\"error_description\": \"Missing or invalid Sec-Fetch-Dest header\"\n}\nThe error_description\nSHOULD specify that the Sec-Fetch-Dest header is missing or invalid.",
    "When the request does not include the required Content-Type: application/x-www-form-urlencoded\nheader, the server MUST return the 415 HTTP response code\nWhen the request does not include the required Sec-Fetch-Dest: email-verification\nheader:\nHTTP 400 Bad Request\n{\n\"error\": \"invalid-request\",\n\"error_description\": \"Missing or invalid Sec-Fetch-Dest header\"\n}\nThe error_description\nSHOULD specify that the Sec-Fetch-Dest header is missing or invalid. {\n\"error\": \"invalid-request\",\n\"error_description\": \"Missing or invalid Sec-Fetch-Dest header\"\n}\nThe error_description\nSHOULD specify that the Sec-Fetch-Dest header is missing or invalid. When the request lacks valid authentication cookies, contains expired/invalid cookies, or the authenticated user does not have control of the requested email address:\nHTTP 401 Unauthorized\n{\n\"error\": \"authentication_required\",\n\"error_description\": \"User must be authenticated and have control of the requested email address\"\n}\nWhen the request_token\nis malformed, missing required claims, or contains invalid values:\nHTTP 400 Bad Request\n{\n\"error\": \"invalid_request\",\n\"error_description\": \"Invalid or malformed request_token\"\n}\nWhen the request_token\nsignature verification fails or the token structure is invalid:\nHTTP 400 Bad Request\n{\n\"error\": \"invalid_token\",\n\"error_description\": \"Token signature verification failed or token structure is invalid\"\n}\nFor internal server errors or temporary unavailability:",
    "When the request lacks valid authentication cookies, contains expired/invalid cookies, or the authenticated user does not have control of the requested email address:\nHTTP 401 Unauthorized\n{\n\"error\": \"authentication_required\",\n\"error_description\": \"User must be authenticated and have control of the requested email address\"\n}\nWhen the request_token\nis malformed, missing required claims, or contains invalid values:\nHTTP 400 Bad Request\n{\n\"error\": \"invalid_request\",\n\"error_description\": \"Invalid or malformed request_token\"\n}\nWhen the request_token\nsignature verification fails or the token structure is invalid:\nHTTP 400 Bad Request\n{\n\"error\": \"invalid_token\",\n\"error_description\": \"Token signature verification failed or token structure is invalid\"\n}\nFor internal server errors or temporary unavailability: HTTP 400 Bad Request\n{\n\"error\": \"invalid_token\",\n\"error_description\": \"Token signature verification failed or token structure is invalid\"\n}\nFor internal server errors or temporary unavailability:\nHTTP 500 Internal Server Error\n{\n\"error\": \"server_error\",\n\"error_description\": \"Temporary server error, please try again later\"\n}\nIn a future version of this spec, the issuer could prompt the user to login via a URL or with a Passkey request. On receiving the issuance_token\n:\n-\n5.1 - the browser MUST verify the SD-JWT per (SD-JWT spec) by:\n- parsing the SD-JWT into header, payload, and signature components\n- confirming the presence of, and extracting the\nalg\nandkid\nfields from the SD-JWT header, and theiss\n,iat\n,cnf\n,email\n, andemail_verified\nclaims from the payload - parsing the email domain from the\nemail\nclaim and looking up theTXT\nrecord for_email-verification.$EMAIL_DOMAIN\nto verify theiss\nclaim matches the issuer identifier in the DNS record - fetching the issuer's public keys from the",
    "On receiving the issuance_token\n:\n-\n5.1 - the browser MUST verify the SD-JWT per (SD-JWT spec) by:\n- parsing the SD-JWT into header, payload, and signature components\n- confirming the presence of, and extracting the\nalg\nandkid\nfields from the SD-JWT header, and theiss\n,iat\n,cnf\n,email\n, andemail_verified\nclaims from the payload - parsing the email domain from the\nemail\nclaim and looking up theTXT\nrecord for_email-verification.$EMAIL_DOMAIN\nto verify theiss\nclaim matches the issuer identifier in the DNS record - fetching the issuer's public keys from the email\nclaim and looking up theTXT\nrecord for_email-verification.$EMAIL_DOMAIN\nto verify theiss\nclaim matches the issuer identifier in the DNS record - fetching the issuer's public keys from the\njwks_uri\nspecified in the.well-known/email-verification\nfile - verifying the SD-JWT signature using the public key identified by\nkid\nfrom the JWKS with thealg\nalgorithm - verifying the\niat\nclaim is within 60 seconds of the current time - verifying the\nemail\nclaim matches the email address the user selected - verifying the\nemail_verified\nclaim is true\n-\n5.2 - the browser then creates an SD-JWT+KB by:\n- taking the verified SD-JWT from step 5.1 as the base token\n- creating a Key Binding JWT (KB-JWT) with the following structure:\n- Header:\nalg\n: same signing algorithm used by the browser's private keytyp\n: \"kb+jwt\"\n- Payload:\naud\n: the RP's originnonce\n: the nonce from the originalnavigator.credentials.get()\ncalliat\n: current time when creating the KB-JWTsd_hash\n: SHA-256 hash of the SD-JWT",
    "email\nclaim and looking up theTXT\nrecord for_email-verification.$EMAIL_DOMAIN\nto verify theiss\nclaim matches the issuer identifier in the DNS record - fetching the issuer's public keys from the\njwks_uri\nspecified in the.well-known/email-verification\nfile - verifying the SD-JWT signature using the public key identified by\nkid\nfrom the JWKS with thealg\nalgorithm - verifying the\niat\nclaim is within 60 seconds of the current time - verifying the\nemail\nclaim matches the email address the user selected - verifying the\nemail_verified\nclaim is true\n-\n5.2 - the browser then creates an SD-JWT+KB by:\n- taking the verified SD-JWT from step 5.1 as the base token\n- creating a Key Binding JWT (KB-JWT) with the following structure:\n- Header:\nalg\n: same signing algorithm used by the browser's private keytyp\n: \"kb+jwt\"\n- Payload:\naud\n: the RP's originnonce\n: the nonce from the originalnavigator.credentials.get()\ncalliat\n: current time when creating the KB-JWTsd_hash\n: SHA-256 hash of the SD-JWT : \"kb+jwt\"\n- Payload:\naud\n: the RP's originnonce\n: the nonce from the originalnavigator.credentials.get()\ncalliat\n: current time when creating the KB-JWTsd_hash\n: SHA-256 hash of the SD-JWT\n- Header:\n- signing the KB-JWT with the browser's private key (the same key pair generated in step 3.4)\n- concatenating the SD-JWT and the KB-JWT separated by a tilde (~) to form the SD-JWT+KB\nExample KB-JWT header:\n{ \"alg\": \"EdDSA\", \"typ\": \"kb+jwt\" }\nExample KB-JWT payload:\n{ \"aud\": \"https://rp.example\", \"nonce\": \"259c5eae-486d-4b0f-b666-2a5b5ce1c925\", \"salt\": \"kR7fY9mP3xQ8wN2vL5jH6tZ1cB4nM9sD8fG3hJ7kL2p\", \"iat\": 1724083260, \"sd_hash\": \"X9yH0Ajrdm1Oij4tWso9UzzKJvPoDxwmuEcO3XAdRC0\" }\n-\n5.3 - the browser sets a TBD hidden field and fires the TBD event ...\ndetails TBD\nThe RP web page now has the SD-JWT+KB from the event, and passes it to the RP server, or the token was posted to the RP server. details TBD\nThe RP server MUST verify the SD-JWT+KB by:\n-",
    "details TBD\nThe RP server MUST verify the SD-JWT+KB by:\n- details TBD\nThe RP web page now has the SD-JWT+KB from the event, and passes it to the RP server, or the token was posted to the RP server. details TBD\nThe RP server MUST verify the SD-JWT+KB by:\n-\n6.1 - the RP server receives the SD-JWT+KB from the web page\n-\n6.2 - the RP parses the SD-JWT+KB by separating the SD-JWT and KB-JWT components (separated by tilde ~)\n-\n6.3 - the RP verifies the KB-JWT by:\n- parsing the KB-JWT into header, payload, and signature components\n- confirming the presence of, and extracting the\nalg\nfield from the KB-JWT header, and theaud\n,nonce\n,iat\n, andsd_hash\nclaims from the payload - verifying the\naud\nclaim matches the RP's origin - verifying the\nnonce\nclaim matches the nonce from the RP's session with the web page - verifying the\niat\nclaim is within a reasonable time window - computing the SHA-256 hash of the SD-JWT and verifying it matches the\nsd_hash\nclaim\n-\n6.4 - the RP verifies the SD-JWT by:",
    "details TBD\nThe RP server MUST verify the SD-JWT+KB by:\n-\n6.1 - the RP server receives the SD-JWT+KB from the web page\n-\n6.2 - the RP parses the SD-JWT+KB by separating the SD-JWT and KB-JWT components (separated by tilde ~)\n-\n6.3 - the RP verifies the KB-JWT by:\n- parsing the KB-JWT into header, payload, and signature components\n- confirming the presence of, and extracting the\nalg\nfield from the KB-JWT header, and theaud\n,nonce\n,iat\n, andsd_hash\nclaims from the payload - verifying the\naud\nclaim matches the RP's origin - verifying the\nnonce\nclaim matches the nonce from the RP's session with the web page - verifying the\niat\nclaim is within a reasonable time window - computing the SHA-256 hash of the SD-JWT and verifying it matches the\nsd_hash\nclaim\n-\n6.4 - the RP verifies the SD-JWT by: iat\nclaim is within a reasonable time window - computing the SHA-256 hash of the SD-JWT and verifying it matches the\nsd_hash\nclaim\n-\n6.4 - the RP verifies the SD-JWT by:\n- parsing the SD-JWT into header, payload, and signature components\n- confirming the presence of, and extracting the\nalg\nandkid\nfields from the SD-JWT header, and theiss\n,iat\n,cnf\n,email\n, andemail_verified\nclaims from the payload - parsing the email domain from the\nemail\nclaim and looking up theTXT\nrecord for_email-verification.$EMAIL_DOMAIN\nto verify theiss\nclaim matches the issuer identifier in the DNS record - fetching the issuer's public keys from the\njwks_uri\nspecified in the.well-known/email-verification\nfile - verifying the SD-JWT signature using the public key identified by\nkid\nfrom the JWKS with thealg\nalgorithm - verifying the\niss\nclaim exactly matches the issuer identifier from the DNS record - verifying the\niat\nclaim is within a reasonable time window - verifying the\nemail_verified\nclaim is true\n-",
    "iat\nclaim is within a reasonable time window - computing the SHA-256 hash of the SD-JWT and verifying it matches the\nsd_hash\nclaim\n-\n6.4 - the RP verifies the SD-JWT by:\n- parsing the SD-JWT into header, payload, and signature components\n- confirming the presence of, and extracting the\nalg\nandkid\nfields from the SD-JWT header, and theiss\n,iat\n,cnf\n,email\n, andemail_verified\nclaims from the payload - parsing the email domain from the\nemail\nclaim and looking up theTXT\nrecord for_email-verification.$EMAIL_DOMAIN\nto verify theiss\nclaim matches the issuer identifier in the DNS record - fetching the issuer's public keys from the\njwks_uri\nspecified in the.well-known/email-verification\nfile - verifying the SD-JWT signature using the public key identified by\nkid\nfrom the JWKS with thealg\nalgorithm - verifying the\niss\nclaim exactly matches the issuer identifier from the DNS record - verifying the\niat\nclaim is within a reasonable time window - verifying the\nemail_verified\nclaim is true\n- iss\nclaim exactly matches the issuer identifier from the DNS record - verifying the\niat\nclaim is within a reasonable time window - verifying the\nemail_verified\nclaim is true\n-\n6.5 - the RP verifies the KB-JWT signature using the public key from the\ncnf\nclaim in the SD-JWT with thealg\nalgorithm from the KB-JWT header\nBelow are notes capturing some discussions of potential privacy implications. -\nThe email domain operator no longer learns which applications the user is verifying their email address to as the applications are no longer sending an email verification code to the user. By using an SD-JWT+KB, the browser intermediates the request and response so that the issuer does not learn the identity of the RP. -\nThe RP can infer if a user is logged into the issuer as the RP receives a SD-JWT when the user is logged in, and does not when the user is not logged in. -\nThe issuer may learn the user has email at a mail domain it is authoritative for that it did not know the user had.",
    "-\nThe issuer may learn the user has email at a mail domain it is authoritative for that it did not know the user had. -\nThe issuer may learn the user has email at a mail domain it is authoritative for that it did not know the user had. The web page would call an API passing the email address and nonce. It would return a promise that resolves to the SD_JWT or an error response. The API would only be callable after a user gesture such as clicking a button labelled verify on the web page. This provides the web page in more flexibility in how to gather the email address. For example, if the web page is using EVP for login, and the user has used different emails for login and those are stored in cookies, the page can display the list of emails and an option to provide a different one. The user can then select the email they want to use rather than having to type it into a text field.",
    "The user can then select the email they want to use rather than having to type it into a text field. In addition to, or instead of the browser sending cookies to the Issuer, the Issuer could return a WebAuthN request to the browser if it has credentials for the user identified by the email address. The browser would then interact with the user and provide the WebAuthN response to the Issuer, authenticating the user, and the Issuer would then return the SD-JWT. Rather than the DNS TXT record, the Mail Domain would host a JSON file in the .wellknown domain. This creates challenges for the long tail of individually owned domains:\n- would require a domain that is used just for email to now have to support a web server\n- the mail domain is usually an apex domain, which does not support CNAME, complicating hosting a web site",
    "Using bubblewrap to add sandboxing to NetBSD",
    "Using bubblewrap to add sandboxing to NetBSD Google Summer of Code 2025 Reports: Using bubblewrap to add sandboxing to NetBSD\nThis report was written by Vasyl Lanko as part of Google Summer of Code 2025. Introduction\nAs of the time of writing, there is no real sandboxing technique available to NetBSD. There is chroot, which can be considered a weak sandbox because it modifies the root directory of the process, effectively restricting the process' view of the file system, but it doesn't isolate anything else, so all networking, IPC, and mounts inside this restricted file system are the same as of the system, and are accessible. There has already been some research on implementing kernel-level isolation in NetBSD with tools like gaols, mult and netbsd-sandbox, but they haven't been merged to NetBSD. Other operating systems have their own ways to isolate programs, FreeBSD has jails, and Linux has namespaces. Project Goals",
    "Project Goals Project Goals\nThe goal of this project is to bring a new way of sandboxing to NetBSD. More specifically, we want to implement a mechanism like Linux namespaces. These namespaces allow the isolation of parts of the system from a namespace, or, as the user sees it, from an application. NetBSD has compat_linux to run Linux binaries on NetBSD systems, and the implementation of namespaces can also be utilized to emulate namespace-related functionality of Linux binaries. A simple example to visualize our intended result is to consider an application running under an isolated UTS namespace that modifies the hostname. From the system's view, the hostname remains the same old hostname, but from the application's view it sees the modified hostname. Project Implementation\nLinux has 8 namespace types, in this project we will focus on only 2 of them:\n- UTS namespace, it is the simplest so we can focus on building the general namespace infrastructure with little namespace-specific details",
    "Project Implementation\nLinux has 8 namespace types, in this project we will focus on only 2 of them:\n- UTS namespace, it is the simplest so we can focus on building the general namespace infrastructure with little namespace-specific details - UTS namespace, it is the simplest so we can focus on building the general namespace infrastructure with little namespace-specific details\n- mount namespace, it is a prerequisite to most other namespace types because UNIX follows the philosophy of \"everything is a file\", so we need a separate mount namespace to have different configuration files on the same location as the system. Linux creates namespaces via the unshare or clone system calls, and it will also be our way of calling the namespace creation logic. We setup the base for implementing Linux namespaces in the NetBSD kernel using kauth, the subsystem managing all authorization requests inside the kernel. It associates credentials with objects, and because the namespace lifecycle management is related to the credential lifecycle it handles all the credential inheritance and reference counting for us. (Thanks kauth devs!)",
    "(Thanks kauth devs!) We separate the implementation of each namespace in a different secmodel, resulting in a similar framework to Linux which allows the isolation of a single namespace type. Our implementation also allows users to pick whether they want to have namespace support, and of what kind, via compilation flags, just like in Linux. UTS namespace\nUTS stands for UNIX Timesharing System, because it allows multiple users to share a single computer system. Isolating the utsname\ncan be useful to give users the illusion that they have control over the system's hostname, and also, for example, to give different hostnames to virtual servers. The UTS namespace stores the namespace's hostname, domain name, and their lengths. To isolate the utsname\nwe need to first create a copy of the current UTS information, plus we need a variable containing the number of credentials referencing this namespace, or, in simpler terms, the reference count of this namespace.",
    "To isolate the utsname\nwe need to first create a copy of the current UTS information, plus we need a variable containing the number of credentials referencing this namespace, or, in simpler terms, the reference count of this namespace. This namespace specific information needs to be saved somewhere, and for that we use the credential's private_data\nfield, so we can use a UTS_key\nto save and retrieve UTS\nrelated information from the secmodel. The key specifies the type of information we want to retrieve from the private_data\n, hence using a UTS_key\nfor the UTS namespace. The key for each namespace is a fixed value (we don't create a new key for every credential), but the retrieved value for that key from different credentials may be different. We had to modify kernel code that was directly accessing the hostname\nand domainname\nvariables, to instead call get_uts()\n, which retrieves the UTS struct for the namespace of the calling process. We didn't modify occurrences in kernel drivers because drivers are not part of any namespace, so they should still access the system's resources directly. MNT namespace",
    "MNT namespace MNT namespace\nThe MNT namespace isolates mounts across namespaces. It is used to have different versions of mounted filesystems across namespaces, meaning a user inside a mount namespace can mount and unmount whatever they want without affecting or even breaking the system. The mount namespace structure in Linux is fairly complicated. To have something similar in NetBSD we need to be able to control the mounts accessed by each namespace, and for that we need to control what is each namespace's mountlist, this is also enough for unmounting file systems, because in practice we can just hide them. For the mount_namespace, mountlist structure and the number of credentials using the mount namespace are stored in the credential's private data with the MNT_key\n. Similarly to the UTS namespace, we had to modify kernel code to not directly access the mountlist\n, but instead go through a wrapper called get_mountlist()",
    "Similarly to the UTS namespace, we had to modify kernel code to not directly access the mountlist\n, but instead go through a wrapper called get_mountlist() . Similarly to the UTS namespace, we had to modify kernel code to not directly access the mountlist\n, but instead go through a wrapper called get_mountlist()\nwhich returns the correct mountlist for the namespace the calling process resides in. Implementation for the mount namespace is immensely more complex than for the UTS namespace, it involves having a good understanding of both Linux and NetBSD behaviour, and I would frequently find myself wondering how to implement something after reading the Linux man pages, which would lead to me looking for it in the Linux source code, understanding it, then going back to NetBSD source code, trying to implement it, and seeing it's too different to implement in the same way. Project Status\nYou can find all code written during this project in GitHub at maksymlanko/netbsd-src gsoc-bubblewrap\nbranch. Because I intend to continue this work outside of GSoC, I want to reinforce that this was the last commit still during GSoC on gsoc-bubblewrap",
    "Because I intend to continue this work outside of GSoC, I want to reinforce that this was the last commit still during GSoC on gsoc-bubblewrap branch. Because I intend to continue this work outside of GSoC, I want to reinforce that this was the last commit still during GSoC on gsoc-bubblewrap\nbranch and this was the last one for the mnt_ns\nstill WIP branch. The link includes implementation of general namespace code via secmodels, implementation of the UTS namespace and related ATF-tests, and the work-in-progress implementation of mount namespaces. The mount namespace functionality is not finished as it would require much more work than the time available for this project. To complete it, it would be required invasive and non-trivial changes to the original source code, and, of course, more time. Future Work\nAs previously mentioned, Linux has 8 namespace types, it is important to see which of the missing namespaces are considered useful and feasible to implement.",
    "Future Work\nAs previously mentioned, Linux has 8 namespace types, it is important to see which of the missing namespaces are considered useful and feasible to implement. Future Work\nAs previously mentioned, Linux has 8 namespace types, it is important to see which of the missing namespaces are considered useful and feasible to implement. I believe that after mount namespaces it would be interesting to implement PID namespaces as this in combination with mount namespaces would permit process isolation from this sandbox. Afterwards, implementing user namespaces would allow users to get capabilities similar to root\nin the namespace, giving them sudo\npermissions while still restricting system-wide actions like shutting down the machine. A lower hanging fruit is to implement the namespace management functionality, which in Linux is lsns to list existing namespaces, and setns to move the current process to an already existing namespace. Challenges\n- Semantics. Did you know the unmount system call with MNT_FORCE flag in Linux (usually) returns EBUSY, and in NetBSD it forces the unmounting? One of them makes it easier to implement mount namespaces.",
    "One of them makes it easier to implement mount namespaces. - The behaviour of namespaces is not fully specified in the man pages. If something is not clear from the man pages you need to read the source code. - Unexpected need to learn a lot of VFS concepts and their differences in NetBSD and Linux. - There was a much bigger research component than I anticipated. In the end, Linux and NetBSD are different operating systems, implemented in different ways. Linux is complex and it is not trivial to port namespaces to NetBSD. Notes\nThe project is called \"Using bubblewrap to add sandboxing to NetBSD\" and was initially projected to emulate the unshare\nsystem call into compat_linux\n, but, seeing that having namespaces could be useful for NetBSD, and that it would be easy to add to compat_linux\nafterwards, we decided to instead implement namespaces directly in the NetBSD kernel. Implementing other system calls necessary to make the bwrap",
    "Implementing other system calls necessary to make the bwrap afterwards, we decided to instead implement namespaces directly in the NetBSD kernel. Implementing other system calls necessary to make the bwrap\nlinux binary work correctly also wouldn't be as satisfying as implementing namespaces directly into NetBSD, so this was why the project was initially called \"Using bubblewrap to add sandboxing to NetBSD\" but nowadays it would be more accurate to call it \"Sandboxing in NetBSD with Linux-like namespaces\". Thanks\nI am very grateful to Google for Google Summer of Code, because without it I wouldn't have learned so much this summer, wouldn't have met with smart and interesting people, and for sure wouldn't have tried to contribute to a project like NetBSD, even if I always wanted to write operating systems code... But, the biggest thing I will take with me from this project is the confidence to be able to contribute to NetBSD and other open source projects.",
    "But, the biggest thing I will take with me from this project is the confidence to be able to contribute to NetBSD and other open source projects. I would also like to thank the members of the NetBSD organization for helping me throughout this project, and more specifically:\n- Taylor R. Campbell, Harold Gutch and Nia Alarie from IRC, for helping me fix a nasty\nLD_LIBRARY_PATH\nbug I had on my system which wouldn't let me finish compiling NetBSD, and general GSoC recomendations. - Emmanuel Dreyfus from\ntech-kern\n, with whom I discussed ideas for projects and proposal suggestions, and in the end inspired the namespaces project. - Christoph Badura and Leonardo Taccari who volunteered to be my mentors. They took time to research and answer my questions, anticipated possible problems in my approaches, and always pointed me in the right direction, daily, during all of GSoC's period. This project is from the 3 of us.",
    "Montana Becomes First State to Enshrine 'Right to Compute' into Law",
    "Montana Becomes First State to Enshrine 'Right to Compute' into Law Montana has made history as the first state in the U.S. to legally protect its citizens\u2019 right to access and use computational tools and artificial intelligence technologies. Governor Greg Gianforte signed Senate Bill 212, officially known as the Montana Right to Compute Act (MRTCA), into law. The groundbreaking legislation affirms Montanans\u2019 fundamental right to own and operate computational resources \u2014 including hardware, software, and AI tools \u2014 under the state\u2019s constitutional protections for property and free expression. Supporters of the bill say it represents a major step in securing digital freedoms in an increasingly AI-driven world. \u201cMontana is once again leading the way in defending individual liberty,\u201d said Senator Daniel Zolnikov, the bill\u2019s sponsor and a longtime advocate for digital privacy. \u201cWith the Right to Compute Act, we are ensuring that every Montanan can access and control the tools of the future.\u201d",
    "\u201cWith the Right to Compute Act, we are ensuring that every Montanan can access and control the tools of the future.\u201d While the law allows state regulation of computation in the interest of public health and safety, it sets a high bar: any restrictions must be demonstrably necessary and narrowly tailored to serve a compelling interest. Legal experts note that this is one of the most protective standards available under Montana law. The act also includes provisions for AI-controlled critical infrastructure, requiring both a \u201cshutdown mechanism\u201d to allow human control and annual safety reviews \u2014 a move aimed at balancing innovation with public safety concerns. The bill has drawn praise from privacy advocates and tech policy groups. Tanner Avery, Policy Director at the free-market think tank Frontier Institute, called the law a \u201cflag in the ground\u201d for digital rights, adding: \u201cMontana has made clear it will treat any attempt to infringe on fundamental digital freedoms with the utmost scrutiny.\u201d",
    "Tanner Avery, Policy Director at the free-market think tank Frontier Institute, called the law a \u201cflag in the ground\u201d for digital rights, adding: \u201cMontana has made clear it will treat any attempt to infringe on fundamental digital freedoms with the utmost scrutiny.\u201d The MRTCA stands in stark contrast to recent regulatory efforts in other states, such as California, Virginia, and New York, where proposals to rein in AI technologies have either failed or been heavily revised. Montana\u2019s approach leans toward empowering individual users rather than restricting access. The law has already inspired similar efforts in New Hampshire, where lawmakers are pushing a constitutional amendment guaranteeing access to computation. Rep. Keith Ammon, the state\u2019s Majority Floor Leader, praised Montana\u2019s leadership: \u201cThis is the kind of bold move that sets the tone for the rest of the country.\u201d\nNationally, the Right to Compute movement is gaining traction. Spearheaded by the grassroots group RightToCompute.ai, the campaign argues that computation \u2014 like speech and property \u2014 is a fundamental human right. \u201cA computer is an extension of the human capacity to think,\u201d the organization states.",
    "\u201cA computer is an extension of the human capacity to think,\u201d the organization states. The movement is supported by Haltia.AI, a Dubai-based AI startup, and the ASIMOV Protocol, a blockchain consortium advocating for decentralized AI infrastructure. Talal Thabet, Co-Founder of both groups, praised Montana\u2019s law as \u201ca monumental step forward in ensuring individuals retain control of their own data and digital tools.\u201d\nAs debates over AI governance and digital rights continue to evolve, Montana\u2019s bold new law could serve as a blueprint for other states seeking to safeguard freedom in the digital era.",
    "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
    "Zensical \u2013 A modern static site generator built by the Material for MkDocs team Zensical \u2013 A modern static site generator built by the Material for MkDocs team\u00b6\nWe are thrilled to announce Zensical, our next-gen static site generator designed to simplify the process of building documentation sites. Distilled from a decade of experience, Zensical is our effort to overcome the technical limitations of MkDocs, reaching far beyond its capabilities. Zensical is the result of thousands of hours of work \u2013 built from the ground up for a modern and comfortable authoring experience, while making it easy for developers to extend and customize Zensical through its upcoming module system. Our goal is to support docs-as-code workflows with tens of thousands of pages, without compromising performance or usability. To make the transition seamless, compatibility comes first. We're putting significant effort into ensuring a smooth migration from Material for MkDocs for all users. Zensical can natively read mkdocs.yml",
    "Zensical can natively read mkdocs.yml , allowing you to build your existing project with minimal changes. As of now, a subset of plugins is supported, and we're working on feature parity in the coming months. Zensical is fully Open Source, licensed under MIT, and can be used for any purpose, including for commercial use. We're also saying goodbye to our sponsorware model, replacing it with our new offering for professional users: Zensical Spark. This allows us to stay independent, maximizing user value, as we shape the future of Zensical together with you. You can subscribe to our newsletter to stay in the loop. This is the second article in a four-part series:\n- Transforming Material for MkDocs\n- Zensical \u2013 A modern static site generator built by the creators of Material for MkDocs. - What happens to the features in Insiders coming November 11, 2025\n- A path forward for our community coming November 18, 2025\nWhy Zensical?\u00b6",
    "- What happens to the features in Insiders coming November 11, 2025\n- A path forward for our community coming November 18, 2025\nWhy Zensical?\u00b6 - What happens to the features in Insiders coming November 11, 2025\n- A path forward for our community coming November 18, 2025\nWhy Zensical?\u00b6\nSince its initial release in 2016, Material for MkDocs has helped tens of thousands of teams to publish and maintain reliable documentation. However, in recent years, it has become apparent that we were running up against limitations of our core dependency, MkDocs. These limitations proved impossible to overcome as they are deeply rooted in its architecture. We also mentioned in our update on our foundational work that MkDocs must be considered a supply chain risk, since it's unmaintained since August 2024. It has seen no releases in over a year and is accumulating unresolved issues and pull requests. These developments have forced us to cut our ties to MkDocs as a dependency.",
    "These developments have forced us to cut our ties to MkDocs as a dependency. In order to map out a path forward, we went back to the drawing board, talked to dozens of our professional users and thoroughly analyzed the MkDocs ecosystem. We didn't just want to create a fork or port of MkDocs, but decided to rethink static site generation from first principles. With Zensical, we are creating a modern static site generator, which is compatible with your content and customizations, and addresses MkDocs' limitations. While Material for MkDocs is built on top of MkDocs, Zensical consolidates both projects into one coherent stack, covering static site generation, theming, and customization. What you can expect today:\nAlthough we haven't reached full feature parity yet, you can already use Zensical to build your existing Material for MkDocs projects with minimal changes. You can jump to the compatibility section to learn what is already supported. What you can expect\u00b6\nSolid foundation\u00b6",
    "What you can expect\u00b6\nSolid foundation\u00b6 You can jump to the compatibility section to learn what is already supported. What you can expect\u00b6\nSolid foundation\u00b6\nOur goal with Zensical is to create a coherent and modern stack, vertically integrating all parts of the authoring experience (AX), developer experience (DX), and user experience (UX). This gives us a significant competitive advantage over solutions that overly rely on third-party frameworks and dependencies, helping us to create much more robust Open Source software. ZRX, our new differential build engine, creates a solid foundation for Zensical, and is an Open Source project of its own. It's a fresh take on making differential data flows easy to build and a joy to work with. Most engineering effort has gone into ZRX, as it forms the backbone of Zensical, and will allow us to ship features faster.",
    "Most engineering effort has gone into ZRX, as it forms the backbone of Zensical, and will allow us to ship features faster. Following the principle of architectural hoisting, we moved essential, reusable functionality into ZRX, which allows us to keep Zensical's core simple and focused on static site generation. ZRX handles the heavy lifting \u2013 differential builds, caching, and data flow orchestration. With the upcoming module system and component system, both of which are on our public roadmap, Zensical will gain more degrees of freedom in the coming months, allowing you to extend and customize Zensical in ways that were previously impossible with MkDocs. Modern design\u00b6\nZensical brings a fresh, modern design that breaks out of the Materal Design aesthetic, creating a visual foundation that is more easily brandable and adaptable to different use cases. The new design prioritizes clarity, simplicity, and usability, while having a more professional finish:",
    "The new design prioritizes clarity, simplicity, and usability, while having a more professional finish: Right now, the layout and site structure of Zensical match Material for MkDocs closely, as we're focusing on ensuring maximum compatibility. Once we finish work on our upcoming component system, we'll provide an alternative that is much more flexible and adaptable, and can be tailored to different use cases and branding requirements more easily. You can also keep the Material for MkDocs look and feel with a single line of configuration. Blazing-fast search\u00b6\nClient-side search isn't a compromise \u2013 for the vast majority of static sites, it's the best solution, since it's faster, involves zero maintenance, and doesn't require you to pay for a service. As covered in depth in the first part of this series, the current search implementation in Material for MkDocs has severe limitations, and is based on a now unmaintained library, which is why we decided to build a new search engine from scratch. It's based on the same goals as Zensical itself: performance, flexibility, and extensibility.",
    "It's based on the same goals as Zensical itself: performance, flexibility, and extensibility. Disco, our modular and blazing-fast client-side search engine, is exclusively available in Zensical. When you build your site with Zensical, your users will immediately benefit from Disco's improved ranking algorithm, as well as its filtering and aggregation capabilities:\nIn early 2026, we'll be releasing Disco as a standalone Open Source project. With the feedback of our professional users in Zensical Spark, we're going to evolve the search experience, turning Disco into a highly configurable and customizable search engine that adapts to your needs. You can subscribe to our newsletter to receive news about Disco. Authoring experience\u00b6\nSlow feedback loops can be a major pain point when writing documentation. Almost all of us know the feeling of waiting for the static site generator to finish building the site, just to see a small change reflected in the output. With Zensical, we're finally addressing this issue.",
    "With Zensical, we're finally addressing this issue. It's important to understand that we're not yet utilizing the differential capabilities of ZRX to the fullest extent, as we're forced to make several compromises to ensure maximum compatibility with Material for MkDocs at the moment. Markdown rendering needs to go through Python Markdown, which forces us to pay for extra marshalling costs. While the initial build can sometimes be slower than with MkDocs, repeated builds \u2013 especially when serving the site \u2013 are already 4 to 5x faster, as only changed files need to be rebuilt. We're also working on a new Markdown toolchain based on a CommonMark-compliant parser written in Rust, which will make Markdown processing significantly faster. We'll be tackling this as part of the upcoming component system, which we'll start working on in early 2026. Once our new Markdown toolchain is ready, we'll provide automated tools to translate between Python Markdown and CommonMark, so you don't need to manually migrate your content.",
    "Once our new Markdown toolchain is ready, we'll provide automated tools to translate between Python Markdown and CommonMark, so you don't need to manually migrate your content. Maximum compatibility\u00b6\nCompatibility with Material for MkDocs is our top priority. We understand that switching to a new static site generator can be challenging, especially for large projects with many customizations. Therefore, we've put significant effort into ensuring that Zensical understands mkdocs.yml\nconfiguration files, so that you can build your projects with minimal changes. This means your existing Markdown files, template overrides, CSS and JavaScript extensions don't need to be touched, primarily because we did not change the generated HTML, and rely on Python Markdown for processing your content. However, plugins are a different story. In MkDocs, practically all plugins have side effects, making it impossible to parallelize builds. We started from first principles and asked: what should extensibility look like in a modern static site generator? Our answer is the upcoming module system, which takes a fundamentally different approach based on four core principles:",
    "Our answer is the upcoming module system, which takes a fundamentally different approach based on four core principles: - Modules can inject, extend, and re-define functionality\n- Modules are deterministic through topological ordering\n- Modules foster reusability, with the possibility to remix them\n- Modules can cooperate through well-defined contracts\nWe're working on shipping essential functionality as provided by MkDocs plugins as built-in modules. In early 2026, we will open the module system to third-party developers, so they can start building their own modules, as we see Zensical as the heart of a thriving ecosystem. Zensical Spark\u00b6\nZensical Spark, our offering for professionals, is the result of countless calls with professional users of Material for MkDocs. From startups to large enterprises, we enable organizations to realize complex projects in diverse environments. For this, we've created Zensical Spark as a collaborative space. If you're a professional user, Zensical Spark is for you, since:\n-",
    "If you're a professional user, Zensical Spark is for you, since:\n- -\nYou can be confident that Zensical will continue to be developed and maintained in the long term as a set of interconnected and sustainable OSI-compliant Open Source projects. -\nYou can receive the support you need to successfully use, configure and customize Zensical in your organization, receiving first-class support from the Zensical team. -\nYou can influence the future development of Zensical by participating in our new approach to Open Source software development, helping us to build exactly what you need. Let's talk! If you're working in a professional context, reach out to contact@zensical.org to schedule a call and learn how Zensical Spark enables your team to transition to Zensical smoothly and have a voice in its continued development. You should also consider joining the waiting list, since seats are limited. We're growing our team\u00b6\nWe're also excited to announce that we're growing our team:\nTimoth\u00e9e Mazzucotelli, also known as @pawamoy, is joining Zensical!",
    "We're growing our team\u00b6\nWe're also excited to announce that we're growing our team:\nTimoth\u00e9e Mazzucotelli, also known as @pawamoy, is joining Zensical! We're growing our team\u00b6\nWe're also excited to announce that we're growing our team:\nTimoth\u00e9e Mazzucotelli, also known as @pawamoy, is joining Zensical! At Zensical, Tim is focusing on providing the same seamless experience for generating API reference documentation from source code (via docstrings) as he has done with mkdocstrings, the second biggest project in the MkDocs ecosystem. With his expertise, and Zensical's new stack, we'll be pushing the boundaries of what's possible with API reference documentation. Goodbye, GitHub Sponsors\u00b6\nThank you! To all of you who have supported us over the years through GitHub Sponsors \u2013 we are incredibly grateful for your support. It has been invaluable in helping us to build, maintain and evolve Material for MkDocs, and we couldn't have done it without you. Seriously, thank you!",
    "Seriously, thank you! Material for MkDocs gave us something invaluable: experience building for tens of thousands of users, and the opportunity to build a team around Open Source software. It showed us that making a living from Open Source isn't just possible \u2013 we grew it into one of the largest sponsorware projects on GitHub and inspired others to pursue similar paths. Now we're breaking new ground. Zensical is our next chapter, and we're professionalizing how we approach Open Source development. Our vision is to make Zensical free for everyone to use while building a sustainable business around it through our new approach. This transition means saying goodbye to GitHub Sponsors. It has served us exceptionally well, but as we professionalize and scale, we're making the leap from personal project to company \u2013 building a business and team that can meet the growing demands of professional users while staying true to our values. We're doubling down on Open Source, developing software for everyone.",
    "We're doubling down on Open Source, developing software for everyone. We're doubling down on Open Source, developing software for everyone. If you want to continue supporting our work, please subscribe to our newsletter. We'll be providing new methods to support us in the coming months, with the possibility of getting exclusive goodies. Looking Ahead\u00b6\nMaterial for MkDocs grew organically in a pot that eventually became too small. With Zensical, we're building on solid foundations designed to grow with us \u2013 and with you. Material for MkDocs is now in maintenance mode\nWe want to be transparent about the risks of staying on Material for MkDocs. With MkDocs unmaintained and facing fundamental supply chain concerns, we cannot guarantee Material for MkDocs will continue working reliably in the future. We're aware that transitioning takes time, which is why we commit to support it at least for the next 12 months, fixing critical bugs and security vulnerabilities as needed, but the path forward is with Zensical.",
    "We're aware that transitioning takes time, which is why we commit to support it at least for the next 12 months, fixing critical bugs and security vulnerabilities as needed, but the path forward is with Zensical. If documentation plays a critical role in your organization, and you're worried how this might affect your business, consider joining Zensical Spark, or feel free to schedule a call by reaching out at contact@zensical.org. Where we'll be in 12 months\u00b6\nOver the next 12 months, following our phased transition strategy, we'll reach Phase 2 and 3 \u2013 introducing our module system and component system, as well as CommonMark support. By replacing Python Markdown with a Rust-based Markdown parser, we'll unlock performance improvements and the modularity needed for flexible templating. This is where Zensical truly starts to unfold its capabilities. Zensical is already powering real projects due to extensive compatibility with Material for MkDocs. We're actively working on closing the gap to reach full feature parity. You can install Zensical now, and build your existing Material for MkDocs projects with it. If you run into a bug, please don't hesitate to open an issue \u2013 we're here to help.",
    "If you run into a bug, please don't hesitate to open an issue \u2013 we're here to help. You can install Zensical now, and build your existing Material for MkDocs projects with it. If you run into a bug, please don't hesitate to open an issue \u2013 we're here to help. Connect with us\u00b6\nIf you have questions we haven't addressed, please reach out to us at contact@zensical.org. We're currently collecting questions from the community about Zensical, and will address them in an FAQ section as part of our documentation in the coming weeks. We're incredibly thankful that you have been part of our journey so far. With Zensical, we're embarking on a new chapter, and we couldn't be more excited to have you with us. You can subscribe to our newsletter to stay in the loop.",
    "I Am Mark Zuckerberg",
    "I Am Mark Zuckerberg Welcome to iammarkzuckerg.com\nNo, not THAT Mark Zuckerberg-this one's busy helping Hoosiers, not launching social networks. Relax, you haven't accidentally logged into Facebook or the Metaverse. You're on the site of Mark S. Zuckerberg, Indiana's original bearer of the name, proud bankruptcy attorney, and frequent recipient of confused emails from people seeking tech support or handouts of money. What I Really Do:\n- Help people obtain a fresh financial start (no passwords required)\n- Offer dependable, human-involved advice (my artificial intelligence is powered by coffee)\n- Answer local legal questions, not privacy scandals\nReal Zuckerberg Facts:\n- Shares a name, not fortune, with the Facebook founder\n- Gets mistaken daily for a tech billionaire\n- Has written zero social media apps, but plenty of court briefs\nFun Fact:\nIn Indiana, saying \"I'm Mark Zuckerberg\" gets more laughs than likes. But if you need trustworthy bankruptcy help, you're in exactly the right place!",
    "But if you need trustworthy bankruptcy help, you're in exactly the right place! Fun Fact:\nIn Indiana, saying \"I'm Mark Zuckerberg\" gets more laughs than likes. But if you need trustworthy bankruptcy help, you're in exactly the right place! Click around, get to know your (non-billionaire) local Mark, and remember: No login required. Click Here to See How Other\nWebsites Have Reacted to This\nInteresting Things That Have Happened to Me Because My Name is Mark Zuckerberg\nFor a complete list of things that have happened to Mark Zuckerberg click here\nLike I said, I don't wish Mark E. Zuckerberg any ill will at all. I hope the best for him, but let me tell you this: I will rule the search for \"Mark Zuckerberg bankruptcy\". And if he does fall upon difficult financial times, and happens to be in Indiana, I will gladly handle his case in honor of our eponymy.",
    "Ironclad \u2013 formally verified, real-time capable, Unix-like OS kernel",
    "Ironclad \u2013 formally verified, real-time capable, Unix-like OS kernel Ironclad is a (partially) formally verified, real-time capable, UNIX-like operating system kernel for general-purpose and embedded uses. It is written in SPARK and Ada, and is comprised of 100% free software. Ironclad features a familiar POSIX-compatible interface, true simultaneous preemptive multitasking, Mandatory Access Control (MAC), and support for hard real-time scheduling. Ironclad is fully open source and distributed under the GPLv3, ensuring it remains free. No firmware blobs are needed or shipped with the kernel. Every piece of the stack is open source. SPARK's state of the art formal verification is employed for ensuring absence of errors and correctness of big portions of Ironclad, like cryptography, MAC, and user-facing facilities. Ported to several platforms and boards, and designed to be easily portable to many more. Dependency on only the GNU toolchain allows for easy cross-compilation.",
    "Dependency on only the GNU toolchain allows for easy cross-compilation. Ported to several platforms and boards, and designed to be easily portable to many more. Dependency on only the GNU toolchain allows for easy cross-compilation. Ironclad will always be free for use, study, and modification, so, to support the project, we rely on the use of donations and grants. Every contribution makes a difference and allows us to do more. This project is funded through NGI Zero Core, a fund established by NLnet with financial support from the European Commission's Next Generation Internet program. Learn more at the NLnet project page. Additionally, we would like to thank the following organizations:",
    "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
    "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf Review\nSelective Serotonin Reuptake Inhibitors and Adverse Effects:\nA Narrative Review\nAmber N. Edinoff 1,*, Haseeb A. Akuly 1\n, Tony A. Hanna 1, Carolina O. Ochoa 2, Shelby J. Patti 2,\nYahya A. Ghaffar 2, Alan D. Kaye 3, Omar Viswanath 4,5,6, Ivan Urits 3,7\n, Andrea G. Boyer 8, Elyse M. Cornett 3\nand Adam M. Kaye 9\n\u0001\u0002\u0003\u0001\u0004\u0005\u0006\u0007\b\u0001\n\u0001\u0002\u0003\u0004\u0005\u0006\u0007\nCitation: Edinoff, A.N. ; Akuly, H.A. ;\nHanna, T.A. ; Ochoa, C.O. ; Patti, S.J. ;\nGhaffar, Y.A. ; Kaye, A.D.; Viswanath,\nO.; Urits, I.; Boyer, A.G.; et al. Selective Serotonin Reuptake\nInhibitors and Adverse Effects: A\nNarrative Review. Neurol. Int. 2021,\n13, 387\u2013401. https://doi.org/\n10.3390/neurolint13030038\nAcademic Editors: Marcello Moccia\nand Motohiro Okada\nReceived: 20 May 2021\nAccepted: 5 July 2021\nPublished: 5 August 2021\nPublisher\u2019s Note: MDPI stays neutral\nwith regard to jurisdictional claims in\npublished maps and institutional af\ufb01l-\niations. Copyright: \u00a9 2021 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article",
    "This article is an open access article with regard to jurisdictional claims in\npublished maps and institutional af\ufb01l-\niations. Copyright: \u00a9 2021 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article\ndistributed\nunder\nthe\nterms\nand\nconditions of the Creative Commons\nAttribution (CC BY) license (https://\ncreativecommons.org/licenses/by/\n4.0/). 1\nDepartment of Psychiatry and Behavioral Medicine, Louisiana State University Health Science Center\nShreveport, Shreveport, LA 71103, USA; haseeb.akuly@lsuhs.edu (H.A.A. ); thanna@lsuhsc.edu (T.A.H.) 2\nSchool of Medicine, Louisiana State University Shreveport, Shreveport, LA 71103, USA;\ncochoa@lsuhsc.edu (C.O.O. ); spatt5@lsuhsc.edu (S.J.P. ); yghaff@lsuhsc.edu (Y.A.G.) 3\nDepartment of Anesthesiology, Louisiana State University Shreveport, Shreveport, LA 71103, USA;\nalan.kaye@lsuhs.edu (A.D.K. ); ivanurits@gmail.com (I.U. ); ecorne@lsuhsc.edu (E.M.C.) 4\nCollege of Medicine-Phoenix, University of Arizona, Phoenix, AZ 85004, USA; viswanoy@gmail.com\n5",
    "4\nCollege of Medicine-Phoenix, University of Arizona, Phoenix, AZ 85004, USA; viswanoy@gmail.com\n5 alan.kaye@lsuhs.edu (A.D.K. ); ivanurits@gmail.com (I.U. ); ecorne@lsuhsc.edu (E.M.C.) 4\nCollege of Medicine-Phoenix, University of Arizona, Phoenix, AZ 85004, USA; viswanoy@gmail.com\n5\nDepartment of Anesthesiology, Creighton University School of Medicine, Omaha, NE 68124, USA\n6\nValley Anesthesiology and Pain Consultants\u2014Envision Physician Services, Phoenix, AZ 85004, USA\n7\nSouthcoast Physicians Group Pain Medicine, Southcoast Health, Wareham, MA 02571, USA\n8\nDepartment of Psychiatry and Behavioral Sciences, Medical University of South Carolina,\nCharleston, SC 29464, USA; alg709@gmail.com\n9\nDepartment of Pharmacy Practice, Thomas J. Long School of Pharmacy and Health Sciences, University of the\nPaci\ufb01c, Stockton, CA 95211, USA; akaye@PACIFIC.EDU\n*\nCorrespondence: amber.edinoff@lsuhsc.edu; Tel. : +1-(318)-675-8969\nAbstract: Depression is the most prevalent psychiatric disorder in the world, affecting 4.4% of the",
    ": +1-(318)-675-8969\nAbstract: Depression is the most prevalent psychiatric disorder in the world, affecting 4.4% of the *\nCorrespondence: amber.edinoff@lsuhsc.edu; Tel. : +1-(318)-675-8969\nAbstract: Depression is the most prevalent psychiatric disorder in the world, affecting 4.4% of the\nglobal population. Despite an array of treatment modalities, depressive disorders remain dif\ufb01cult\nto manage due to many factors. Beginning with the introduction of \ufb02uoxetine to the United States\nin 1988, selective serotonin reuptake inhibitors (SSRIs) quickly became a mainstay of treatment\nfor a variety of psychiatric disorders. The primary mechanism of action of SSRIs is to inhibit\npresynaptic reuptake of serotonin at the serotonin transporter, subsequently increasing serotonin at\nthe postsynaptic membrane in the serotonergic synapse. The six major SSRIs that are marketed in the\nUSA today, \ufb02uoxetine, citalopram, escitalopram, paroxetine, sertraline, and \ufb02uvoxamine, are a group\nof structurally unrelated molecules that share a similar mechanism of action. While their primary",
    "While their primary USA today, \ufb02uoxetine, citalopram, escitalopram, paroxetine, sertraline, and \ufb02uvoxamine, are a group\nof structurally unrelated molecules that share a similar mechanism of action. While their primary\nmechanism of action is similar, each SSRI has unique pharmacokinetics, pharmacodynamics, and\nside effect pro\ufb01le. One of the more controversial adverse effects of SSRIs is the black box warning for\nincreased risk of suicidality in children and young adults aged 18\u201324. There is a lack of understanding\nof the complexities and interactions between SSRIs in the developing brain of a young person with\ndepression. Adults, who do not have certain risk factors, which could be confounding factors, do not\nseem to carry this increased risk of suicidality. Ultimately, when prescribing SSRIs to any patient,\na risk\u2013bene\ufb01t analysis must factor in the potential treatment effects, adverse effects, and dangers of",
    "Ultimately, when prescribing SSRIs to any patient,\na risk\u2013bene\ufb01t analysis must factor in the potential treatment effects, adverse effects, and dangers of a risk\u2013bene\ufb01t analysis must factor in the potential treatment effects, adverse effects, and dangers of\nthe illness to be treated. The aim of this review is to educate clinicians on potential adverse effects\nof SSRIs. Keywords: selective serotonin reuptake inhibitors; adverse effects; suicidality\n1. Introduction\nDepression is the most prevalent psychiatric disorder in the world, affecting 4.4% of\nthe global population [1]. In the United States alone, the economic burden of the major\ndepressive disorder increased by 21.5% from 2005 to 2015, when it was estimated to be\nUSD 210.5 million/billion [2]. There are several types of depression and to differentiate\nthere are speci\ufb01ers that can be included. These are atypical features, anxious distressed,\nNeurol. Int. 2021, 13, 387\u2013401. https://doi.org/10.3390/neurolint13030038\nhttps://www.mdpi.com/journal/neurolint\nNeurol. Int. 2021, 13\n388\nmixed features, melancholic features, psychotic features, catatonia, peripartum onset, and",
    "2021, 13\n388\nmixed features, melancholic features, psychotic features, catatonia, peripartum onset, and https://www.mdpi.com/journal/neurolint\nNeurol. Int. 2021, 13\n388\nmixed features, melancholic features, psychotic features, catatonia, peripartum onset, and\nseasonal pattern [3]. Each different type of depression may respond better to a certain\ntype of pharmacologic treatment than others. Despite an array of treatment modalities,\ndepressive disorders remain dif\ufb01cult to manage due to many factors, including relatively\nhigh relapse rates while undergoing treatment and unfavorable side effect pro\ufb01les of the\nmedications available [4,5]. Preceding the discovery of selective serotonin reuptake inhibitors (SSRIs), monoamine\noxidase inhibitors (MAOIs), and tricyclic antidepressants (TCAs) were the only options\nfor pharmacologic intervention in depressive disorders. These drugs, however, had un-\nfavorable side effect pro\ufb01les, resulting in poor patient adherence. Consuming too much\ntyramine while on an MAOI may cause a potentially deadly hypertensive crisis. TCAs can",
    "TCAs can favorable side effect pro\ufb01les, resulting in poor patient adherence. Consuming too much\ntyramine while on an MAOI may cause a potentially deadly hypertensive crisis. TCAs can\ncause blockage of cardiac sodium channels and cardiac arrhythmias [6]. Beginning with the introduction of \ufb02uoxetine to the United States in 1988, SSRIs\nquickly became a mainstay of treatment for a variety of psychiatric disorders. They were\noriginally studied to target depression, but further investigation has led to their use in\nmany anxiety disorders. SSRIs were not more effective than TCAs but had increased rates\nof patient adherence [7], largely due to their more favorable side effect pro\ufb01le. Despite\nbeing an immense step forward in the management of psychiatric disorders, SSRIs still\nhave a variety of adverse effects that need to be reviewed and monitored. The primary mechanism of action of SSRIs is to inhibit the presynaptic reuptake of",
    "The primary mechanism of action of SSRIs is to inhibit the presynaptic reuptake of have a variety of adverse effects that need to be reviewed and monitored. The primary mechanism of action of SSRIs is to inhibit the presynaptic reuptake of\nserotonin at the serotonin transporter, subsequently increasing serotonin at the postsynaptic\nmembrane in the serotonergic synapse [8]. Interestingly, the therapeutic effects of SSRIs\ncannot be entirely summed up by simple inhibition of serotonin transporter (SERT), and\nas such further mechanisms of action must be at work. A current theory posits that\nthe neuronal stress caused by SSRIs causes a shift in brain homeostasis that results in\ndownregulation of SERTs in some areas of the brain and upregulation in others [9]. This\nmechanism may explain why the full therapeutic effects of SSRIs are not realized until four\nto six weeks after initiation, despite signi\ufb01cant immediate alterations in serotonin \ufb02ux. The\naim of this review to educate clinicians on potential adverse effects of SSRIs. 2. Current Uses of SSRIs",
    "Current Uses of SSRIs to six weeks after initiation, despite signi\ufb01cant immediate alterations in serotonin \ufb02ux. The\naim of this review to educate clinicians on potential adverse effects of SSRIs. 2. Current Uses of SSRIs\nSSRIs are the \ufb01rst-line pharmacotherapy for most patients with depression because\nthey are effective and generally better tolerated when compared to other antidepressants [8]. Though initially approved for the treatment of depression, the US Food and Drug Ad-\nministration (FDA) has approved SSRIs for a variety of other conditions [8]. Clinically,\nprescribing SSRIs outside of their approved indications, or \u201coff-label\u201d, is increasing, as SS-\nRIs demonstrate ef\ufb01cacy in several other therapeutic applications [10\u201312]. Off-label use\nof SSRIs can include for \ufb01bromyalgia, premature ejaculation, and neurocardiogenic syn-\ncope [13]. 2.1. Depression\nDepression is a debilitating illness that often interferes with a patient\u2019s quality of life.",
    "Depression\nDepression is a debilitating illness that often interferes with a patient\u2019s quality of life. cope [13]. 2.1. Depression\nDepression is a debilitating illness that often interferes with a patient\u2019s quality of life. It imposes a signi\ufb01cant \ufb01nancial burden on a patient and the healthcare system, with both\ndirect and indirect costs [14]. In 2018, a study reported increased use of outpatient services\nby patients with hypertension and/or diabetes with untreated depressive symptoms [15]. Along with addressing the patient\u2019s depressive symptoms, treatment with antidepressants\nin these patients may decrease secondary health costs [15]. Additional comorbidities asso-\nciated with depression are alcohol use disorder, anxiety disorders, and even somatoform\ndisorders [16]. Adequate treatment of depression is thought to decrease these associated\ncomorbidities as well. The individual and societal impacts of depression highlight the importance of effective\ntreatments. In patients who have not had a medication trial of an antidepressant, SSRIs are",
    "In patients who have not had a medication trial of an antidepressant, SSRIs are The individual and societal impacts of depression highlight the importance of effective\ntreatments. In patients who have not had a medication trial of an antidepressant, SSRIs are\nusually the \ufb01rst medication used in depression treatment. While SSRIs are the mainstay\nof pharmacological treatment for patients with depression, some patients do not respond\nNeurol. Int. 2021, 13\n389\nto initial monotherapy and require the addition of other treatments [17]. One strategy\ninvolves combining SSRIs with psychotherapy. In one study, 30% of SSRI users utilized\npsychotherapy [18]. A meta-analysis that looked at studies that examined the use of\nantidepressants, psychotherapy, and both used in combination found that the use of the\ncombination of antidepressants and psychotherapy offered better treatment outcomes\nwhich were still sustained two years later [19]. Additionally, SSRIs are often combined with other pharmacological agents to increase",
    "Additionally, SSRIs are often combined with other pharmacological agents to increase which were still sustained two years later [19]. Additionally, SSRIs are often combined with other pharmacological agents to increase\nef\ufb01cacy. In a Spanish survey, combination therapy was frequently prescribed by psychia-\ntrists, with SSRI and mirtazapine being the most preferred combination [20]. Despite this,\nsome research questions the clinical bene\ufb01ts and cost-effectiveness of SSRI combination\ntherapy, and further studies are needed to fully elucidate what combination therapies are\nmost bene\ufb01cial for patients and when to use them [21,22]. 2.2. Anxiety Disorders\nAnxiety disorders, such as generalized anxiety disorder (GAD), social anxiety disorder\n(SAD), and panic disorder are some of the most common psychiatric disorders. SSRIs are\ncurrently the preferred medication for anxiety disorders due to an abundance of literature\nsupporting their safety and effectiveness [23\u201325]. Compared to other anxiolytics, SSRIs",
    "Compared to other anxiolytics, SSRIs currently the preferred medication for anxiety disorders due to an abundance of literature\nsupporting their safety and effectiveness [23\u201325]. Compared to other anxiolytics, SSRIs\nhave fewer side effects and treat depression, which is often comorbid with anxiety [26]. Results from a meta-analysis of 57 trials con\ufb01rm that SSRIs are an effective treatment for\nanxiety disorders and that doses on the higher side of the therapeutic range are associated\nwith greater symptom improvement [25]. 2.3. Autism Spectrum Disorders\nSSRIs are frequently and increasingly prescribed to individuals with autism spec-\ntrum disorders (ASD) [27]. Yet, a meta-analysis involving nine randomized control trials\ndemonstrated insuf\ufb01cient evidence for the ef\ufb01cacy of the SSRIs \ufb02uoxetine, citalopram, and\n\ufb02uvoxamine in children with ASD [28]. In contrast, Reddihough et al. found that treatment\nwith \ufb02uoxetine signi\ufb01cantly decreased obsessive-compulsive behaviors in children and",
    "found that treatment\nwith \ufb02uoxetine signi\ufb01cantly decreased obsessive-compulsive behaviors in children and \ufb02uvoxamine in children with ASD [28]. In contrast, Reddihough et al. found that treatment\nwith \ufb02uoxetine signi\ufb01cantly decreased obsessive-compulsive behaviors in children and\nadolescents with ASD [29]. The uncertainty of SSRI ef\ufb01cacy in core autism behaviors\nhighlights the need for further studies. 2.4. Eating Disorders\nSSRIs have demonstrated to be useful treatment options for bulimia nervosa (BN) and\nbinge eating disorder (BED) [30]. Fluoxetine is the only SSRI with FDA approval for BN,\nthough other SSRIs have shown effectiveness [30\u201332]. In BED, a meta-analysis of 45 studies\nshowed SSRIs provided some improvement in remission and reduction in the frequency of\nbinge eating but no improvement in patient BMI [33]. 2.5. Premenstrual Syndrome/ Premenstrual Dysmorphic Disorder\nSSRIs are an essential pharmacological treatment for patients with unmanageable\npremenstrual syndrome (PMS) and premenstrual dysmorphic disorder (PMDD) [34]. SSRIs",
    "SSRIs SSRIs are an essential pharmacological treatment for patients with unmanageable\npremenstrual syndrome (PMS) and premenstrual dysmorphic disorder (PMDD) [34]. SSRIs\ncan be taken either continuously or in the luteal phase to reduce the symptoms of PMS\nand PMDD [35]. Most SSRIs exhibit equal ef\ufb01cacy for the treatment of PMS and PMDD,\nso a provider\u2019s choice of SSRI should be based on anticipated side effects and the patient\u2019s\nresponse to the drug [34\u201336]. 2.6. Menopausal Vasomotor Symptoms\nTraditionally, hormone replacement therapy has been used for vasomotor symptoms\nassociated with menopause; however, safety concerns and poor compliance have led to the\nuse of alternative medications. SSRIs, especially paroxetine, can be effective for managing\nmenopausal vasomotor symptoms, reducing both the frequency and severity of hot \ufb02ashes\nin menopausal women [37\u201339]. Neurol. Int. 2021, 13\n390\n2.7. Myocardial Infarctions",
    "Myocardial Infarctions menopausal vasomotor symptoms, reducing both the frequency and severity of hot \ufb02ashes\nin menopausal women [37\u201339]. Neurol. Int. 2021, 13\n390\n2.7. Myocardial Infarctions\nSome, but not all, evidence links SSRIs to a reduced risk of myocardial infarctions (MI),\nespecially in patients with depression and a cardiovascular history [40\u201344]. For example,\nin a study of Veteran\u2019s Affairs (VA) patients with depression, 12 weeks of SSRI therapy\nsigni\ufb01cantly decreased the risk of MI and mortality [45]. Although the exact mechanism\nis unknown, some studies hypothesize that SSRIs may reduce the likelihood of MI by\ninhibiting serotonin-mediated platelet activation [46\u201348]. It should also be noted that not\nall SSRIs are safe to use in patients with cardiac disorders and should not be used as a\ntreatment for cardiac concerns alone. 2.8. Nociceptive Pain\nPharmacological relief for nociceptive pain typically involves opioids. However, the",
    "However, the treatment for cardiac concerns alone. 2.8. Nociceptive Pain\nPharmacological relief for nociceptive pain typically involves opioids. However, the\nclinical utility of these drugs can be challenging due to the development of tolerance and\ndependence [49,50]. The use of the SSRI \ufb02uoxetine has been evaluated as an adjunctive\ntherapy option for the management of nociceptive pain. Animal studies indicate that\nco-administration of \ufb02uoxetine with morphine prevents the development of tolerance and\ndependence [51,52]. Alboghobeish et al. found that \ufb02uoxetine increased the antinociceptive\neffect of morphine, in addition to attenuating tolerance and withdrawal [52]. 2.9. Gastrointestinal Disorders\nGastrointestinal (GI) disorders are frequently comorbid in patients with depression\nand anxiety disorders [53\u201355]. Serotonin transporters are located on neurons, glial cells,\nblood platelets, and enterocytes, and altered signaling of serotonin in the gut may con-",
    "Serotonin transporters are located on neurons, glial cells,\nblood platelets, and enterocytes, and altered signaling of serotonin in the gut may con- and anxiety disorders [53\u201355]. Serotonin transporters are located on neurons, glial cells,\nblood platelets, and enterocytes, and altered signaling of serotonin in the gut may con-\ntribute to the symptoms associated with GI disorders [56,57]. Antidepressants have shown\nto have anti-ulcerative effects and have been increasingly prescribed in those with GI\ndisorders [58]. Multiple animal studies have shown that the SSRI \ufb02uvoxamine protects\nagainst the development of peptic ulcers through antioxidant and anti-in\ufb02ammatory mech-\nanisms [59,60]. Certain SSRIs may improve symptoms of irritable bowel syndrome (IBS);\nhowever, their ef\ufb01cacy is controversial, so they should only be prescribed in IBS patients\nwith comorbid depression or anxiety [61,62]. 3. SSRIs: Types and Differences\nThe six major SSRIs that are marketed in the USA today, \ufb02uoxetine, citalopram,\nescitalopram, paroxetine, sertraline, and \ufb02uvoxamine, are a group of structurally unrelated",
    "SSRIs: Types and Differences\nThe six major SSRIs that are marketed in the USA today, \ufb02uoxetine, citalopram,\nescitalopram, paroxetine, sertraline, and \ufb02uvoxamine, are a group of structurally unrelated The six major SSRIs that are marketed in the USA today, \ufb02uoxetine, citalopram,\nescitalopram, paroxetine, sertraline, and \ufb02uvoxamine, are a group of structurally unrelated\nmolecules that share a similar mechanism of action. Even though their primary mechanism\nof action is similar, each SSRI has unique pharmacokinetics, pharmacodynamics, side effect\npro\ufb01le, and ef\ufb01cacy that dispose each to be more or less suited for a particular clinical niche. Selecting the right SSRI depends upon the individual patient and whether or not the side\neffects can be utilized as secondary therapeutic effects. With regards to adverse effects, many are shared among all SSRIs to varying degrees,\nincluding sexual dysfunction, gastrointestinal distress, prolonged QT interval, and xerosto-\nmia [63]. Some of these side effects will be discussed further in later sections, but they are\nalso important delineating factors among the different SSRIs. 3.1. Fluoxetine",
    "Fluoxetine mia [63]. Some of these side effects will be discussed further in later sections, but they are\nalso important delineating factors among the different SSRIs. 3.1. Fluoxetine\nFluoxetine, sold most commonly under the brand names Prozac and Sarafem, is the\noldest and best-studied of the SSRIs. Sarafem is only FDA-approved for use in premenstrual\ndysphoric disorder, but other forms of \ufb02uoxetine are currently approved for use in major\ndepressive disorder, bipolar disorder, BN, obsessive-compulsive disorder (OCD), panic\ndisorder (PD), and treatment-resistant depression. Among the SSRIs, \ufb02uoxetine exhibits the least speci\ufb01c binding to SERT and, at high\ndoses, can increase synaptic norepinephrine and dopamine levels [64]. Fluoxetine tends\nto be associated with higher rates of weight loss, agitation, and anxiety when compared\nto other SSRIs, which may be related to its slightly reduced binding speci\ufb01city [65,66]. Neurol. Int. 2021, 13\n391",
    "2021, 13\n391 to other SSRIs, which may be related to its slightly reduced binding speci\ufb01city [65,66]. Neurol. Int. 2021, 13\n391\nDespite being the least speci\ufb01c SSRI for SERT, \ufb02uoxetine exhibits much higher binding\nspeci\ufb01city than TCAs and MAOIs, resulting in a much more favorable side effect pro\ufb01le. 3.2. Citalopram/Escitalopram\nCitalopram and escitalopram are both FDA-approved in the United States for use in\ntreating major depressive disorder (MDD), while escitalopram is also approved for GAD. The drug citalopram is the racemic mixture of both R and S enantiomers of citalopram,\nwhile escitalopram is only the S enantiomer. The S enantiomer is the compound of interest\nwhen treating depression, while the R enantiomer appears to have no effect and may\neven interfere with the effects of its racemate [67]. Due to its lack of the R enantiomer,\nescitalopram may be more ef\ufb01cacious than citalopram for depression and has the highest\nspeci\ufb01city for SERT of the SSRIs [68,69].",
    "Due to its lack of the R enantiomer,\nescitalopram may be more ef\ufb01cacious than citalopram for depression and has the highest\nspeci\ufb01city for SERT of the SSRIs [68,69]. escitalopram may be more ef\ufb01cacious than citalopram for depression and has the highest\nspeci\ufb01city for SERT of the SSRIs [68,69]. Both drugs, but especially citalopram, are more often associated with QT prolongation\nthan other SSRIs, and this relationship appears to be dose-dependent [70]. As of March\n2021, the FDA issued a safety communication regarding these two medications about the\nQT elongation. It cited a study that found more profound changes in the QTc that started\nat 40 mg of citalopram [71]. At 20 mg, the QTc was changed by 8.5 ms. At 40 mg the QTc\nwas changed by 12.6 ms, and at 60 mg the QTc was changed by 18.5 ms [71]. It is because\nof this study that the FDA recommends to not given doses above 40 mg of citalopram. 3.3. Paroxetine\nParoxetine is currently approved for MDD, GAD, post-traumatic stress disorder, and\nPMDD, among others. Of the SSRIs, it inhibits SERT most potently [72]. One study found",
    "One study found 3.3. Paroxetine\nParoxetine is currently approved for MDD, GAD, post-traumatic stress disorder, and\nPMDD, among others. Of the SSRIs, it inhibits SERT most potently [72]. One study found\nthat paroxetine and \ufb02uoxetine both inhibited the enzyme cytochrome P450 2D6 (CYP2D6),\nrequired for the conversion of tamoxifen to its more active metabolites, resulting in lower\nlevels of these metabolites and, potentially, a reduction in the drug\u2019s anticancer effects [73]. This interaction warrants further investigation. 3.4. Fluvoxamine\nSold most commonly under the brand name Luvox, \ufb02uvoxamine is approved in the\nUnited States for the treatment of obsessive-compulsive disorder and SAD. Like other SSRIs,\n\ufb02uvoxamine demonstrates high speci\ufb01city for SERT; however, unlike other SSRIs, it is also a\npotent agonist at the sigma-1 receptor [74]. The role of the sigma-1 receptor is not completely\nunderstood, but it is thought to be involved in some of the cognitive improvements seen",
    "The role of the sigma-1 receptor is not completely\nunderstood, but it is thought to be involved in some of the cognitive improvements seen potent agonist at the sigma-1 receptor [74]. The role of the sigma-1 receptor is not completely\nunderstood, but it is thought to be involved in some of the cognitive improvements seen\nwith \ufb02uvoxamine therapy [75]. Fluvoxamine is also the only monocyclic SSRI, with the\nothers featuring two to four rings in their chemical structures [76]. 3.5. Sertraline\nSertraline is approved for MDD, OCD, PD, PTSD, SAD, and PMDD. In one review,\nsertraline was found to be more ef\ufb01cacious in the acute phase (between six to twelve weeks)\nof treatment of MDD than other SSRIs [77]. The same review also found sertraline to\nbe associated with a higher rate of diarrhea as a side effect. Sertraline may demonstrate\nantagonist activity at the sigma-1 receptor but with a lesser af\ufb01nity than \ufb02uvoxamine as an\nagonist [74]. 4. Pharmacokinetics/Pharmacodynamics\nAs discussed previously, inhibition of presynaptic SERT causes an increase in sero-",
    "Pharmacokinetics/Pharmacodynamics\nAs discussed previously, inhibition of presynaptic SERT causes an increase in sero- agonist [74]. 4. Pharmacokinetics/Pharmacodynamics\nAs discussed previously, inhibition of presynaptic SERT causes an increase in sero-\ntonin at the synaptic cleft leading, in part, to the therapeutic effects of SSRIs and other\nantidepressants. SSRIs marked a massive improvement in the treatment of depression\nfor many reasons, particularly their binding speci\ufb01city. Compared to MAOIs and TCAs,\nSSRIs have much higher speci\ufb01city for SERT, which allows them to avoid many of the\nantimuscarinic, antihistaminergic, and antiadrenergic side effects of TCAs [78]. Among\nthe SSRIs, escitalopram has the highest speci\ufb01city of all and is almost twice as effective at\ninhibiting SERT as its counterpart citalopram [79]. Neurol. Int. 2021, 13\n392\nHalf-lives of the SSRIs under steady state conditions depends on the individual drug. For example, the half-life of \ufb02uoxetine is between one and four days [80]. Paroxetine\nhas a half-life around 21 h and citalopram has a half-life around 26 h. Sertraline and",
    "Paroxetine\nhas a half-life around 21 h and citalopram has a half-life around 26 h. Sertraline and For example, the half-life of \ufb02uoxetine is between one and four days [80]. Paroxetine\nhas a half-life around 21 h and citalopram has a half-life around 26 h. Sertraline and\ncitalopram show linear pharmacokinetics while \ufb02uoxetine, \ufb02uvoxamine, and paroxetine\nshow nonlinear pharmacokinetics [80]. The SSRIs are metabolized by the cytochrome P450 system in the liver. Fluvoxam-\nine, \ufb02uoxetine, and sertraline inhibit certain cytochrome P450 enzymes to a great degree,\nwhich may cause more drug\u2013drug interactions than found with citalopram and escitalo-\npram [81\u201384]. One study showed that \ufb02uoxetine, paroxetine, and possibly \ufb02uvoxamine\ninhibit their own metabolism, which may result in nonlinear kinetics at higher doses [85]. This does not increase their rate of adverse effects, but care should be taken when prescrib-\ning these drugs to a patient with impaired drug elimination due to liver disease, kidney\ndisease, or advanced age [86]. Fluoxetine has the longest half-life of the SSRIs\u2014between",
    "Fluoxetine has the longest half-life of the SSRIs\u2014between ing these drugs to a patient with impaired drug elimination due to liver disease, kidney\ndisease, or advanced age [86]. Fluoxetine has the longest half-life of the SSRIs\u2014between\nfour and six days for the compound itself, and seven to \ufb01fteen days for its active metabolite\nnor\ufb02uoxetine [65,87]. Sertraline and citalopram exhibit linear kinetics and so may be better\nchoices when initiating therapy for an individual with impaired drug elimination [65]. All of the SSRIs inhibit CYP2D6 with \ufb02uoxetine and paroxetine being the most potent\ninhibitor [88]. Interactions with CYP3A4 appear to not be signi\ufb01cant with SSRIs [88]. 5. SSRIs and Adverse Effects\nSSRIs are generally better tolerated than other antidepressants, but common side\neffects may include nausea, vomiting, insomnia, drowsiness, headache, decreased sex\ndrive, and agitation [8,89]. Here, we will discuss some of the less common adverse effects\nof SSRIs reported in literature, with a focus on extrapyramidal symptoms (EPS), serotonin",
    "Here, we will discuss some of the less common adverse effects\nof SSRIs reported in literature, with a focus on extrapyramidal symptoms (EPS), serotonin drive, and agitation [8,89]. Here, we will discuss some of the less common adverse effects\nof SSRIs reported in literature, with a focus on extrapyramidal symptoms (EPS), serotonin\nsyndrome, QT prolongation, rash, birth defects, hyponatremia, and cataracts. 5.1. Extrapyramidal Symptoms\nAlthough uncommon, EPS in patients treated with SSRIs has been observed in nu-\nmerous studies [90\u201392]. One study identi\ufb01ed 86 case reports connecting the use of SSRIs\nwith the development of dystonia, parkinsonism, dyskinesia, and akathisia. Most of these\ncases occurred within 30 days of treatment initiation or dose increase, with citalopram,\nescitalopram, \ufb02uoxetine, and sertraline most frequently involved [90]. This association\nhighlights the importance of monitoring patients during SSRI therapy for the development\nof EPS [90\u201392]. 5.2. Serotonin Syndrome\nSerotonin syndrome is a potentially fatal consequence of serotonergic overactivity in",
    "Serotonin Syndrome\nSerotonin syndrome is a potentially fatal consequence of serotonergic overactivity in of EPS [90\u201392]. 5.2. Serotonin Syndrome\nSerotonin syndrome is a potentially fatal consequence of serotonergic overactivity in\nthe peripheral and central nervous systems [93]. Though rare, incidence is increasing due\nto widespread SSRI use [93]. The majority of cases involve a combination of serotonergic\ndrugs, though SSRI monotherapy may also lead to serotonin syndrome [94,95]. One\ncase reported moderate serotonin syndrome involving hyperre\ufb02exia and ankle clonus in\nan adult male on sertraline monotherapy [96]. Most other cases of serotonin syndrome\nwith SSRI monotherapy have involved overdose or switching SSRI therapy without cross-\ntitration [97\u201399]. To prevent serotonin syndrome in patients on SSRIs, providers should\nexercise caution when combining, switching, or discontinuing these drugs [100]. 5.3. QT Prolongation\nSSRIs, especially citalopram, can prolong the QT interval by antagonizing myocyte\npotassium channels, which may trigger fatal reentrant tachycardias, such as Torsades de",
    "QT Prolongation\nSSRIs, especially citalopram, can prolong the QT interval by antagonizing myocyte\npotassium channels, which may trigger fatal reentrant tachycardias, such as Torsades de 5.3. QT Prolongation\nSSRIs, especially citalopram, can prolong the QT interval by antagonizing myocyte\npotassium channels, which may trigger fatal reentrant tachycardias, such as Torsades de\nPointes [101,102]. Rochester et al. concluded that citalopram considerably increases the\nrisk of QT prolongation in patients over 60 years old [102]. The risk of QT prolongation\nwith citalopram seems to be dose-dependent, and those with cardiac disease and other\nQT-prolonging risk factors are more vulnerable [103]. Conversely, data from a retrospective\nreview found no association between QT prolongation and citalopram (or escitalopram)\nNeurol. Int. 2021, 13\n393\nin geriatric patients. The authors suggest clinicians compare the risk of QT prolongation\nversus the clinic risk of lowering citalopram/escitalopram dose on a case-by-case basis until\nfurther prospective studies are completed [104]. The FDA recommends a maximum 20 mg",
    "The FDA recommends a maximum 20 mg versus the clinic risk of lowering citalopram/escitalopram dose on a case-by-case basis until\nfurther prospective studies are completed [104]. The FDA recommends a maximum 20 mg\ndaily dose of citalopram and ECG monitoring for at-risk and older individuals [71,102]. 5.4. Rash\nSSRIs have been associated with photosensitivity, spontaneous bruising, pruritus,\nalopecia, and urticaria [105]. In 2019, a female with a history of asthma and an autoimmune\ndisorder developed an itchy pruritic rash four weeks after starting escitalopram [106]. In another case report, \ufb02uoxetine was thought to be the cause of acute urticaria and\nangioedema in a 23-year-old male [107]. Rarely, serious cutaneous reactions such as Stevens\u2013\nJohnson syndrome, toxic epidermal necrosis, erythema multiforme, acute generalized\nexanthematous pustulosis, and drug-induced hypersensitivity reactions have been reported\nin patients taking SSRIs [108\u2013110]. These conditions may be life-threatening, stressing the",
    "These conditions may be life-threatening, stressing the exanthematous pustulosis, and drug-induced hypersensitivity reactions have been reported\nin patients taking SSRIs [108\u2013110]. These conditions may be life-threatening, stressing the\nimportance of patient and provider education in recognizing adverse cutaneous reactions\nearly [108]. 5.5. Congenital Malformations\nGiven the widespread use of SSRIs and their ability to cross the placental barrier,\nnumerous studies have evaluated the association between SSRIs and congenital defects,\nwith inconsistent \ufb01ndings [111]. More recent data report an association between SSRIs\n(mainly paroxetine and \ufb02uoxetine) and a slightly increased risk of congenital defects, par-\nticularly cardiac malformations [111\u2013114]. Literature suggests that SSRIs may potentially\ninterfere with serotonin signaling important for myocardial development in the developing\nfetus [112,113,115]. However, the discontinuation of SSRI treatment may present an even",
    "However, the discontinuation of SSRI treatment may present an even interfere with serotonin signaling important for myocardial development in the developing\nfetus [112,113,115]. However, the discontinuation of SSRI treatment may present an even\ngreater risk for fetal development and the health of the mother, and thus, decisions on\npharmacotherapy in pregnant women should be individualized [116,117]. 5.6. Hyponatremia\nAmong all antidepressants, SSRIs carry the highest risk of hyponatremia, especially in\nthe initial weeks of treatment [118,119]. Although the mechanism is unknown, serotonin\nmay increase antidiuretic hormone, thereby inducing syndrome of inappropriate secretion\nof antidiuretic hormone (SIADH) [119,120]. Most cases of hyponatremia due to SSRIs\ninvolve elderly patients, but other risk factors include concomitant use of hyponatremia-\ninducing drugs, low body weight, female gender, low serum sodium, and severe ill-\nness [120\u2013122]. 5.7. Cataracts\nRecent studies suggest a positive association between long-term use of SSRIs and",
    "Cataracts\nRecent studies suggest a positive association between long-term use of SSRIs and inducing drugs, low body weight, female gender, low serum sodium, and severe ill-\nness [120\u2013122]. 5.7. Cataracts\nRecent studies suggest a positive association between long-term use of SSRIs and\nthe development of cataracts. A nested case-control study and a meta-analysis found\nthat continuous use of \ufb02uoxetine and \ufb02uvoxamine signi\ufb01cantly increased the risk of\ncataracts [123]. In contrast, Becker et al. concluded that SSRI therapy does not alter the risk\nof cataracts [124]. Given these inconsistent \ufb01ndings, providers should recommend regular\neye examinations for patients on SSRIs [125]. 6. Suicidal Ideation\nAccording to the Centers for Disease Control and Prevention, suicide is the tenth\nleading cause of death [126]. Suicidal ideation (SI) is de\ufb01ned as thinking about suicide\nor taking one\u2019s own life, and Table 1 shows the warning signs of SI. Psychiatric illnesses,\nespecially major depressive disorder (MDD), are closely linked to suicide. Beginning in",
    "Beginning in or taking one\u2019s own life, and Table 1 shows the warning signs of SI. Psychiatric illnesses,\nespecially major depressive disorder (MDD), are closely linked to suicide. Beginning in\nthe 1950s, TCAs, including amitriptyline, amoxapine, desipramine (Norpramin), doxepin,\nimipramine (Tofranil), nortriptyline (Pamelor), protriptyline, and trimipramine, were the\n\ufb01rst line of treatment for MDD. TCAs were used widely until SSRIs were introduced on\nthe market in 1982 and became \ufb01rst-line due to their direct action and more favorable side\nNeurol. Int. 2021, 13\n394\neffect pro\ufb01le. One of the most worrisome side effects of treatment with antidepressants,\nespecially SSRIs, is new or worsening SI. Table 1. Symptoms of Suicidal Ideation. Behavioral Symptoms\nPsychosocial Symptoms\nPhysical Symptoms\nCognitive Symptoms\nGiving away possessions\nHelplessness\nScars\nPreoccupation with death\nTalking about death\nPsychosis\nAltered sleeping habits\nBelieving suicide is only way\nto end emotional pain",
    "Behavioral Symptoms\nPsychosocial Symptoms\nPhysical Symptoms\nCognitive Symptoms\nGiving away possessions\nHelplessness\nScars\nPreoccupation with death\nTalking about death\nPsychosis\nAltered sleeping habits\nBelieving suicide is only way\nto end emotional pain Cognitive Symptoms\nGiving away possessions\nHelplessness\nScars\nPreoccupation with death\nTalking about death\nPsychosis\nAltered sleeping habits\nBelieving suicide is only way\nto end emotional pain\nGetting affairs in order\nSelf-loathing\nAltered eating habits\nSaying goodbye to loved ones\nHopelessness\nTerminal illness\nObtaining suicidal items\nParanoia\nDecreasing social contact\nEmotional Pain\nIncreasing drug/alcohol use\nMood swings\nWithdrawing\nPersonality changes\nIncreasing risky behavior\nSevere anxiety\nTreatment Emergent Suicidal Ideation (TESI) is the increased likelihood of developing\nSI after beginning treatment with an SSRI or other antidepressant [127]. Clinicians have\nvariably reported suspicion that antidepressants may increase or decrease suicidal ideation\nand/or behaviors in patients. Clinical studies have a mix of predictive outcomes, includ-\ning direct, indirect, or no effect of SSRIs on SI. Although studies have been conducted",
    "Although studies have been conducted and/or behaviors in patients. Clinical studies have a mix of predictive outcomes, includ-\ning direct, indirect, or no effect of SSRIs on SI. Although studies have been conducted\nworldwide, subjectivity in de\ufb01ning SI has contributed to their inconclusivity in adults. 6.1. Adolescents\nIn 2004, the US Food and Drug Administration (FDA) added a black box warning level\n5 to all antidepressants of suicidality for children and young adults aged 18\u201324 years [128]. Anxiety, agitation, hostility, restlessness, or impulsive behavior in adolescents after starting\nan antidepressant may be the natural course of worsening depression or TESI [129]. Fol-\nlowing this, physicians began to underdiagnose MDD in adolescents and prescribed them\nfewer antidepressants, and patients under age 18 were often not included in studies. In 2014, a retrospective cohort study investigated 36,842 children aged 6 to 18 years\nold, with a mean age of 14 [130]. The children were enrolled in Tennessee Medicaid",
    "The children were enrolled in Tennessee Medicaid In 2014, a retrospective cohort study investigated 36,842 children aged 6 to 18 years\nold, with a mean age of 14 [130]. The children were enrolled in Tennessee Medicaid\nbetween 1995 and 2006 and were all new users of one antidepressant medication, including\n\ufb02uoxetine, sertraline, paroxetine, citalopram, escitalopram, or venlafaxine [130]. Four\nhundred nineteen cohort members who had a medically treated suicide attempt with\nexplicit or inferred attempt to die, con\ufb01rmed through medical record review, including four\nwho completed suicide [130]. Compared to the national suicide average in adolescents,\nthere was no evidence of increased risk for serious suicide attempts on any of the individual\nantidepressants [130]. One limitation of this study was the focus on suicide attempts,\nthereby possibly missing some SI. A European multicenter double-blind study investigated 244 adolescents aged\n13 to 18 years old with MDD who were randomized into a placebo group (n = 124) or",
    "A European multicenter double-blind study investigated 244 adolescents aged\n13 to 18 years old with MDD who were randomized into a placebo group (n = 124) or thereby possibly missing some SI. A European multicenter double-blind study investigated 244 adolescents aged\n13 to 18 years old with MDD who were randomized into a placebo group (n = 124) or\ntreatment with citalopram (n = 120) [131]. More than two-thirds of the adolescents received\npsychotherapy, and one-third of both groups withdrew. The adolescents were measured\nwith the Kiddie Schedule for Affective Disorders and Schizophrenia (K-SADS) Present\nscore, and the Montgomery Asberg Depression Rating Scale (MADRS). For patients not\nreceiving psychotherapy, there was a higher percentage of K-SADS-P responders with\ncitalopram (41%) versus placebo (25%), and a signi\ufb01cantly higher percentage of MADRS\nresponders and remitters with citalopram (52% and 45%, respectively) versus placebo (22%\nand 19%, respectively) [131]. Five patients in the placebo group and fourteen patients\nin the citalopram group experienced suicide attempts, de\ufb01ned to include SI and suicidal",
    "Five patients in the placebo group and fourteen patients\nin the citalopram group experienced suicide attempts, de\ufb01ned to include SI and suicidal and 19%, respectively) [131]. Five patients in the placebo group and fourteen patients\nin the citalopram group experienced suicide attempts, de\ufb01ned to include SI and suicidal\ntendencies, which was not a signi\ufb01cant difference [131]. However, the K-SADS-P SI single\nitem showed a worsening in the placebo (18%) than in the citalopram group (8%) [131]. Neurol. Int. 2021, 13\n395\nThis study highlights the dif\ufb01culty determining a clear correlation between SI and SSRIs,\neven in adolescents, and the need for further studies. 6.2. Adults\nGiven the completed development of the brain, and therefore, the greater social\nacceptability of studies in adults, the relationship between SI and SSRIs in adults is\nbetter characterized. From July 2001 to April 2004, Sequenced Treatment Alternatives to Relieve Depression\n(STAR*D) enrolled 4041 18\u201375-year-old outpatients diagnosed with nonpsychotic MDD. The group was representative of the demographics of the US Census [132]. The patients",
    "The patients (STAR*D) enrolled 4041 18\u201375-year-old outpatients diagnosed with nonpsychotic MDD. The group was representative of the demographics of the US Census [132]. The patients\nwere evaluated using the Quick Inventory of Depressive Symptoms (QIDS-SR) and received\ntreatment with citalopram for 12 weeks. The dosing schedule started at 20 mg/day,\nincreased to 40 mg/day at week four, and increased to 60 mg/day at week six. Of the\n1909 participants with SI at baseline, 1738 returned for treatment visits, and 74% of those\nimproved from baseline, while only 4% had worsened SI [132]. In the small minority\nwho experienced worsening SI during the study, most improved by their last treatment\nvisit [132]. This study demonstrated a clear improvement of SI in depressed adults treated\nwith citalopram, though there was no comparison placebo group. In 2009, there was a government-run study of 1014 adults with MDD in a real-world\ninpatient setting [133]. The Hamilton Depression Rating Score (HAMD) was used to",
    "The Hamilton Depression Rating Score (HAMD) was used to In 2009, there was a government-run study of 1014 adults with MDD in a real-world\ninpatient setting [133]. The Hamilton Depression Rating Score (HAMD) was used to\nevaluate the patients who were treated with an SSRI, a TCA, or placebo. Those treated\nwith \ufb02uoxetine, showed a 72% improvement in SI, those treated with the TCA showed\na 69.8% improvement, and the placebo group showed a 54% improvement [133]. This\nstudy showed a clear improvement in SI with an SSRI or a TCA [133]. One limitation was\na potential selection bias, as the participants were inpatients and not randomly selected. Depressed patients were rarely discharged when suicidal, and the \ufb01nal evaluation was\ncompleted at discharge [133]. In 2018, the Arzneimittelsicherheit in der Psychiatrie (AMSP) program for Drug\nSafety in Psychiatry studied 219,635 patients from 1993 to 2014 to determine the correlation\nbetween SI and antidepressants, including SSRIs, TCAs, serotonin-norepinephrine reuptake",
    "In 2018, the Arzneimittelsicherheit in der Psychiatrie (AMSP) program for Drug\nSafety in Psychiatry studied 219,635 patients from 1993 to 2014 to determine the correlation\nbetween SI and antidepressants, including SSRIs, TCAs, serotonin-norepinephrine reuptake Safety in Psychiatry studied 219,635 patients from 1993 to 2014 to determine the correlation\nbetween SI and antidepressants, including SSRIs, TCAs, serotonin-norepinephrine reuptake\ninhibitors (SNRIs), and noradrenergic and speci\ufb01c serotonergic antidepressants (NaSSAs). There were 83 documented suicidal cases during the study\u201444 cases of SI, 34 attempted\nsuicides, and 5 fatal suicides\u2014with an incidence rate of 0.04% [134]. Increased restlessness,\nego-dystonic thoughts or urges, and impulsivity contributed to suicidality [134]. This\nstudy found a rare and not clinically signi\ufb01cant association between antidepressant use\nand SI [134]. 6.3. Potential Confounders\nIn adults, speci\ufb01c symptoms, such as insomnia, activation, and anxiety during an-\ntidepressant treatment, may increase SI [135]. Being Hispanic or African American, taking\nsedative medications, abusing alcohol or drugs, increased depression severity, melancholic",
    "Being Hispanic or African American, taking\nsedative medications, abusing alcohol or drugs, increased depression severity, melancholic tidepressant treatment, may increase SI [135]. Being Hispanic or African American, taking\nsedative medications, abusing alcohol or drugs, increased depression severity, melancholic\nfeatures, absence of hypersomnia, and comorbidity are associated with increased SI during\ntreatment [128]. Woman are slightly less likely than men to develop SI and tend to develop\nit later in treatment [128]. Being widowed, better work performance, weight loss, and the\npresence of vascular or neurologic comorbidities were associated with worsening SI [128]. Clinical trials that control for these variables, are needed to further determine the direct\neffect of SSRIs on SI. 7. Conclusions\nThis review discussed SSRIs and their clinical indications, adverse effect pro\ufb01les,\nwithin-class differences, and potential association with SI. Despite being initially devel-\noped for the treatment of depressive disorders, SSRIs are now used in anxiety disorders,",
    "Despite being initially devel-\noped for the treatment of depressive disorders, SSRIs are now used in anxiety disorders, within-class differences, and potential association with SI. Despite being initially devel-\noped for the treatment of depressive disorders, SSRIs are now used in anxiety disorders,\nother psychiatric disorders, and certain medical conditions. Each SSRI possesses unique\ncharacteristics that make it a better \ufb01t for certain patients, depending on patient comor-\nNeurol. Int. 2021, 13\n396\nbidities and genetics, and potential adverse effects. For patients who require multiple\npharmacologic interventions for various ailments, an SSRI that does not inhibit cytochrome\nP450 enzymes, such as citalopram or escitalopram, may be considered in order to avoid\ndrug\u2013drug interactions. While SSRIs are much better tolerated than their predecessors, the TCAs and MAOIs,\nthere are potential adverse effects. Some of the more common ones include GI upset,\ninsomnia, agitation, and sexual dysfunction. One of the more controversial adverse effects",
    "One of the more controversial adverse effects there are potential adverse effects. Some of the more common ones include GI upset,\ninsomnia, agitation, and sexual dysfunction. One of the more controversial adverse effects\nof SSRIs is the black box warning for increased risk of suicidality in children and young\nadults aged 18\u201324. There is a lack of understanding of the complexities and interactions\nbetween SSRIs in the developing brain of a young person with depression. Adults, who do\nnot have certain risk factors, as stated previously, do not seem to carry this increased risk\nof suicidality. Ultimately, when prescribing SSRIs to any patient, a risk\u2013bene\ufb01t analysis\nmust factor in the potential treatment effects, adverse effects, and dangers of the illness to\nbe treated. Author Contributions: A.N.E., C.O.O., S.J.P. and Y.A.G. were responsible for the writing. A.N.E.,\nH.A.A., T.A.H., A.D.K., A.M.K., O.V., I.U., A.G.B. and E.M.C. were all editors. All authors have read\nand agreed to the published version of the manuscript.",
    "All authors have read\nand agreed to the published version of the manuscript. H.A.A., T.A.H., A.D.K., A.M.K., O.V., I.U., A.G.B. and E.M.C. were all editors. All authors have read\nand agreed to the published version of the manuscript. Funding: This research received no external funding. Institutional Review Board Statement: Not applicable. Informed Consent Statement: Not applicable. Data Availability Statement: No data were collected in this manuscript but all were cited as appro-\npriate and can be found in the reference section. Con\ufb02icts of Interest: Authors declare no con\ufb02ict of interest. References\n1. World Health Organization. Depression and Other Common Mental Disorders: Global Health Estimates; World Health Organization:\nGeneva, Switzerland, 2017. 2. Greenberg, P.E. ; Fournier, A.A.; Sisitsky, T.; Pike, C.T. ; Kessler, R.C. The economic burden of adults with major depressive disorder\nin the United States (2005 and 2010). J. Clin. Psychiatry 2015, 76, 155\u2013162. [CrossRef] [PubMed]\n3.",
    "[CrossRef] [PubMed]\n3. in the United States (2005 and 2010). J. Clin. Psychiatry 2015, 76, 155\u2013162. [CrossRef] [PubMed]\n3. Depression (Major Depressive Disorder)\u2014Diagnosis and Treatment\u2014Mayo Clinic. Available online: https://www.mayoclinic. org/diseases-conditions/depression/diagnosis-treatment/drc-20356013 (accessed on 21 June 2021). 4. Yang, H.; Chuzi, S.; Sinicropi-Yao, L.; Johnson, D.; Chen, Y.; Clain, A.; Baer, L.; McGrath, P.J. ; Stewart, J.W. ; Fava, M.; et al. Type of\nresidual symptom and risk of relapse during the continuation/maintenance phase treatment of major depressive disorder with\nthe selective serotonin reuptake inhibitor \ufb02uoxetine. Eur. Arch. Psychiatry Clin. Neurosci. 2010, 260, 145\u2013150. [CrossRef]\n5. Clevenger, S.S.; Malhotra, D.; Dang, J.; Vanle, B.; IsHak, W.W. The role of selective serotonin reuptake inhibitors in preventing\nrelapse of major depressive disorder. Ther. Adv. Psychopharmacol. 2018, 8, 49\u201358. [CrossRef] [PubMed]\n6.",
    "[CrossRef] [PubMed]\n6. relapse of major depressive disorder. Ther. Adv. Psychopharmacol. 2018, 8, 49\u201358. [CrossRef] [PubMed]\n6. Stahl, S.M. The 7 habits of highly effective psychopharmacologists, Part 3: Sharpen the saw with selective choices of continuing\nmedical education programs. J. Clin. Psychiatry 2000, 61, 401\u2013402. [CrossRef] [PubMed]\n7. Edwards, J.G. ; Anderson, I. Systematic review and guide to selection of selective serotonin reuptake inhibitors. Drugs 1999, 57,\n507\u2013533. [CrossRef]\n8. Chu, A.; Wadhwa, R. Selective Serotonin Reuptake Inhibitors; StatPearls Publishing: Treasure Island, FL, USA, 2020. 9. Santarsieri, D.; Schwartz, T.L. Antidepressant ef\ufb01cacy and side-effect burden: A quick guide for clinicians. Drugs Context 2015, 4,\n212290. [CrossRef]\n10. Hoffman, R. Off-Label Uses for Selective Serotonin Reuptake Inhibitors. Am. Fam. Physician 2005, 71, 43. [PubMed]\n11. Sk\u00e5nland, S.S.; Cie\u00b4\nslar-Pobuda, A. Off-label uses of drugs for depression. Eur. J. Pharmacol. 2019, 865, 172732. [CrossRef]\n12.",
    "[CrossRef]\n12. 11. Sk\u00e5nland, S.S.; Cie\u00b4\nslar-Pobuda, A. Off-label uses of drugs for depression. Eur. J. Pharmacol. 2019, 865, 172732. [CrossRef]\n12. Boyer, W.F. Potential indications for the selective serotonin reuptake inhibitors. Int. Clin. Psychopharmacol. 1992, 6, 5\u201312. [CrossRef]\n13. Stone, K.J. ; Viera, A.J. ; Parman, C.L. Off-label applications for SSRIs. Am. Fam. Physician 2003, 68, 498\u2013504. [PubMed]\n14. World Health Organization. Investing in Mental Health; World Health Organization: Geneva, Switzerland, 2003; pp. 1\u201352. 15. P\u00e1link\u00e1s, A.; S\u00e1ndor, J.; Papp, M.; K\u02dd\nor\u00f6si, L.; Falusi, Z.; P\u00e1l, L.; B\u00e9lteczki, Z.; Rihmer, Z.; D\u00f6me, P. Associations between untreated\ndepression and secondary health care utilization in patients with hypertension and/or diabetes. Soc. Psychiatry Psychiatr. Epidemiol. 2019, 54, 255\u2013276. [CrossRef] [PubMed]\n16. Steffen, A.; N\u00fcbel, J.; Jacobi, F.; B\u00e4tzing, J.; Holstiege, J. Mental and somatic comorbidity of depression: A comprehensive",
    "Mental and somatic comorbidity of depression: A comprehensive Epidemiol. 2019, 54, 255\u2013276. [CrossRef] [PubMed]\n16. Steffen, A.; N\u00fcbel, J.; Jacobi, F.; B\u00e4tzing, J.; Holstiege, J. Mental and somatic comorbidity of depression: A comprehensive\ncross-sectional analysis of 202 diagnosis groups using German nationwide ambulatory claims data. BMC Psychiatry 2020, 20, 142. [CrossRef]\nNeurol. Int. 2021, 13\n397\n17. Malhi, G.S. ; Mann, J. Depression. Lancet 2018, 392, 2299\u20132312. [CrossRef]\n18. Chung, S. Does the Use of SSRIs Reduce Medical Care Utilization and Expenditures? J. Ment. Health Policy Econ. 2005, 8, 119. 19. Cuijpers, P.; Sijbrandij, M.; Koole, S.L. ; Andersson, G.; Beekman, A.T.; Reynolds, C.F. Adding psychotherapy to antidepressant\nmedication in depression and anxiety disorders: A meta-analysis. World Psychiatry 2014, 13, 56\u201367. [CrossRef]\n20. De La G\u00e1ndara, J.; Ag\u00fcera, L.; Rojo, J.E. ; Ros, S.; De Pedro, J.M. Use of antidepressant combinations: Which, when and why? Results of a Spanish survey. Acta Psychiatr. Scand. 2005, 112, 32\u201335. [CrossRef]",
    "[CrossRef] Results of a Spanish survey. Acta Psychiatr. Scand. 2005, 112, 32\u201335. [CrossRef]\n21. Palaniyappan, L.; Insole, L.; Ferrier, I.N. Combining antidepressants: A review of evidence. Adv. Psychiatr. Treat. 2009, 15, 90\u201399. [CrossRef]\n22. Kessler, D.; Burns, A.; Tallon, D.; Lewis, G.; Macneill, S.; Round, J.; Hollingworth, W.; Chew-Graham, C.; Anderson, I.; Campbell,\nJ.; et al. Combining mirtazapine with ssris or snris for treatment-resistant depression: The MIR RCT. Health Technol. Assess. 2018,\n22, 1\u2013136. [CrossRef] [PubMed]\n23. Keck, P.E. ; McElroy, S.L. New uses for antidepressants: Social phobia. J. Clin. Psychiatry 1997, 58, 32\u201336. 24. Canton, J.; Scott, K.M. ; Glue, P. Optimal treatment of social phobia: Systematic review and meta-analysis. Neuropsychiatr. Dis. Treat. 2012, 8, 203\u2013215. [PubMed]\n25. Jakubovski, E.; Johnson, J.A. ; Nasir, M.; M\u00fcller-Vahl, K.; Bloch, M.H. Systematic review and meta-analysis: Dose-response curve",
    "Systematic review and meta-analysis: Dose-response curve Treat. 2012, 8, 203\u2013215. [PubMed]\n25. Jakubovski, E.; Johnson, J.A. ; Nasir, M.; M\u00fcller-Vahl, K.; Bloch, M.H. Systematic review and meta-analysis: Dose-response curve\nof SSRIs and SNRIs in anxiety disorders. Depress. Anxiety 2019, 36, 198\u2013212. [CrossRef] [PubMed]\n26. Bandelow, B.; Michaelis, S.; Wedekind, D. Treatment of anxiety disorders. Dialogues Clin. Neurosci. 2017, 19, 93\u2013107. 27. Reiersen, A.M.; Handen, B. Commentary on \u2018Selective serotonin reuptake inhibitors (SSRIs) for autism spectrum disorders (ASD)\u2019. Evid. Based Child Health Cochrane Rev. J. 2011, 6, 1082\u20131085. [CrossRef] [PubMed]\n28. Williams, K.; Wheeler, D.M. ; Silove, N.; Hazell, P. Cochrane Review: Selective serotonin reuptake inhibitors (SSRIs) for autism\nspectrum disorders (ASD). Evid. Based Child Health Cochrane Rev. J. 2011, 6, 1044\u20131078. [CrossRef]\n29. Reddihough, D.S. ; Marraffa, C.; Mouti, A.; O\u2019Sullivan, M.; Lee, K.J. ; Orsini, F.; Hazell, P.; Granich, J.; Whitehouse, A.J.O. ; Wray, J.;",
    "; Wray, J.; 29. Reddihough, D.S. ; Marraffa, C.; Mouti, A.; O\u2019Sullivan, M.; Lee, K.J. ; Orsini, F.; Hazell, P.; Granich, J.; Whitehouse, A.J.O. ; Wray, J.;\net al. Effect of Fluoxetine on Obsessive-Compulsive Behaviors in Children and Adolescents with Autism Spectrum Disorders: A\nRandomized Clinical Trial. J. Am. Med. Assoc. 2019, 322, 1561\u20131569. [CrossRef]\n30. Milano, W.; Capasso, A. Psychopharmacological Options in the Multidisciplinary and Multidimensional Treatment of Eating\nDisorders. Open Neurol. J. 2019, 13, 22\u201331. [CrossRef]\n31. Bello, N.T. ; Yeomans, B.L. Safety of pharmacotherapy options for bulimia nervosa and binge eating disorder. Expert Opin. Drug\nSafety 2018, 17, 17\u201323. [CrossRef]\n32. Crow, S.J. Pharmacologic Treatment of Eating Disorders. Psychiatr. Clin. N. Am. 2019, 42, 253\u2013262. [CrossRef]\n33. Ghaderi, A.; Odeberg, J.; Gustafsson, S.; R\u00e5stam, M.; Brolund, A.; Pettersson, A.; Parling, T. Psychological, pharmacological, and",
    "Ghaderi, A.; Odeberg, J.; Gustafsson, S.; R\u00e5stam, M.; Brolund, A.; Pettersson, A.; Parling, T. Psychological, pharmacological, and 33. Ghaderi, A.; Odeberg, J.; Gustafsson, S.; R\u00e5stam, M.; Brolund, A.; Pettersson, A.; Parling, T. Psychological, pharmacological, and\ncombined treatments for binge eating disorder: A systematic review and metaanalysis. PeerJ 2018, 6, e5113. [CrossRef]\n34. Appleton, S.M. Premenstrual Syndrome: Evidence-based Evaluation and Treatment. Clin. Obstet. Gynecol. 2018, 61, 52\u201361. [CrossRef]\n35. Marjoribanks, J.; Brown, J.; O\u2019Brien, P.M.S. ; Wyatt, K. Selective serotonin reuptake inhibitors for premenstrual syndrome. Cochrane\nDatabase Syst. Rev. 2013. [CrossRef]\n36.\ndi Scalea, T.L. ; Pearlstein, T. Premenstrual Dysphoric Disorder. Med. Clin. N. Am. 2019, 103, 613\u2013628. [CrossRef] [PubMed]\n37. Slaton, R.M. ; Champion, M.N. ; Palmore, K.B. A Review of Paroxetine for the Treatment of Vasomotor Symptoms. J. Pharm. Pract. 2014, 28, 266\u2013274. [CrossRef] [PubMed]\n38. Stubbs, C.; Mattingly, L.; Crawford, S.A.; Wickersham, E.A. ; Brockhaus, J.L. ; McCarthy, L.H. Do SSRIs and SNRIs reduce the",
    "Do SSRIs and SNRIs reduce the 2014, 28, 266\u2013274. [CrossRef] [PubMed]\n38. Stubbs, C.; Mattingly, L.; Crawford, S.A.; Wickersham, E.A. ; Brockhaus, J.L. ; McCarthy, L.H. Do SSRIs and SNRIs reduce the\nfrequency and/or severity of hot \ufb02ashes in menopausal women. J. Okla. State Med. Assoc. 2017, 110, 272\u2013274. 39. Riemma, G.; Schiattarella, A.; La Verde, M.; Zarobbi, G.; Garzon, S.; Cucinella, G.; Calagna, G.; Labriola, D.; De Franciscis, P.\nEf\ufb01cacy of low-dose paroxetine for the treatment of hot \ufb02ushes in surgical and physiological postmenopausal women: Systematic\nreview and meta-analysis of randomized trials. Med. Lith. 2019, 55, 554. [CrossRef] [PubMed]\n40. Almuwaqqat, Z.; Jokhadar, M.; Norby, F.; Lutsey, P.L. ; O\u2019Neal, W.T. ; Seyerle, A.; Soliman, E.Z. ; Chen, L.; Bremner, J.D. ; Vaccarino,\nV.; et al. Association of Antidepressant Medication Type With the Incidence of Cardiovascular Disease in the ARIC Study. J. Am. Heart Assoc. 2019, 8, e012503. [CrossRef]\n41.",
    "[CrossRef]\n41. V.; et al. Association of Antidepressant Medication Type With the Incidence of Cardiovascular Disease in the ARIC Study. J. Am. Heart Assoc. 2019, 8, e012503. [CrossRef]\n41. Kim, Y.H. ; Lee, Y.S. ; Kim, M.G. ; Song, Y.K. ; Kim, Y.; Jang, H.; Kim, J.H. ; Han, N.; Ji, E.; Kim, I.-W.; et al. The effect of selective\nserotonin reuptake inhibitors on major adverse cardiovascular events: A meta-analysis of randomized-controlled studies in\ndepression. Int. Clin. Psychopharmacol. 2019, 34, 9\u201317. [CrossRef]\n42. Kim, J.M. ; Stewart, R.; Lee, Y.S. ; Lee, H.J. ; Kim, M.C. ; Kim, J.W. ; Kang, H.J.L. ; Bae, K.Y. ; Kim, S.W. ; Shin, I.S. ; et al. Effect of\nescitalopram vs placebo treatment for depression on long-term cardiac outcomes in patients with acute coronary syndrome: A\nrandomized clinical trial. J. Am. Med. Assoc. 2018, 320, 350\u2013357. [CrossRef]\n43. Coupland, C.; Hill, T.; Morriss, R.; Moore, M.; Arthur, A.; Hippisley-Cox, J. Antidepressant use and risk of cardiovascular",
    "Coupland, C.; Hill, T.; Morriss, R.; Moore, M.; Arthur, A.; Hippisley-Cox, J. Antidepressant use and risk of cardiovascular 43. Coupland, C.; Hill, T.; Morriss, R.; Moore, M.; Arthur, A.; Hippisley-Cox, J. Antidepressant use and risk of cardiovascular\noutcomes in people aged 20 to 64: Cohort study using primary care database. BMJ 2016, 352, i1350. [CrossRef]\n44. Fernandes, N.; Prada, L.; Rosa, M.M. ; Ferreira, J.J.; Costa, J.; Pinto, F.J.; Caldeira, D. The impact of SSRIs on mortality and\ncardiovascular events in patients with coronary artery disease and depression: Systematic review and meta-analysis. Clin. Res. Cardiol. 2020, 110, 183\u2013193. [CrossRef]\nNeurol. Int. 2021, 13\n398\n45. Scherrer, J.F. ; Gar\ufb01eld, L.D. ; Lustman, P.J. ; Hauptman, P.J. ; Chrusciel, T.; Zeringue, A.; Carney, R.M. ; Freedland, K.E. ; Bucholz,\nK.K. ; Owen, R.; et al. Antidepressant drug compliance: Reduced risk of MI and mortality in depressed patients. Am. J. Med. 2011,\n124, 318\u2013324. [CrossRef] [PubMed]\n46. Undela, K.; Parthasarathi, G.; John, S.S. Impact of antidepressants use on risk of myocardial infarction: A systematic review and",
    "Undela, K.; Parthasarathi, G.; John, S.S. Impact of antidepressants use on risk of myocardial infarction: A systematic review and 124, 318\u2013324. [CrossRef] [PubMed]\n46. Undela, K.; Parthasarathi, G.; John, S.S. Impact of antidepressants use on risk of myocardial infarction: A systematic review and\nmeta-analysis. Indian J. Pharmacol. 2015, 47, 256\u2013262. 47. Sauer, W.H. ; Berlin, J.A. ; Kimmel, S.E. Selective serotonin reuptake inhibitors and myocardial infarction. Circulation 2001, 104,\n1894\u20131898. [CrossRef]\n48. Helmeste, D.M. ; Tang, S.W. ; Reist, C.; Vu, R. Serotonin uptake inhibitors modulate intracellular Ca2+ mobilization in platelets. Eur. J. Pharmacol. Mol. Pharmacol. 1995, 288, 373\u2013377. [CrossRef]\n49. Kim, K.H. ; Seo, H.J. ; Abdi, S.; Huh, B. All about pain pharmacology: What pain physicians should know. Korean J. Pain. Korean\nPain Soc. 2020, 33, 108\u2013120. [CrossRef] [PubMed]\n50. Morgan, M.M. ; Christie, M.J. Analysis of opioid ef\ufb01cacy, tolerance, addiction and dependence from cell culture to human. Br. J.\nPharmacol. 2011, 164, 1322\u20131334. [CrossRef]\n51.",
    "[CrossRef]\n51. 50. Morgan, M.M. ; Christie, M.J. Analysis of opioid ef\ufb01cacy, tolerance, addiction and dependence from cell culture to human. Br. J.\nPharmacol. 2011, 164, 1322\u20131334. [CrossRef]\n51. Hamdy, M.M. ; Elbadr, M.M. ; Barakat, A. Fluoxetine uses in nociceptive pain management: A promising adjuvant to opioid\nanalgesics. Fundam. Clin. Pharmacol. 2018, 32, 532\u2013546. [CrossRef] [PubMed]\n52. Alboghobeish, S.; Naghizadeh, B.; Kheirollah, A.; Ghorbanzadeh, B.; Mansouri, M.T. Fluoxetine increases analgesic effects of\nmorphine, prevents development of morphine tolerance and dependence through the modulation of L-type calcium channels\nexpression in mice. Behav. Brain Res. 2019, 361, 86\u201394. [CrossRef]\n53. Lee, Y.B. ; Yu, J.; Choi, H.H. ; Jeon, B.S. ; Kim, H.-K.; Kim, S.-W.; Kim, S.S.; Park, Y.G. ; Chae, H.S. The association between peptic\nulcer diseases and mental health problems. Medicine 2017, 96, e7828. [CrossRef]\n54.",
    "[CrossRef]\n54. ulcer diseases and mental health problems. Medicine 2017, 96, e7828. [CrossRef]\n54. Byrne, G.; Rosenfeld, G.; Leung, Y.; Qian, H.; Raudzus, J.; Nunez, C.; Bressler, B. Prevalence of anxiety and depression in patients\nwith in\ufb02ammatory bowel disease. Can. J. Gastroenterol. Hepatol. 2017, 2017, 1\u20136. [CrossRef]\n55. Graff, L.A.; Walker, J.R.; Bernstein, C.N. Depression and anxiety in i\ufb02ammatory bowel disease: A review of comorbidity and\nmanagement. In\ufb02amm. Bowel Dis. 2009, 15, 1105\u20131118. [CrossRef] [PubMed]\n56. Fuller, R.W. ; Wong, D.T. Serotonin Uptake and Serotonin Uptake Inhibition. Ann. N. Y. Acad. Sci. 1990, 600, 68\u201380. [CrossRef]\n57. Sikander, A.; Rana, S.V. ; Prasad, K.K. Role of serotonin in gastrointestinal motility and irritable bowel syndrome. Clin. Chim. Acta\n2009, 403, 47\u201355. [CrossRef] [PubMed]\n58. Olden, K.W. The use of antidepressants in functional gastrointestinal disorders: New uses for old drugs. CNS Spectr. 2005, 10,\n891\u2013896. [CrossRef] [PubMed]\n59.",
    "[CrossRef] [PubMed]\n59. 58. Olden, K.W. The use of antidepressants in functional gastrointestinal disorders: New uses for old drugs. CNS Spectr. 2005, 10,\n891\u2013896. [CrossRef] [PubMed]\n59. Elsaed, W.M. ; Alahmadi, A.M.; Al-Ahmadi, B.T. ; Taha, J.A. ; Tarabishi, R.M. Gastroprotective and antioxidant effects of \ufb02uvoxam-\nine on stress-induced peptic ulcer in rats. J. Taibah Univ. Med. Sci. 2018, 13, 422\u2013431. [CrossRef]\n60. Dursun, H.; Bilici, M.; Albayrak, F.; Ozturk, C.; Saglam, M.B. ; Alp, H.H. ; Suleyman, H. Antiulcer activity of \ufb02uvoxamine in rats\nand its effect on oxidant and antioxidant parameters in stomach tissue. BMC Gastroenterol. 2009, 9, 36. [CrossRef]\n61. Chen, L.; Ilham, S.J. ; Feng, B. Pharmacological approach for managing pain in irritable bowel syndrome: A review article. Anesthesiol. Pain Med. 2017, 7, e42747. [CrossRef]\n62. Seddighnia, A.; Najafabadi, B.T. ; Ghamari, K.; Noorbala, A.A.; Daryani, N.E. ; Kashani, L.; Akhondzadeh, S. Vortioxetine effects",
    "; Kashani, L.; Akhondzadeh, S. Vortioxetine effects Anesthesiol. Pain Med. 2017, 7, e42747. [CrossRef]\n62. Seddighnia, A.; Najafabadi, B.T. ; Ghamari, K.; Noorbala, A.A.; Daryani, N.E. ; Kashani, L.; Akhondzadeh, S. Vortioxetine effects\non quality of life of irritable bowel syndrome patients: A randomized, double-blind, placebo-controlled trial. J. Clin. Pharm. Ther. 2020, 45, 97\u2013104. [CrossRef]\n63. David, D.J. ; Gourion, D. Antid\u00e9presseurs et tol\u00e9rance: D\u00e9terminants et prise en charge des principaux effets ind\u00e9sirables. Encephale 2016, 42, 553\u2013561. [CrossRef]\n64. Bymaster, F.P. ; Zhang, W.; Carter, P.A. ; Shaw, J.; Chernet, E.; Phebus, L.; Wong, D.T. ; Perry, K.W. Fluoxetine, but not other selective\nserotonin uptake inhibitors, increases norepinephrine and dopamine extracellular levels in prefrontal cortex. Psychopharmacology\n2002, 160, 353\u2013361. [CrossRef]\n65. Marken, P.A. ; Stuart Munro, J. Selecting a selective serotonin reuptake inhibitor: Clinically important distinguishing features.",
    "Selecting a selective serotonin reuptake inhibitor: Clinically important distinguishing features. 2002, 160, 353\u2013361. [CrossRef]\n65. Marken, P.A. ; Stuart Munro, J. Selecting a selective serotonin reuptake inhibitor: Clinically important distinguishing features. Prim. Care Companion J. Clin. Psychiatry 2000, 2, 205\u2013210. [CrossRef]\n66. Stahl, S.M. Essential Psychopharmacology, 2nd ed. ; Cambridge University Press: New York, NY, USA, 1999. 67. S\u00e1nchez, C.; B\u00f8ges\u00f3, K.P. ; Ebert, B.; Reines, E.H.; Braestrup, C. Escitalopram versus citalopram: The surprising role of the\nR-enantiomer. Psychopharmacology 2004, 174, 163\u2013176. [CrossRef] [PubMed]\n68. Owens, M.J.; Knight, D.L. ; Nemeroff, C.B. Second-generation SSRIs: Human monoamine transporter binding pro\ufb01le of escitalo-\npram and R-\ufb02uoxetine. Biol. Psychiatry 2001, 50, 345\u2013350. [CrossRef]\n69. Raffaele, R.; Vecchio, I.; Giammona, G.; Polizzi, A.; Ruggieri, M.; Malaguarnera, M.; Rampello, L.; Nicoletti, F. Citalopram in the\ntreatment of depression in the elderly. Arch. Gerontol. Geriatr. 2002, 35, 303\u2013308. [CrossRef]\n70.",
    "[CrossRef]\n70. treatment of depression in the elderly. Arch. Gerontol. Geriatr. 2002, 35, 303\u2013308. [CrossRef]\n70. Lam, R.W. Antidepressants and QTc prolongation. J. Psychiatry Neurosci. 2013, 38, E5. [CrossRef] [PubMed]\n71. U.S. Food & Drug Administration. FDA Drug Safety Communication: Revised Recommendations for Celexa (Citalo-\npram Hydrobromide) Related to a Potential Risk of Abnormal Heart Rhythms with High Doses. Available online:\nhttps://www.fda.gov/drugs/drug-safety-and-availability/fda-drug-safety-communication-revised-recommendations-\ncelexa-citalopram-hydrobromide-related (accessed on 20 May 2021). 72. Bourin, M.; Chue, P.; Guillon, Y. Paroxetine: A review. CNS Drug Rev. 2001, 7, 25\u201347. [CrossRef]\nNeurol. Int. 2021, 13\n399\n73. Desmarais, J.E. ; Looper, K.J. Interactions between tamoxifen and antidepressants via cytochrome P450 2D6. J. Clin. Psychiatry\n2009, 70, 1688\u20131697. [CrossRef]\n74.",
    "[CrossRef]\n74. Neurol. Int. 2021, 13\n399\n73. Desmarais, J.E. ; Looper, K.J. Interactions between tamoxifen and antidepressants via cytochrome P450 2D6. J. Clin. Psychiatry\n2009, 70, 1688\u20131697. [CrossRef]\n74. Hashimoto, K. Sigma-1 Receptors and Selective Serotonin Reuptake Inhibitors: Clinical Implications of their Relationship. Cent. Nerv. Syst. Agents Med. Chem. 2009, 9, 197\u2013204. [CrossRef] [PubMed]\n75. Hindmarch, I.; Hashimoto, K. Cognition and depression: The effects of \ufb02uvoxamine, a sigma-1 receptor agonist, reconsidered. Hum. Psychopharmacol. Clin. Ex. 2010, 25, 193\u2013200. [CrossRef]\n76. Claassen, V.; Davies, J.E. ; Hertting, G.; Placheta, P. Fluvoxamine, a speci\ufb01c 5-hydroxytryptamine uptake inhibitor. Br. J. Pharmacol. 1977, 60, 505\u2013516. [CrossRef]\n77. Cipriani, A.; La Ferla, T.; Furukawa, T.A. ; Signoretti, A.; Nakagawa, A.; Churchill, R.; McGuire, H.; Barbui, C. Sertraline versus\nother antidepressive agents for depression. Cochrane Database Syst. Rev. 2010, 4, CD006117. [CrossRef]\n78.",
    "[CrossRef]\n78. other antidepressive agents for depression. Cochrane Database Syst. Rev. 2010, 4, CD006117. [CrossRef]\n78. Xue, W.; Wang, P.; Li, B.; Li, Y.; Xu, X.; Yang, F.; Yao, X.; Chen, Y.Z. ; Xu, F.; Zhu, F. Identi\ufb01cation of the inhibitory mechanism of\nFDA approved selective serotonin reuptake inhibitors: An insight from molecular dynamics simulation study. Phys. Chem. Chem. Phys. 2015, 18, 3260\u20133271. [CrossRef] [PubMed]\n79. Rao, N. The clinical pharmacokinetics of escitalopram. Clin. Pharmacokinet. 2007, 46, 281\u2013290. [CrossRef]\n80. DeVane, C.L. Pharmacokinetics of the selective serotonin reuptake inhibitors. J. Clin. Psychiatry 1992, 53, 13\u201320. [PubMed]\n81. Iribarne, C.; Picart, D.; Dr\u00e9ano, Y.; Berthou, F. In vitro interactions between \ufb02uoxetine or \ufb02uvoxamine and methadone or\nbuprenorphine. Fundam. Clin. Pharmacol. 1998, 12, 194\u2013199. [CrossRef] [PubMed]\n82. Belpaire, F.M. ; Wijnant, P.; Temmerman, A.; Rasmussen, B.B. ; Br\u00f8sen, K. The oxidative metabolism of metoprolol in human liver",
    "; Br\u00f8sen, K. The oxidative metabolism of metoprolol in human liver 82. Belpaire, F.M. ; Wijnant, P.; Temmerman, A.; Rasmussen, B.B. ; Br\u00f8sen, K. The oxidative metabolism of metoprolol in human liver\nmicrosomes: Inhibition by the selective serotonin reuptake inhibitors. Eur. J. Clin. Pharmacol. 1998, 54, 261\u2013264. [CrossRef]\n83. Schmider, J.; Greenblatt, D.J. ; Von Moltke, L.L. ; Karsov, D.; Shader, R.I. Inhibition of CYP2C9 by selective serotonin reuptake\ninhibitors in vitro: Studies of phenytoin p-hydroxylation. Br. J. Clin. Pharmacol. 1997, 44, 495\u2013498. [CrossRef]\n84. Br\u00f8sen, K.; Skjelbo, E.; Rasmussen, B.B. ; Poulsen, H.E. ; Loft, S. Fluvoxamine is a potent inhibitor of cytochrome P4501A2. Biochem. Pharmacol. 1993, 45, 1211\u20131214. [CrossRef]\n85. Catterson, M.L. ; Preskorn, S.H. Pharmacokinetics of selective serotonin reuptake inhibitors: Clinical relevance. Pharmacol. Toxicol. 1996, 78, 203\u2013208. [CrossRef]\n86. Dalhoff, K.; Almdal, T.P. ; Bjerrum, K.; Keiding, S.; Mengel, H.; Lund, J. Pharmacokinetics of paroxetine in patients with cirrhosis.",
    "; Bjerrum, K.; Keiding, S.; Mengel, H.; Lund, J. Pharmacokinetics of paroxetine in patients with cirrhosis. 1996, 78, 203\u2013208. [CrossRef]\n86. Dalhoff, K.; Almdal, T.P. ; Bjerrum, K.; Keiding, S.; Mengel, H.; Lund, J. Pharmacokinetics of paroxetine in patients with cirrhosis. Eur. J. Clin. Pharmacol. 1991, 41, 351\u2013354. [CrossRef]\n87. Rossi, A.; Barraco, A.; Donda, P. Fluoxetine: A review on evidence based medicine. Ann. Gen. Hosp. Psychiatry 2004, 3, 2. [CrossRef]\n88. Br\u00f8sen, K. Differences in interactions of SSRIs. Int. Clin. Psychopharmacol. 1998, 13, S45\u2013S47. [CrossRef] [PubMed]\n89. National Health Services. Selective Serotonin Reuptake Inhibitors (SSRIs)\u2014Side Effects. Available online: https://www.nhs.uk/\nmental-health/talking-therapies-medicine-treatments/medicines-and-psychiatry/ssri-antidepressants/side-effects (accessed on\n21 November 2020). 90. Hawthorne, J.M. ; Caley, C.F. Extrapyramidal reactions associated with serotonergic antidepressants. Ann. Pharmacother. 2015, 49,\n1136\u20131152. [CrossRef] [PubMed]\n91.",
    "[CrossRef] [PubMed]\n91. 21 November 2020). 90. Hawthorne, J.M. ; Caley, C.F. Extrapyramidal reactions associated with serotonergic antidepressants. Ann. Pharmacother. 2015, 49,\n1136\u20131152. [CrossRef] [PubMed]\n91. M\u00f6rkl, S.; Seltenreich, D.; Letmaier, M.; Bengesser, S.; Wurm, W.; Grohmann, R.; Bleich, S.; Toto, S.; St\u00fcbner, S.; Butler, M.I. ;\net al. Extrapyramidal reactions following treatment with antidepressants: Results of the AMSP multinational drug surveillance\nprogramme. World J. Biol. Psychiatry 2020, 21, 308\u2013316. [CrossRef]\n92. Guo, M.Y. ; Etminan, M.; Procyshyn, R.M. ; Kim, D.D. ; Samii, A.; Kezouh, A.; Carleton, B.C. Association of Antidepressant Use\nwith Drug-Related Extrapyramidal Symptoms: A Pharmacoepidemiological Study. J. Clin. Psychopharmacol. 2018, 38, 349\u2013356. [CrossRef]\n93. Scotton, W.J. ; Hill, L.J. ; Williams, A.C.; Barnes, N.M. Serotonin Syndrome: Pathophysiology, Clinical Features, Management, and",
    "; Williams, A.C.; Barnes, N.M. Serotonin Syndrome: Pathophysiology, Clinical Features, Management, and [CrossRef]\n93. Scotton, W.J. ; Hill, L.J. ; Williams, A.C.; Barnes, N.M. Serotonin Syndrome: Pathophysiology, Clinical Features, Management, and\nPotential Future Directions. Int. J. Tryptophan Res. 2019, 12, 1178646919873925. [CrossRef] [PubMed]\n94. Francescangeli, J.; Karamchandani, K.; Powell, M.; Bonavia, A. The serotonin syndrome: From molecular mechanisms to clinical\npractice. Int. J. Mol. Sci. 2019, 20, 2288. [CrossRef] [PubMed]\n95. Dunkley, E.J.C. ; Isbister, G.K.; Sibbritt, D.; Dawson, A.H.; Whyte, I.M. The hunter serotonin toxicity criteria: Simple and accurate\ndiagnostic decision rules for serotonin toxicity. QJM Mon. J. Assoc. Physicians 2003, 96, 635\u2013642. [CrossRef]\n96. Duignan, K.M. ; Quinn, A.M.; Matson, A.M. Serotonin syndrome from sertraline monotherapy. Am. J. Emerg. Med. 2020, 38,\ne5\u2013e1695. [CrossRef] [PubMed]\n97. Mendelsohn, J.; Coffey, B.J. Serotonin Syndrome in an Adolescent Girl. J. Child Adolesc. Psychopharmacol. 2019, 29, 783\u2013786. [CrossRef]\n98.",
    "[CrossRef]\n98. e5\u2013e1695. [CrossRef] [PubMed]\n97. Mendelsohn, J.; Coffey, B.J. Serotonin Syndrome in an Adolescent Girl. J. Child Adolesc. Psychopharmacol. 2019, 29, 783\u2013786. [CrossRef]\n98. Hudd, T.R. ; Blake, C.S. ; Rimola-Dejesus, Y.; Nguyen, T.T. ; Zaiken, K. A Case Report of Serotonin Syndrome in a Patient on\nSelective Serotonin Reuptake Inhibitor (SSRI) Monotherapy. J. Pharm. Pract. 2020, 33, 206\u2013212. [CrossRef]\n99. Schult, R.F. ; Morris, A.J. ; Picard, L.; Wiegand, T.J. Citalopram overdose and severe serotonin syndrome in an intermediate\nmetabolizing patient. Am. J. Emerg. Med. 2019, 37, e5\u2013e1993. [CrossRef] [PubMed]\n100. Keks, N.; Hope, J.; Keogh, S. Switching and stopping antidepressants. Aust. Prescr. 2016, 39, 76\u201383. 101. Nachimuthu, S.; Assar, M.D. ; Schussler, J.M. Drug-induced QT interval prolongation: Mechanisms and clinical management. Ther. Adv. Drug Safety 2012, 3, 241\u2013253. [CrossRef] [PubMed]\nNeurol. Int. 2021, 13\n400",
    "2021, 13\n400 Ther. Adv. Drug Safety 2012, 3, 241\u2013253. [CrossRef] [PubMed]\nNeurol. Int. 2021, 13\n400\n102. Rochester, M.P. ; Kane, A.M.; Linnebur, S.A.; Fixen, D.R. Evaluating the risk of QTc prolongation associated with antidepressant\nuse in older adults: A review of the evidence. Ther. Adv. Drug Safety 2018, 9, 297\u2013308. [CrossRef]\n103. Cooke, M.J.; Waring, W.S. Citalopram and cardiac toxicity. Eur. J. Clin. Pharmacol. 2013, 69, 755\u2013760. [CrossRef] [PubMed]\n104. Cr\u00e9peau-Gendron, G.; Brown, H.K. ; Shorey, C.; Madan, R.; Szabuniewicz, C.; Koh, S.; Veinish, S.; Mah, L. Association between\ncitalopram, escitalopram and QTc prolongation in a real-world geriatric setting. J. Affect. Disord. 2019, 250, 341\u2013345. [CrossRef]\n105. Krasowska, D.; Szymanek, M.; Schwartz, R.A.; My\u00b4\nsli\u00b4\nnski, W. Cutaneous effects of the most commonly used antidepressant\nmedication, the selective serotonin reuptake inhibitors. J. Am. Acad. Dermatol. 2007, 56, 848\u2013853. [CrossRef]",
    "[CrossRef] sli\u00b4\nnski, W. Cutaneous effects of the most commonly used antidepressant\nmedication, the selective serotonin reuptake inhibitors. J. Am. Acad. Dermatol. 2007, 56, 848\u2013853. [CrossRef]\n106. Prabhakar, D.; Sablaban, I. Escitalopram-Induced Rash. Prim. Care Companion CNS Disord. 2019, 21. [CrossRef]\n107. Tuman, T.C. ; Tuman, B.; Polat, M.; \u00c7akir, U. Urticaria and angioedema associated with \ufb02uoxetine. Clin. Psychopharmacol. Neurosci. 2017, 15, 418\u2013419. [CrossRef]\n108. Herstowska, M.; Komorowska, O.; Cuba\u0142a, W.J. ; Jakuszkowiak-Wojten, K.; Ga\u0142uszko-We\n\u00b8gielnik, M.; Landowski, J. Severe skin\ncomplications in patients treated with antidepressants: A literature review. Postepy Dermatol. Alergol. 2014, 31, 92\u201397. [CrossRef]\n109. Mameli, C.; Tadini, G.; Cattaneo, D.; Cerini, C.; Zuccotti, G.V. Acute generalized exanthematous pustulosis induced by paroxetine\nin an adolescent girl. Acta Derm. Venereol. 2013, 93, 733\u2013734. [CrossRef] [PubMed]",
    "[CrossRef] [PubMed] in an adolescent girl. Acta Derm. Venereol. 2013, 93, 733\u2013734. [CrossRef] [PubMed]\n110. Byrne, A.; Arkell, S.; Bandi, P. SSRI-induced severe adverse cutaneous reaction\u2014A case report. Prog. Neurol. Psychiatry 2017, 21,\n9\u201312. [CrossRef]\n111. Reefhuis, J.; Devine, O.; Friedman, J.M. ; Louik, C.; Honein, M.A. Speci\ufb01c SSRIs and birth defects: Bayesian analysis to interpret\nnew data in the context of previous reports. BMJ 2015, 351. [CrossRef]\n112. B\u00e9rard, A.; Iessa, N.; Chaabane, S.; Muanda, F.T. ; Boukhris, T.; Zhao, J.P. The risk of major cardiac malformations associated with\nparoxetine use during the \ufb01rst trimester of pregnancy: A systematic review and meta-analysis. Br. J. Clin. Pharmacol. 2016, 81,\n589\u2013604. [CrossRef]\n113. Gao, S.-Y. ; Wu, Q.-J. ; Zhang, T.-N.; Shen, Z.-Q. ; Liu, C.-X. ; Xu, X.; Ji, C.; Zhao, Y.-H. Fluoxetine and congenital malformations: A\nsystematic review and meta-analysis of cohort studies. Br. J. Clin. Pharmacol. 2017, 83, 2134\u20132147. [CrossRef]",
    "[CrossRef] systematic review and meta-analysis of cohort studies. Br. J. Clin. Pharmacol. 2017, 83, 2134\u20132147. [CrossRef]\n114. Gao, S.-Y. ; Wu, Q.-J. ; Sun, C.; Zhang, T.-N.; Shen, Z.-Q. ; Liu, C.-X. ; Gong, T.-T.; Xu, X.; Ji, C.; Huang, D.-H.; et al. Selective\nserotonin reuptake inhibitor use during early pregnancy and congenital malformations: A systematic review and meta-analysis\nof cohort studies of more than 9 million births. BMC Med. 2018, 16, 1\u201314. [CrossRef]\n115. Sari, Y.; Zhou, F.C. Serotonin and its transporter on proliferation of fetal heart cells. Int. J. Dev. Neurosci. 2003, 21, 417\u2013424. [CrossRef] [PubMed]\n116. Dubovicky, M.; Belovicova, K.; Csatlosova, K.; Bogi, E. Risks of using SSRI / SNRI antidepressants during pregnancy and\nlactation. Interdiscip. Toxicol. 2017, 10, 30\u201334. [CrossRef]\n117. Armstrong, C. ACOG Guidelines on Psychiatric Medication Use During Pregnancy and Lactation. Am. Fam. Physician 2008,\n78, 772.",
    "Physician 2008,\n78, 772. lactation. Interdiscip. Toxicol. 2017, 10, 30\u201334. [CrossRef]\n117. Armstrong, C. ACOG Guidelines on Psychiatric Medication Use During Pregnancy and Lactation. Am. Fam. Physician 2008,\n78, 772. 118. Leth-M\u00f8ller, K.B. ; Hansen, A.H.; Torstensson, M.; Andersen, S.E. ; \u00d8dum, L.; Gislasson, G.; Torp-Pedersen, C.; Holm, E.A. Antidepressants and the risk of hyponatremia: A Danish register-based population study. BMJ Open 2016, 6, e011200. [CrossRef]\n[PubMed]\n119. Farmand, S.; Lindh, J.D. ; Calissendorff, J.; Skov, J.; Falhammar, H.; Nathanson, D.; Mannheimer, B. Differences in Associations of\nAntidepressants and Hospitalization Due to Hyponatremia. Am. J. Med. 2018, 131, 56\u201363. [CrossRef] [PubMed]\n120. Jacob, S.; Spinler, S.A. Hyponatremia associated with selective serotonin-reuptake inhibitors in older adults. Ann. Pharmacother. 2006, 40, 1618\u20131622. [CrossRef] [PubMed]",
    "[CrossRef] [PubMed] 120. Jacob, S.; Spinler, S.A. Hyponatremia associated with selective serotonin-reuptake inhibitors in older adults. Ann. Pharmacother. 2006, 40, 1618\u20131622. [CrossRef] [PubMed]\n121. Leung, V.P.Y. ; Chiu, H.F.K. ; Lam, L.C.W. Hyponatremia associated with paroxetine. Pharmacopsychiatry 1998, 31, 32\u201334. [CrossRef]\n122. de Picker, L.; van Den Eede, F.; Dumont, G.; Moorkens, G.; Sabbe, B.G.C. Antidepressants and the Risk of Hyponatremia: A\nClass-by-Class Review of Literature. Psychosomatics 2014, 55, 536\u2013547. [CrossRef]\n123. Chou, P.-H.; Chu, C.-S.; Chen, Y.-H.; Hsu, M.-Y. ; Huang, M.-W.; Lan, T.-H.; Lin, C.-H. Antidepressants and risk of cataract\ndevelopment: A population-based, nested case-control study. J. Affect. Disord. 2017, 215, 237\u2013244. [CrossRef] [PubMed]\n124. Becker, C.; Schwenkglenks, M.; Frueh, M.; Reich, O.; Meier, C.R. Use of selective serotonin reuptake inhibitors, other antidepres-",
    "Use of selective serotonin reuptake inhibitors, other antidepres- 124. Becker, C.; Schwenkglenks, M.; Frueh, M.; Reich, O.; Meier, C.R. Use of selective serotonin reuptake inhibitors, other antidepres-\nsant medication, and risk of cataract: A case-control study based on Swiss claims data. Eur. J. Clin. Pharmacol. 2020, 76, 1329\u20131335. [CrossRef]\n125. Karak\u00fc\u00e7\u00fck, Y.; Beyoglu, A.; \u00c7\u00f6mez, A.; Orhan, F.\u00d6. ; Demir, M. Early effects of selective serotonin reuptake inhibitors (SSRIs) on\ncornea and lens density in patients with depression. Psychiatry Clin. Psychopharmacol. 2019, 29, 387\u2013393. [CrossRef]\n126. V\u00e4rnik, P. Suicide in the world. Int. J. Environ. Res. Public Health 2012, 9, 760\u2013771. [CrossRef]\n127. Nobile, B.; Ramoz, N.; Jaussent, I.; Gorwood, P.; Oli\u00e9, E.; Castroman, J.L. ; Guillaume, S.; Courtet, P. Polymorphism A118G of\nopioid receptor mu 1 (OPRM1) is associated with emergence of suicidal ideation at antidepressant onset in a large naturalistic\ncohort of depressed outpatients. Sci. Rep. 2019, 9, 1\u20138. [CrossRef]",
    "[CrossRef] opioid receptor mu 1 (OPRM1) is associated with emergence of suicidal ideation at antidepressant onset in a large naturalistic\ncohort of depressed outpatients. Sci. Rep. 2019, 9, 1\u20138. [CrossRef]\n128. Ho, D. Antidepressants and the FDA\u2019s Black-Box Warning: Determining a Rational Public Policy in the Absence of Suf\ufb01cient\nEvidence. AMA J. Ethics 2012, 14, 484\u2013488. 129. Sato, Y.; Takatsu, Y.; Ito, H.; Kataoka, K.; Takeuchi, Y.; Matsumori, A. SSRI Antidepressant Medications: Adverse; Effects and\nTolerability. Heart Vessel. 1996, 11, 218\u2013220. [CrossRef] [PubMed]\n130. Cooper, W.O. ; Callahan, S.T. ; Shintani, A.; Fuchs, D.C.; Shelton, R.C. ; Dudley, J.A. ; Graves, A.J. ; Ray, W.A. Antidepressants and\nsuicide attempts in children. Pediatrics 2014, 133, 204\u2013210. [CrossRef]\nNeurol. Int. 2021, 13\n401\n131. Von Knorring, A.L. ; Olsson, G.I. ; Thomsen, P.H. ; Lemming, O.M. ; Hult\u00e9n, A. A randomized, double-blind, placebo-controlled",
    "A randomized, double-blind, placebo-controlled Neurol. Int. 2021, 13\n401\n131. Von Knorring, A.L. ; Olsson, G.I. ; Thomsen, P.H. ; Lemming, O.M. ; Hult\u00e9n, A. A randomized, double-blind, placebo-controlled\nstudy of citalopram in adolescents with major depressive disorder. J. Clin. Psychopharmacol. 2006, 26, 311\u2013315. [CrossRef]\n[PubMed]\n132. Zisook, S.; Trivedi, M.H. ; Warden, D.; Lebowitz, B.; Thase, M.E. ; Stewart, J.W. ; Moutier, C.; Fava, M.; Wisniewski, S.; Luther, J.;\net al. Clinical correlates of the worsening or emergence of suicidal ideation during SSRI treatment of depression: An examination\nof citalopram in the STAR*D study. J. Affect. Disord. 2009, 117, 63\u201373. [CrossRef]\n133. Seem\u00fcller, F.; Riedel, M.; Obermeier, M.; Bauer, M.; Adli, M.; Mundt, C.; Holsboer, F.; Brieger, P.; Laux, G.; Bender, W.; et al. The\ncontroversial link between antidepressants and suicidality risks in adults: Data from a naturalistic study on a large sample of",
    "The\ncontroversial link between antidepressants and suicidality risks in adults: Data from a naturalistic study on a large sample of controversial link between antidepressants and suicidality risks in adults: Data from a naturalistic study on a large sample of\nin-patients with a major depressive episode. Int. J. Neuropsychopharmacol. 2009, 12, 181\u2013189. [CrossRef]\n134. St\u00fcbner, S.; Grohmann, R.; Greil, W.; Zhang, X.; M\u00fcller-Oerlinghausen, B.; Bleich, S.; R\u00fcther, E.; M\u00f6ller, H.-J. ; Engel, R.; Falkai, P.;\net al. Suicidal ideation and suicidal behavior as rare adverse events of antidepressant medication: Current report from the AMSP\nmulticenter drug safety surveillance project. Int. J. Neuropsychopharmacol. 2018, 21, 814\u2013821. [CrossRef]\n135. Wichniak, A.; Wierzbicka, A.; Wal\u02db\necka, M.; Jernajzzyk, W. Effects of Antidepressants on Sleep. Curr. Psychiatry Rep. 2017, 19, 63. [CrossRef]",
    "GCF-Giraffe-booklet-2017-LR-spreads-c-GCF.compressed.pdf",
    "GCF-Giraffe-booklet-2017-LR-spreads-c-GCF.compressed.pdf A CONSERVATION GUIDE\nAFRICA\u2019S GIRAFFE\nIUCN RED LIST\nBILLY DODSON\nCONTENTS\nIntroduction\t\n1\n\t Evolution\t\n2\nGiraffe & humans\t\n2\nGiraffe facts\t\n3\nTaxonomy & species\t\n5\nDistribution & habitat\t\n6\n\t Masai giraffe\t\n7\n\t Northern giraffe\t\n8\n\t \t Kordofan giraffe\t\n8\n\t \t Nubian giraffe\t\n9\n\t \t West African giraffe\t\n10\n\t Reticulated giraffe\t\n11\n\t Southern giraffe\t\n12\n\t \t Angolan giraffe\t\n12\n\t \t South African giraffe\t\n13\nConservation\t\n14\nStatus & statistics\t\n14\nStakeholders\t\n16\nThreats\t\n17\nLimiting factors\t\n18\nSignificance of giraffe\t\n20\nEconomic\t\n20\nEcological\t\n20\nThe future\t\n21\nGiraffe Conservation Foundation\t\n22\nOPPOSITE  These giraffe images, \nwhich are carved life-size and with \nincredible detail into rock, are \nbelieved to date back 9,000 years \nto a time when the Sahara was wet \nand green. MIKE HETTWER\nWIKIMEDIA COMMONS\nIn 1612, \na giraffe star-\nconstellation was \nidentified in northern \nhemisphere \nskies. D\nI\nD\n \nY\nO\nU\n \nK\nN\nO\nW\n? Introduction",
    "Introduction and green. MIKE HETTWER\nWIKIMEDIA COMMONS\nIn 1612, \na giraffe star-\nconstellation was \nidentified in northern \nhemisphere \nskies. D\nI\nD\n \nY\nO\nU\n \nK\nN\nO\nW\n? Introduction\nAfrica\u2019s Giraffe \u2013 A Conservation Guide, provides essential, up-to-date information on one \nof the world\u2019s most iconic animals: the giraffe. It highlights conservation and management \nchallenges faced by all stakeholders across the continent, from local communities to \ngovernments and their agencies, and from the non-governmental conservation community \nto the private sector. This guide comes at a significant time for giraffe in Africa with the \npresent knowledge that their numbers have suffered a decrease by approximately 40% in \nthe past three decades, and the recent discovery that there are in fact four species of giraffe \nand not only one, as previously assumed. Giraffe are still considered as one species by the \nInternational Union for the Conservation of Nature (IUCN), and their formal conservation",
    "Giraffe are still considered as one species by the \nInternational Union for the Conservation of Nature (IUCN), and their formal conservation and not only one, as previously assumed. Giraffe are still considered as one species by the \nInternational Union for the Conservation of Nature (IUCN), and their formal conservation \nstatus on the IUCN Red List of Threatened Species is now listed as Vulnerable. Additionally, \ntwo subspecies have already been classified as Endangered with a high conservation priority. Surprisingly, giraffe in the wild have been largely ignored and under-researched. This \nsituation is slowly being addressed. With a few exceptions, giraffe are in decline throughout \nthe continent and the need for a concerted conservation effort has never been more urgent. In order to address this, the Giraffe Conservation Foundation (GCF) has drafted an Africa-\nwide Giraffe Strategic Framework, providing a road-map for giraffe conservation throughout \nAfrica. Evolution\nHelladotherium, a three-metre-tall \nantelope-like animal, which once roamed \nthe plains and forests of Asia and Europe",
    "Evolution\nHelladotherium, a three-metre-tall \nantelope-like animal, which once roamed \nthe plains and forests of Asia and Europe Africa. Evolution\nHelladotherium, a three-metre-tall \nantelope-like animal, which once roamed \nthe plains and forests of Asia and Europe \nbetween the Eocene and Oligocene epochs \n30-50 million years ago, is the forefather of the \ntwo remaining members of the Giraffidae family: \nthe giraffe and the okapi. To date, more than ten \nfossil genera have been discovered, revealing that \nby the Miocene epoch, 6-20 million years ago, \nearly deer-like giraffids were yet to develop the \ncharacteristic long neck of today\u2019s giraffe. Giraffe and humans\nThis exotic, long-necked creature has captured \nthe human imagination through the ages, as \ndemonstrated in art throughout the African \ncontinent, be it by the Egyptians, the Nubians or, \nin the south, the San. Rock carvings in the Sahara \nDesert in northern Niger, estimated to be 9,000 \nyears old, represent the earliest, and arguably the \nmost impressive, recorded human association \nwith giraffe. Beyond the African continent, the",
    "Beyond the African continent, the Desert in northern Niger, estimated to be 9,000 \nyears old, represent the earliest, and arguably the \nmost impressive, recorded human association \nwith giraffe. Beyond the African continent, the \ngiraffe delighted Caesar\u2019s Rome as long ago as 46 \nBC and it also features in artwork from the Chinese \nMing dynasty. The giraffe continues to be iconic today. It is the \nnational animal of Tanzania, and in Botswana, it \nis considered to be the royal totem and, therefore, \nmay not be hunted. Its distinctive, iconic image \nis used in advertising around the world to sell \nanything from children\u2019s apparel to wine, or for the \npromotion of social media fads and the FIFA World \nCup. Why then, having captivated humans so infinitely \nthrough the ages, has the giraffe been allowed to \nslip beneath the conservation radar? Why are they \nexperiencing such significant population declines \nin much of their remaining range? These are only \ntwo out of the many questions that urgently require",
    "These are only \ntwo out of the many questions that urgently require experiencing such significant population declines \nin much of their remaining range? These are only \ntwo out of the many questions that urgently require \nanswers to help save giraffe, before it is too late. Giraffe Conservation Foundation\t\n2\n1\t\ngiraffeconservation.org\nHeight (average adult)\nM 5.3m (17ft 4in)\nF 4.3m (14ft 2in)\nWeight (average adult)\nM 1,200kg (2,600lb)\nF 830kg (1,800lb) \nLargest\nM recorded at 6m (19+ ft)\nHeaviest\nM recorded at 1,900kg (4,200lb)\nFoot size\n30cm (12in) diameter\nHoof: M 20cm (8in); F 18cm (7in) (average)\nDefence\nForelegs and hind legs can deliver a \nlethal kick. They can kick in all directions. Speed\n50km/h (30mph) for sustained periods; calves less than \n3m (9ft 10in) high can outrun adults. Means of feeding\nBrowsing, using a prehensile tongue (50cm (20in) long) \nand upper lip. Diet\nTree leaves, fruits, pods and shoots; rarely grass. Senses\nColour vision, acute sense of smell, good hearing. Sleep\n4.5hrs, mainly at night; both standing and lying down.",
    "Sleep\n4.5hrs, mainly at night; both standing and lying down. and upper lip. Diet\nTree leaves, fruits, pods and shoots; rarely grass. Senses\nColour vision, acute sense of smell, good hearing. Sleep\n4.5hrs, mainly at night; both standing and lying down. Longevity\n+/- 25 years (average)\nSocial behaviour\nRanges from solitary (often older males) to large, loose, \nmixed herds. Herds adjust their social systems, known \nas fission-fusion, by individuals or smaller groups readily \nmerging with or splitting from the herd. This differs from \none population to another. Sex ratio\nVery close to 1:1 (average)\nAge at sexual maturity\nM restricted by competition from larger males. F 3-4 years; in oestrus 1 day every 2 weeks. Breeding lifetime\nThroughout life. F recorded mating within weeks of giving birth. GIRAFFE FACTS\nBILLY DODSON\nGestation\n+/- 15 months (453-464 days)\nOffspring\nSingle calf, rarely twins; known to stay with mother until \n22 months old, but often independent much sooner, \ndepending on the gender. Conservation Status",
    "Conservation Status +/- 15 months (453-464 days)\nOffspring\nSingle calf, rarely twins; known to stay with mother until \n22 months old, but often independent much sooner, \ndepending on the gender. Conservation Status\nGiraffe, as a species, are listed as Vulnerable on the \nIUCN Red List. Giraffe have no \nfront teeth in their \nupper jaw. D\nI\nD\n \nY\nO\nU\n \nK\nN\nO\nW\n? 3\t\ngiraffeconservation.org\nGiraffe Conservation Foundation\t\n4\nLike okapi, hippo, oryx, buffalo and cattle, the giraffe is an even-toed ungulate. Rhino, zebra \nand horses are odd-toed ungulates. As the world\u2019s tallest animal and largest ruminant (an \nanimal that partly digests its food, then regurgitates it to chew as \u2018cud\u2019), it belongs to: \nClass: \t Mammalia (mammals)\nOrder: \t Artiodactyla (even-toed ungulates) \nFamily: \tGiraffidae\u2028\nGenus: \tGiraffa\nUntil recently, it was widely recognised that there was only one species of giraffe, and nine \nsubspecies. New genetic research, conducted by GCF and partners, has shown that there",
    "New genetic research, conducted by GCF and partners, has shown that there Genus: \tGiraffa\nUntil recently, it was widely recognised that there was only one species of giraffe, and nine \nsubspecies. New genetic research, conducted by GCF and partners, has shown that there \nare in fact four distinct species of giraffe, and five subspecies. These ground-breaking \nfindings will enhance future giraffe research, conservation and management. To confirm \nthese findings, further research is being carried out by GCF and partners to correlate genetics \nwith the traditional classification taxonomy methods, based on morphology and geography. All four giraffe species and their subspecies live in geographically distinct areas throughout \nAfrica. While some of these species have been reported to hybridise in zoos, there is very \nlittle evidence that this occurs readily in the wild. Taxonomy and Species\nBILLY DODSON\n5\t\ngiraffeconservation.org\nDistribution and Habitat\nThe four species of giraffe currently occur in 21 countries, forming a wide arc throughout",
    "Taxonomy and Species\nBILLY DODSON\n5\t\ngiraffeconservation.org\nDistribution and Habitat\nThe four species of giraffe currently occur in 21 countries, forming a wide arc throughout Taxonomy and Species\nBILLY DODSON\n5\t\ngiraffeconservation.org\nDistribution and Habitat\nThe four species of giraffe currently occur in 21 countries, forming a wide arc throughout \nsub-Saharan Africa from Niger to Central and East Africa, down to southern Africa. Giraffe \nare predominantly browsers and their long custom-built legs and neck ensure the utilisation \nof a food source beyond the reach, except for elephant, of any other animals. Surprisingly, \ndespite this highly specialised adaptation, giraffe are extremely versatile and also flourish in \nhabitats with relatively few tall trees where, instead, they trim the tops of bushes and smaller \ntrees. Nevertheless, the quintessential image of a giraffe shows it reaching up to browse on \none of Africa\u2019s large Acacia trees. To drink, giraffe first have to splay their forelegs and/or bend their knees, and only then can \nthey lower their necks to drink. However, despite their body mass, water is not a necessity",
    "However, despite their body mass, water is not a necessity To drink, giraffe first have to splay their forelegs and/or bend their knees, and only then can \nthey lower their necks to drink. However, despite their body mass, water is not a necessity \nas they can absorb sufficient moisture from their food plants. Even when water is readily \navailable, evidence shows that many giraffe do not drink regularly \u2013 sometimes, not at all. Giraffa tippelskirchi\nGiraffa camelopardalis\n\t\nG. c. antiquorum\n\t\nG. c. camelopardalis\n\t\nG. c. peralta\nGiraffa reticulata\nGiraffa giraffa\n\t\nG. g. angolensis\n\t\nG. g. giraffa\nGiraffe Conservation Foundation\t\n6\nSubspecies:\nKordofan giraffe G. c. antiquorum\nThe Kordofan giraffe\u2019s range includes some of Africa\u2019s \nmore hostile areas: southern Chad, Central African \nRepublic, northern Cameroon, northern Democratic \nRepublic of Congo, and western South Sudan. It is \nestimated that fewer than 2,000 individuals survive in \nthese war ravaged countries. Some of these populations",
    "Some of these populations Republic of Congo, and western South Sudan. It is \nestimated that fewer than 2,000 individuals survive in \nthese war ravaged countries. Some of these populations \nwere previously assumed to be other giraffe subspecies, \nbut our recent research has shown that they are a distinct \nsubspecies. The Kordofan giraffe\u2019s patches \nare pale and irregular. Similar \nto other northern giraffe \nsubspecies, they have no \nmarkings on their lower legs. Northern giraffe  \nGiraffa camelopardalis\nThree subspecies of the northern giraffe occur across \nEastern and Central Africa. Cameroon\nChad\nCAR\nDRC\nSouth \nSudan\nMasai giraffe  \nGiraffa tippelskirchi\nMasai giraffe range across central and southern Kenya; \nthroughout Tanzania; and an isolated population exists \nin the South Luangwa Valley, northeastern Zambia \n(formerly known as Thornicroft\u2019s giraffe). Extralimital \npopulations (those outside their natural range) have \nbeen translocated to the Akagera National Park,",
    "Extralimital \npopulations (those outside their natural range) have \nbeen translocated to the Akagera National Park, (formerly known as Thornicroft\u2019s giraffe). Extralimital \npopulations (those outside their natural range) have \nbeen translocated to the Akagera National Park, \nRwanda. Formerly the most populous giraffe with an \nestimated 66,500 individuals three decades ago, less \nthan half (32,500) of them remain in the wild today. Approximately 600 of the remaining individuals occur in \nthe geographically isolated Zambian population. Ongoing \nreports of poaching suggest that their population \ncontinues to decrease. The Masai giraffe is often \nnoticeably darker than other \nspecies. Its patches are large, \ndark brown and distinctively \nvine leaf-shaped with jagged \nedges. The patches are \nsurrounded by a creamy-\nbrown colour, which continues \ndown their lower legs. BILLY DODSON\nKenya\nTanzania\nZambia\n7\t\ngiraffeconservation.org\nGiraffe Conservation Foundation\t\n8\nSubspecies: \nWest African giraffe  G. c. peralta\nAt the beginning of the 20th century the West African",
    "BILLY DODSON\nKenya\nTanzania\nZambia\n7\t\ngiraffeconservation.org\nGiraffe Conservation Foundation\t\n8\nSubspecies: \nWest African giraffe  G. c. peralta\nAt the beginning of the 20th century the West African Kenya\nTanzania\nZambia\n7\t\ngiraffeconservation.org\nGiraffe Conservation Foundation\t\n8\nSubspecies: \nWest African giraffe  G. c. peralta\nAt the beginning of the 20th century the West African \ngiraffe were widely distributed, from Nigeria to Senegal, \nbut by the mid 1990s only 49 individuals remained in \nthe whole of West Africa. These few survivors are now \nformally protected by the Niger government and their \nnumbers have risen to approximately 550 individuals. However, their future is still of great concern as they live \nin an isolated pocket (the giraffe zone) east of the capital \nNiamey, and share their living space with local villagers. No other large wild mammals occur in this area, and \nhabitat loss and destruction is increasing. In 2008, the \nWest African giraffe was classified as Endangered and \nof high conservation importance on the IUCN Red List. The West African giraffe is \nnoticeably light in appearance. Their patches are rectangular \nand tan coloured, and are",
    "Their patches are rectangular \nand tan coloured, and are of high conservation importance on the IUCN Red List. The West African giraffe is \nnoticeably light in appearance. Their patches are rectangular \nand tan coloured, and are \nbroadly surrounded by a \ncreamy-colour. There are no \nmarkings on their lower legs. Niger\nBurkina \nFaso\nMali\nBenin\nNigeria\nSubspecies: \nNubian giraffe  G. c. camelopardalis\nThe Nubian giraffe is the nominate subspecies, which \nmeans that its Latin sub-specific name is the same as \nthe original species described because it was the first \nspecimen recorded. The estimated number of Nubian \ngiraffe is 2,645 individuals, which includes the genetically \nidentical formerly recognised Rothschild\u2019s giraffe. At \npresent, fewer than 200 occur in western Ethiopia, 450 \nin eastern South Sudan, 450 in Kenya, and more than \n1,545 in Uganda. Interestingly, the majority of Nubian giraffe in Kenya live \nextralimitally (outside their natural range), which is the \nresult of an effort to establish viable populations for",
    "Interestingly, the majority of Nubian giraffe in Kenya live \nextralimitally (outside their natural range), which is the \nresult of an effort to establish viable populations for 1,545 in Uganda. Interestingly, the majority of Nubian giraffe in Kenya live \nextralimitally (outside their natural range), which is the \nresult of an effort to establish viable populations for \nconservation. Exact information about the precariously small and \nfragmented populations in Ethiopia and South Sudan \nis extremely difficult to ascertain, and their numbers \nare likely lower due to ongoing poaching in the region. In 2010, the formerly known Rothschild\u2019s subspecies \nwas classified as Endangered and of high conservation \nimportance on the IUCN Red List. The Nubian giraffe\u2019s patches \nare large, rectangular and \nchestnut-brown. The patches \nare surrounded by an off-\nwhite, creamy colour. There \nare no markings on their lower \nlegs. South \nSudan\nEthiopia\nKenya\nUganda\n9\t\ngiraffeconservation.org\nGiraffe Conservation Foundation\t\n10\nSubspecies: \nAngolan giraffe  G. g. angolensis\nDespite their name, Angolan giraffe were extirpated",
    "South \nSudan\nEthiopia\nKenya\nUganda\n9\t\ngiraffeconservation.org\nGiraffe Conservation Foundation\t\n10\nSubspecies: \nAngolan giraffe  G. g. angolensis\nDespite their name, Angolan giraffe were extirpated South \nSudan\nEthiopia\nKenya\nUganda\n9\t\ngiraffeconservation.org\nGiraffe Conservation Foundation\t\n10\nSubspecies: \nAngolan giraffe  G. g. angolensis\nDespite their name, Angolan giraffe were extirpated \n(locally extinct) in Angola until recent translocations. The \nAngolan giraffe\u2019s range includes central Botswana and \nmost parts of Namibia. Extralimital populations (those \noutside their natural range) have been translocated \nto South Africa, and to private land in Botswana and \nZimbabwe. The estimated 5,000 individuals three \ndecades ago have, today, almost tripled to an estimated \n13,050 in the wild. The Angolan giraffe is \nrelatively light in colour. In \nnorthwest Namibia, where it is \nparticularly arid, they can be \nalmost colourless. They have \nlarge, uneven and irregularly \nnotched light brown patches. Their patches are surrounded \nby a pale cream colour, and \ntheir lower legs are randomly \nspeckled with uneven spots. Southern giraffe  \nGiraffa giraffa",
    "Southern giraffe  \nGiraffa giraffa notched light brown patches. Their patches are surrounded \nby a pale cream colour, and \ntheir lower legs are randomly \nspeckled with uneven spots. Southern giraffe  \nGiraffa giraffa\nTwo subspecies of the southern giraffe occur across \nSouthern Africa and, together, they make up more than \n50% of the continent\u2019s total giraffe numbers. Namibia\nBotswana\nReticulated giraffe  \nGiraffa reticulata\nThe reticulated giraffe has a relatively limited distribution \nacross northern and north-eastern Kenya, and small \nrestricted populations most likely persist in southern \nSomalia and southern Ethiopia. It is estimated that \nabout 8,700 individuals remain in the wild \u2013 a significant \ndecrease from the approximate 37,000 three decades \nago. However, numbers across northern Kenya appear \nto be increasing with improved community and private \nland conservation. It is easy to see why this \nspecies is called the \nreticulated giraffe, as its rich \norange-brown patches are",
    "It is easy to see why this \nspecies is called the \nreticulated giraffe, as its rich \norange-brown patches are to be increasing with improved community and private \nland conservation. It is easy to see why this \nspecies is called the \nreticulated giraffe, as its rich \norange-brown patches are \nclearly defined by a network of \nstriking white lines, which \ncontinue the entire length of \ntheir legs. Ethiopia\nSomalia\nKenya\n11\t\ngiraffeconservation.org\nGiraffe Conservation Foundation\t\n12\nSubspecies: \nSouth African giraffe  G. g. giraffa\nThe South African giraffe ranges from west to east \nacross southern eastern Angola; northern Botswana; \nsouthern Mozambique; northern South Africa; south-\nwestern Zambia; and eastern and southern Zimbabwe. Previous re-introductions of the South African and \nAngolan giraffe to overlapping areas have likely resulted \nin hybrid populations. There have also been extralimital \n(outside their natural range) introductions of South \nAfrican giraffe across Angola, Senegal, South Africa, \nZambia and Zimbabwe. At present, the South African",
    "At present, the South African (outside their natural range) introductions of South \nAfrican giraffe across Angola, Senegal, South Africa, \nZambia and Zimbabwe. At present, the South African \ngiraffe population is estimated at 39,000 individuals, \nshowing a marked increase over the past three decades. The South African giraffe has \nstar-shaped patches in various \nshades of brown, surrounded \nby a light tan colour. Their \nlower legs are randomly \nspeckled with uneven spots. Zambia\nAngola\nZimbabwe\nBotswana\nSouth \nAfrica\nMozambique\nConservation\nStatus and statistics\nThree decades ago, in the 1980s, the total number of all giraffe in Africa was estimated \nat greater than 155,000 individuals. Today, the IUCN Species Survival Commission (SSC) \nGiraffe & Okapi Specialist Group and GCF estimate the current Africa-wide giraffe population \nto be less than 100,000 individuals. This is a drop by almost 40%. In some areas traditionally \nregarded as prime giraffe habitat, numbers have dropped by more than 95%.",
    "In some areas traditionally \nregarded as prime giraffe habitat, numbers have dropped by more than 95%. to be less than 100,000 individuals. This is a drop by almost 40%. In some areas traditionally \nregarded as prime giraffe habitat, numbers have dropped by more than 95%. Limited conservation research has been undertaken on giraffe throughout Africa. Whilst the \nIUCN Red List currently recognises one species of giraffe and nine subspecies, new findings \nby GCF and partners propose that there are actually four species and five subspecies of \ngiraffe. More research is needed to confirm these findings before the IUCN can take them into \nconsideration for future assessments. As a species, the giraffe is listed as Vulnerable on the IUCN Red List of Threatened Species. Furthermore, two of the currently recognised subspecies are listed as Endangered. Updated \nassessments for most other subspecies have been submitted for review to better understand \ntheir conservation status. GCF researchers have begun, and continue, to develop the first-ever continent-wide giraffe-",
    "GCF researchers have begun, and continue, to develop the first-ever continent-wide giraffe- their conservation status. GCF researchers have begun, and continue, to develop the first-ever continent-wide giraffe-\nrange-state country profiles. These profiles collate all historical and currently available census \nand anecdotal data on giraffe numbers and distribution, as well as their specific threats. Below are the most up-to-date population figures, some of which formed the basis of the \nupdated IUCN Red List assessment of giraffe as Vulnerable. Species and Numbers\nGiraffa camelopardalis (northern giraffe)\t\n5,195\n\t\nG. c. antiquorum (Kordofan giraffe)\t\n2,000\n\t\nG. c. camelopardalis (Nubian giraffe)\t\n2,645\n\t\nG. c. peralta (West African giraffe)\t\n550\nGiraffa giraffa (southern giraffe)\t\n52,050\n\t\nG. g. angolensis (Angolan giraffe)\t\n13,050\n\t\nG. g. giraffa (South African giraffe)\t\n39,000\nGiraffa reticulata (reticulated giraffe)\t\n8,700\nGiraffa tippelskirchi (Masai giraffe)\t\n32,500\n13\t\ngiraffeconservation.org\nGiraffe Conservation Foundation\t\n14\n450,000\n100,000\n50,000\n0\n \n1 \n2 \n3 \n4 \n5",
    "Species and Numbers\nGiraffa camelopardalis (northern giraffe)\t\n5,195\n\t\nG. c. antiquorum (Kordofan giraffe)\t\n2,000\n\t\nG. c. camelopardalis (Nubian giraffe)\t\n2,645\n\t\nG. c. peralta (West African giraffe)\t\n550\nGiraffa giraffa (southern giraffe)\t\n52,050\n\t\nG. g. angolensis (Angolan giraffe)\t\n13,050\n\t\nG. g. giraffa (South African giraffe)\t\n39,000\nGiraffa reticulata (reticulated giraffe)\t\n8,700\nGiraffa tippelskirchi (Masai giraffe)\t\n32,500\n13\t\ngiraffeconservation.org\nGiraffe Conservation Foundation\t\n14\n450,000\n100,000\n50,000\n0\n \n1 \n2 \n3 \n4 \n5 Giraffa reticulata (reticulated giraffe)\t\n8,700\nGiraffa tippelskirchi (Masai giraffe)\t\n32,500\n13\t\ngiraffeconservation.org\nGiraffe Conservation Foundation\t\n14\n450,000\n100,000\n50,000\n0\n \n1 \n2 \n3 \n4 \n5 \n6 \n7 \n8 \n9 \n10 \n11\n \nSales\n1st Qtr\n2nd Qtr\n3rd Qtr\n4th Qtr\nMasai giraffe\nSouthern \ngiraffe\nNorthern giraffe\nReticulated \ngiraffe\n1. African elephant \t\n450,000\t\nVU\n2. Hippo \t\n125,000\t\nVU\n3. Giraffe (all)\t\n98,445\t\nVU\n4. Southern giraffe \t\n52,050\t\nNE \n5. Masai giraffe \t\n32,500\t\nNE\n6. Lion \t\n20,000\t\nVU\n7. Reticulated giraffe \t\n8,700\t\nNE\n8. Cheetah\t\n7,500\t\nVU\n9. Black rhino\t\n5,250\t\nCR\n10. Northern giraffe\t\n5,195\t\nNE\n11. Mountain gorilla \t\n880\t\nCR\nCITES\nAs there is limited recognised international trade in giraffe and their parts, they are not \nlisted in the Convention on International Trade in Endangered Species of Wild Fauna and \nFlora (CITES). GCF is committed to clarifying and monitoring the giraffe trade situation and",
    "GCF is committed to clarifying and monitoring the giraffe trade situation and listed in the Convention on International Trade in Endangered Species of Wild Fauna and \nFlora (CITES). GCF is committed to clarifying and monitoring the giraffe trade situation and \nreviewing the appropriateness of the current CITES listing. Stakeholders\nOccurring in 21 African countries, giraffe live throughout all land-management regimes: \nfrom state-owned national parks and reserves to private and communal lands. Many of the \norganisations and individuals who live and work in these areas, often in the wildlife industry, \nrecognise the importance of giraffe and have become directly or indirectly involved in their \nconservation. As giraffe are widely distributed throughout Africa, their conservation is not an \neasy task. It will be a challenge to develop and coordinate a continent-wide giraffe strategy \nIUCN Red List\t\nGiraffe  Giraffa camelopardalis\t\nVulnerable\nWest African giraffe  G. c. peralta \t\nEndangered\nRothschild\u2019s giraffe  G. c. rothschildi  \t Endangered\nGiraffe \u2018horns\u2019",
    "It will be a challenge to develop and coordinate a continent-wide giraffe strategy \nIUCN Red List\t\nGiraffe  Giraffa camelopardalis\t\nVulnerable\nWest African giraffe  G. c. peralta \t\nEndangered\nRothschild\u2019s giraffe  G. c. rothschildi  \t Endangered\nGiraffe \u2018horns\u2019 IUCN Red List\t\nGiraffe  Giraffa camelopardalis\t\nVulnerable\nWest African giraffe  G. c. peralta \t\nEndangered\nRothschild\u2019s giraffe  G. c. rothschildi  \t Endangered\nGiraffe \u2018horns\u2019 \nare not horns at all, but \n\u2018ossicones\u2019. Ossicones are \nlumps of soft cartilage which, \nin later life, ossify and fuse to \nthe skull. They are believed \nto aid thermoregulation. D\nI\nD\n \nY\nO\nU\n \nK\nN\nO\nW\n? 15\t\ngiraffeconservation.org\nGiraffe Conservation Foundation\t\n16\nand action plan that incorporates the priorities of each stakeholder, country, and the four \nspecies and their subspecies. Although giraffe conservation should be seen as an Africa-wide initiative, GCF is helping to \ntackle it by starting with a country-by-country and species-by-species approach. Priorities \nare critical for the long-term objective of developing a consolidated continent-wide strategy. Threats \nThe combined impacts of habitat loss, habitat fragmentation, habitat degradation, human",
    "Threats \nThe combined impacts of habitat loss, habitat fragmentation, habitat degradation, human are critical for the long-term objective of developing a consolidated continent-wide strategy. Threats \nThe combined impacts of habitat loss, habitat fragmentation, habitat degradation, human \npopulation growth, poaching, disease, war and civil unrest threaten the remaining giraffe \nnumbers and their distribution throughout Africa. Many threats arise from direct, indirect or \nperceived competition for resources with humans and their livestock. Habitat degradation \nand destruction is caused by an increasing human demand for agricultural land, pastoralism, \nand uncontrolled timber and fuel-wood harvesting. Human-giraffe conflict can develop due to crop loss and damage, and potential disease \ntransmission can result from habitat sharing with domestic livestock. Sadly, giraffe outside \nprotected areas are sometimes also struck by vehicles and trains. The fragmentation and loss of giraffe habitat caused by human encroachment often leads",
    "The fragmentation and loss of giraffe habitat caused by human encroachment often leads protected areas are sometimes also struck by vehicles and trains. The fragmentation and loss of giraffe habitat caused by human encroachment often leads \nto the isolation of giraffe populations which, in turn, limits the flow and exchange of genetic \ndiversity between populations. BILLY DODSON\nAlthough there is very little \nevidence of species interbreeding \nin the wild, the translocation of \none species of giraffe to an area \nalready occupied by a different \nspecies could create the risk \nof hybridisation. Should they \ninterbreed, the genetic uniqueness \nof each individual species would \nbe lost. Limiting factors\nThe giraffe has a distinct advantage \nin that it seldom competes with \nother wild animals or, more \nimportantly, domestic livestock \nfor food. Although conflict does \nsometimes occur, they do not \nnaturally/normally pose a threat \nto humans. Nevertheless, there \nare a number of factors that \nrestrict conservation initiatives \nthroughout Africa. Scientific",
    "Scientific sometimes occur, they do not \nnaturally/normally pose a threat \nto humans. Nevertheless, there \nare a number of factors that \nrestrict conservation initiatives \nthroughout Africa. Scientific \nLong-term studies, reliable historical and current data, and targeted research are all \nlacking. This lack of information remains one of the most limiting factors when it comes \nto understanding the conservation and management of giraffe, as well as their ecology, \ntaxonomy and physiology. Current giraffe projects being conducted in Africa are some of \nthe first ever. More extensive knowledge of giraffe is required, and exciting advances are being made. Our ongoing genetic research on giraffe populations across the continent has unravelled the \nmystery surrounding the giraffe\u2019s taxonomy, providing invaluable information for Africa-wide \ngiraffe conservation and management. The giraffe\u2019s physiology brings its own problems. Translocation projects can be highly",
    "Translocation projects can be highly giraffe conservation and management. The giraffe\u2019s physiology brings its own problems. Translocation projects can be highly \nbeneficial for establishing or securing new giraffe populations, but they are a significant \nlogistical undertaking. Conservationists and stakeholders go to great lengths in their efforts \nto secure giraffe populations and success can already be seen in many countries. GPS satellite tracking units have become an important aid for understanding giraffe home \n17\t\ngiraffeconservation.org\nGiraffe Conservation Foundation\t\n18\nranges and individuals\u2019 daily and \nseasonal movements, be they in \nand around human settlements or \nacross international borders. The \ninformation these devices provide \nis \ninvaluable \nfor \nsupporting \nlong-term species and land \nmanagement plans for giraffe \nand other wildlife. Nevertheless, \ntracking giraffe using GPS satellite \nunits remains in its infancy and it \nrequires greater investment in \nboth time and resources \u2013 and",
    "Nevertheless, \ntracking giraffe using GPS satellite \nunits remains in its infancy and it \nrequires greater investment in \nboth time and resources \u2013 and and other wildlife. Nevertheless, \ntracking giraffe using GPS satellite \nunits remains in its infancy and it \nrequires greater investment in \nboth time and resources \u2013 and \nby its very nature of being such \na uniquely built animal, it is \nsomething of a challenge! Ecological \nGiraffe \npopulations \nnaturally \nfluctuate due to mortality through \npredation and disease, although \nthis varies from population to \npopulation across the continent. Although lions prey on adult \ngiraffe, they can result in 50% \nor more of new-born giraffe not \nmaking it through their first year. Giraffe are also vulnerable to leopard and spotted hyena, and to a lesser extent cheetah and \ncrocodile. Additionally, humans pose a big problem by poaching giraffe throughout their \nrange. Population growth is also limited by malnutrition, resulting from poor food quality and \nquantity, as well as diseases such as anthrax and rinderpest. Social",
    "Social range. Population growth is also limited by malnutrition, resulting from poor food quality and \nquantity, as well as diseases such as anthrax and rinderpest. Social \nWhen it comes to conservation, giraffe compete with more charismatic species such as \nelephant and lion, particularly for funding. It is estimated that the current giraffe population \nis a quarter of the African elephant\u2019s. This discrepancy, and little-known fact by most in the \nworld, understandably leads many people to assume that  giraffe are everywhere and do \nnot face a conservation crisis \u2013 but the 40% population decline over the past three decades \nclearly demonstrates that it does. The extent of poaching and its subsequent changes in giraffe population dynamics is still \npoorly understood. It is a subject that needs to be further addressed but, already, reports \nfrom various parts of Africa are not positive. Significance of Giraffe\nEconomic",
    "Significance of Giraffe\nEconomic poorly understood. It is a subject that needs to be further addressed but, already, reports \nfrom various parts of Africa are not positive. Significance of Giraffe\nEconomic\nThe giraffe\u2019s significance lies in its evolutionary uniqueness. Its silhouette, which is both \nunmistakable and evocative, is used around the world as a symbol to market a wide range \nof commercial and non-commercial products, events and initiatives. As much as it is a \nsymbol for Africa, the giraffe is also used widely for other purposes because of its uniquely \nrecognisable shape and its perceived gentle nature. Giraffe are much-loved by most. In Africa, it is the tangible economic benefits generated by tourism that interest and motivate \nmany stakeholders, particularly those who live and work amongst wildlife. Many travel \noperators and safari brochures include the giraffe when marketing Africa as an exciting travel \ndestination, and giraffe are a must-see on every African safari-goer\u2019s wish list.",
    "Many travel \noperators and safari brochures include the giraffe when marketing Africa as an exciting travel \ndestination, and giraffe are a must-see on every African safari-goer\u2019s wish list. operators and safari brochures include the giraffe when marketing Africa as an exciting travel \ndestination, and giraffe are a must-see on every African safari-goer\u2019s wish list. Unlike the \u2018Big Five\u2019 (buffalo, elephant, leopard, lion and rhino) and a handful of ungulates, the \ngiraffe is not in demand as a trophy. Revenue from legal hunting is therefore limited. Ecological\nGiraffe are habitat and landscape changers. Together \nwith other large browsers, such as elephant and rhino, \nthey open up vegetated areas and promote the growth \nof new  forage for themselves and other wildlife. On a finer scale, giraffe browsing stimulates shoot \nproduction in various plant species, and often \nfunctions as a valuable pollinator. For example, in areas \nprotected from giraffe and other mega-herbivores, a \ndecline of some Acacia species can be observed. This \nsubsequently affects available food sources for other wildlife.",
    "This \nsubsequently affects available food sources for other wildlife. protected from giraffe and other mega-herbivores, a \ndecline of some Acacia species can be observed. This \nsubsequently affects available food sources for other wildlife. Giraffe also provide an essential natural landscape service by eating plant seeds and \ndispersing them in new areas through their droppings. The seeds\u2019 potential to germinate is \nenhanced once they have passed through the giraffe\u2019s digestive tract, and they are deposited \nwith their own little fertiliser power-packs! However, there are not only mutually beneficial relationships between giraffe and many \nplants, but also with some animals, especially the oxpecker. These birds have the important \njob of assisting giraffe to groom hard-to-reach places by removing parasitic ticks, which \noften infest giraffe and their wounds, and at the same time they benefit from a valuable food \nsource. The Romans \nbelieved that the giraffe \nwas part camel and part \nleopard, hence the scientific \nname camelopardalis. However,",
    "However, source. The Romans \nbelieved that the giraffe \nwas part camel and part \nleopard, hence the scientific \nname camelopardalis. However, \ntheir lack of ferocity apparently \ndisappointed the crowds \nin colosseum fighting-\narenas! D\nI\nD\n \nY\nO\nU\n \nK\nN\nO\nW\n? 19\t\ngiraffeconservation.org\nGiraffe Conservation Foundation\t\n20\nThe Giraffe Conservation Foundation (GCF) is dedicated to securing a future for all giraffe \nin Africa. GCF is the only NGO in the world that concentrates solely on the conservation \nand management of giraffe in the wild throughout Africa. As a Namibia-based organisation, \nGCF currently supports and works collaboratively with giraffe conservation initiatives in 14 \ncountries throughout Africa, on all giraffe species and their subspecies. As the key focal organisation for the conservation and management of giraffe in Africa, GCF \nuses its ever-expanding network to maintain a close working relationship with government",
    "As the key focal organisation for the conservation and management of giraffe in Africa, GCF \nuses its ever-expanding network to maintain a close working relationship with government As the key focal organisation for the conservation and management of giraffe in Africa, GCF \nuses its ever-expanding network to maintain a close working relationship with government \nbodies, conservation organisations, academic institutions and local communities. It provides \na platform and forum for giraffe conservation and related management discussions, and helps \nsignificantly to increase awareness and education about the plight of giraffe. Importantly, \nGCF supports dedicated and innovative conservation and research to better understand \ngiraffe ecology, speciation, conservation and management. giraffeconservation.org\nIUCN SSC Giraffe and \nOkapi Specialist Group\nThe International Union for Conservation of Nature\u2019s (IUCN) Species Survival Commission \n(SSC) Giraffe and Okapi Specialist Group (GOSG) is one of over 120 IUCN SSC Specialist \nGroups, Red List Authorities and Task Forces working towards achieving the SSC\u2019s vision of",
    "giraffeconservation.org\nIUCN SSC Giraffe and \nOkapi Specialist Group\nThe International Union for Conservation of Nature\u2019s (IUCN) Species Survival Commission \n(SSC) Giraffe and Okapi Specialist Group (GOSG) is one of over 120 IUCN SSC Specialist \nGroups, Red List Authorities and Task Forces working towards achieving the SSC\u2019s vision of (SSC) Giraffe and Okapi Specialist Group (GOSG) is one of over 120 IUCN SSC Specialist \nGroups, Red List Authorities and Task Forces working towards achieving the SSC\u2019s vision of \n\u201ca world that values and conserves present levels of biodiversity\u201d. Made up of experts from \naround the world, IUCN SSC GOSG leads efforts to study giraffe and okapi and the threats \nthey face, as well as leading and supporting conservation actions designed to ensure the \nsurvival of the two species into the future. giraffidsg.org\n3\t\nwww.gifaffeconservation.org\nThe Future\nThe Giraffe Conservation Foundation (GCF) \nis dedicated to a sustainable future for all \ngiraffe populations in the wild. Working in \ncollaboration with African governments, \nNGOs, universities, researchers and the \nIUCN SSC Giraffe and Okapi Specialist \nGroup, GCF is developing appropriate \nconservation strategies for each of these \npopulations. There is no straight-forward \nsolution to giraffe conservation and",
    "There is no straight-forward \nsolution to giraffe conservation and Group, GCF is developing appropriate \nconservation strategies for each of these \npopulations. There is no straight-forward \nsolution to giraffe conservation and \nmanagement in Africa, but supporting and \nworking together with partners is the key \napproach. Even though giraffe can only \nbe saved in Africa, international support is \nimportant. GCF \nrecently \ndeveloped \nan \nAfrica-\nwide Strategic Framework for giraffe \nconservation, not only to guide the \norganisation\u2019s \nconservation \npriorities \nthroughout the continent, but to also serve \nas a road-map for future conservation by all \nstakeholders. GCF\u2019s continued focus includes working \nclosely with partners to develop National \nGiraffe Conservation Strategies and Action \nPlans, initiating conservation translocations, \nundertaking \npopulation \nassessments \nand on targeted giraffe conservation and \nmanagement efforts throughout Africa. Giraffe Conservation Foundation\nThe word \u2018giraffe\u2019 \nis believed to come \nfrom the Arab word",
    "Giraffe Conservation Foundation\nThe word \u2018giraffe\u2019 \nis believed to come \nfrom the Arab word population \nassessments \nand on targeted giraffe conservation and \nmanagement efforts throughout Africa. Giraffe Conservation Foundation\nThe word \u2018giraffe\u2019 \nis believed to come \nfrom the Arab word \nzarafa, which means \n\u2018fast walker\u2019. D\nI\nD\n \nY\nO\nU\n \nK\nN\nO\nW\n? BILLY DODSON\nGiraffe Conservation Foundation\t\n22\nThis updated edition of Africa\u2019s Giraffe \u2013 A Conservation Guide was produced by the Giraffe \nConservation Foundation (GCF). We are grateful for the support of all the credited photographers who have generously allowed us to \nreproduce their images free of charge, as well as for the effort of those involved in the development of \nthe first and second edition. Copyright \u00a9 Giraffe Conservation Foundation 2017\nCopyright for photographs as credited. Cover image by Majed Sultan. Giraffe Conservation Foundation\nPO Box 86099\nEros, Namibia\ninfo@giraffeconservation.org / giraffeconservation.org\nBibliography",
    "Giraffe Conservation Foundation\nPO Box 86099\nEros, Namibia\ninfo@giraffeconservation.org / giraffeconservation.org\nBibliography Copyright for photographs as credited. Cover image by Majed Sultan. Giraffe Conservation Foundation\nPO Box 86099\nEros, Namibia\ninfo@giraffeconservation.org / giraffeconservation.org\nBibliography\nGiraffe Conservation Foundation. 2013. Africa\u2019s Giraffe (Giraffa camelopardalis) \u2013 A Conservation \nGuide. Windhoek, Namibia. Fennessy, J., Bidon, T., Reuss, F., Kumar, V., Elkan, P\n., Nilsson, M.A., Vamberger, M. Fritz, U. & Janke, A. 2016. From one to four species: multi-locus analyses reveal hidden genetic diversity in \ngiraffe. Current Biology 10.1016/j.cub.2016.07.036\nMuller, Z., Bercovitch, F., Brand, R., Brown, D., Brown, M., Bolger, D., Carter, K., Deacon, F., \nDoherty, J.B., Fennessy, J., Fennessy, S., Hussein, A.A., Lee, D., Marais, A., Strauss, M., Tutchings, \nA. & Wube, T. 2016. Giraffa camelopardalis. The IUCN Red List of Threatened Species 2016: \ne.T9194A51140239. http://dx.doi.org/10.2305/IUCN.UK.2016-3.RLTS.T9194A51140239.en \n(Downloaded on 09 January 2017)\nAKSHAY  VISHWANATH",
    "http://dx.doi.org/10.2305/IUCN.UK.2016-3.RLTS.T9194A51140239.en \n(Downloaded on 09 January 2017)\nAKSHAY  VISHWANATH e.T9194A51140239. http://dx.doi.org/10.2305/IUCN.UK.2016-3.RLTS.T9194A51140239.en \n(Downloaded on 09 January 2017)\nAKSHAY  VISHWANATH\n23\t\ngiraffeconservation.org\nTo support giraffe conservation in Africa: \n\t\nVisit the GCF website  \n\t\nhttp://giraffeconservation.org/donate\n\t\nAdopt a Giraffe \t\n\t\nhttp://giraffeconservation.org/adopt-a-giraffe"
  ],
  "metadata": [
    {
      "article_id": "6468270047648745042",
      "chunk_id": 0,
      "title": "How AI generated code compounds technical debt",
      "topics": [
        "AI",
        "Technology"
      ],
      "source": "news",
      "url": "https://leaddev.com/technical-direction/how-ai-generated-code-accelerates-technical-debt",
      "added_at": "2025-11-09T12:01:24.411434"
    },
    {
      "article_id": "6468270047648745042",
      "chunk_id": 1,
      "title": "How AI generated code compounds technical debt",
      "topics": [
        "AI",
        "Technology"
      ],
      "source": "news",
      "url": "https://leaddev.com/technical-direction/how-ai-generated-code-accelerates-technical-debt",
      "added_at": "2025-11-09T12:01:24.820594"
    },
    {
      "article_id": "6468270047648745042",
      "chunk_id": 2,
      "title": "How AI generated code compounds technical debt",
      "topics": [
        "AI",
        "Technology"
      ],
      "source": "news",
      "url": "https://leaddev.com/technical-direction/how-ai-generated-code-accelerates-technical-debt",
      "added_at": "2025-11-09T12:01:25.126173"
    },
    {
      "article_id": "6468270047648745042",
      "chunk_id": 3,
      "title": "How AI generated code compounds technical debt",
      "topics": [
        "AI",
        "Technology"
      ],
      "source": "news",
      "url": "https://leaddev.com/technical-direction/how-ai-generated-code-accelerates-technical-debt",
      "added_at": "2025-11-09T12:01:26.150198"
    },
    {
      "article_id": "9031711621983707363",
      "chunk_id": 0,
      "title": "Monorepo vs Multi-repo vs Git submodule vs Git Subtree",
      "topics": [
        "Technology",
        "Code",
        "Software",
        "Dev"
      ],
      "source": "news",
      "url": "https://levelup.gitconnected.com/monorepo-vs-multi-repo-vs-git-submodule-vs-git-subtree-a-complete-guide-for-developers-961535aa6d4c",
      "added_at": "2025-11-09T12:03:47.053167"
    },
    {
      "article_id": "9031711621983707363",
      "chunk_id": 1,
      "title": "Monorepo vs Multi-repo vs Git submodule vs Git Subtree",
      "topics": [
        "Technology",
        "Code",
        "Software",
        "Dev"
      ],
      "source": "news",
      "url": "https://levelup.gitconnected.com/monorepo-vs-multi-repo-vs-git-submodule-vs-git-subtree-a-complete-guide-for-developers-961535aa6d4c",
      "added_at": "2025-11-09T12:03:47.361562"
    },
    {
      "article_id": "9031711621983707363",
      "chunk_id": 2,
      "title": "Monorepo vs Multi-repo vs Git submodule vs Git Subtree",
      "topics": [
        "Technology",
        "Code",
        "Software",
        "Dev"
      ],
      "source": "news",
      "url": "https://levelup.gitconnected.com/monorepo-vs-multi-repo-vs-git-submodule-vs-git-subtree-a-complete-guide-for-developers-961535aa6d4c",
      "added_at": "2025-11-09T12:03:47.564209"
    },
    {
      "article_id": "9031711621983707363",
      "chunk_id": 3,
      "title": "Monorepo vs Multi-repo vs Git submodule vs Git Subtree",
      "topics": [
        "Technology",
        "Code",
        "Software",
        "Dev"
      ],
      "source": "news",
      "url": "https://levelup.gitconnected.com/monorepo-vs-multi-repo-vs-git-submodule-vs-git-subtree-a-complete-guide-for-developers-961535aa6d4c",
      "added_at": "2025-11-09T12:03:47.872183"
    },
    {
      "article_id": "9031711621983707363",
      "chunk_id": 4,
      "title": "Monorepo vs Multi-repo vs Git submodule vs Git Subtree",
      "topics": [
        "Technology",
        "Code",
        "Software",
        "Dev"
      ],
      "source": "news",
      "url": "https://levelup.gitconnected.com/monorepo-vs-multi-repo-vs-git-submodule-vs-git-subtree-a-complete-guide-for-developers-961535aa6d4c",
      "added_at": "2025-11-09T12:03:48.180725"
    },
    {
      "article_id": "9031711621983707363",
      "chunk_id": 5,
      "title": "Monorepo vs Multi-repo vs Git submodule vs Git Subtree",
      "topics": [
        "Technology",
        "Code",
        "Software",
        "Dev"
      ],
      "source": "news",
      "url": "https://levelup.gitconnected.com/monorepo-vs-multi-repo-vs-git-submodule-vs-git-subtree-a-complete-guide-for-developers-961535aa6d4c",
      "added_at": "2025-11-09T12:03:48.486433"
    },
    {
      "article_id": "9031711621983707363",
      "chunk_id": 6,
      "title": "Monorepo vs Multi-repo vs Git submodule vs Git Subtree",
      "topics": [
        "Technology",
        "Code",
        "Software",
        "Dev"
      ],
      "source": "news",
      "url": "https://levelup.gitconnected.com/monorepo-vs-multi-repo-vs-git-submodule-vs-git-subtree-a-complete-guide-for-developers-961535aa6d4c",
      "added_at": "2025-11-09T12:03:48.794964"
    },
    {
      "article_id": "9031711621983707363",
      "chunk_id": 7,
      "title": "Monorepo vs Multi-repo vs Git submodule vs Git Subtree",
      "topics": [
        "Technology",
        "Code",
        "Software",
        "Dev"
      ],
      "source": "news",
      "url": "https://levelup.gitconnected.com/monorepo-vs-multi-repo-vs-git-submodule-vs-git-subtree-a-complete-guide-for-developers-961535aa6d4c",
      "added_at": "2025-11-09T12:03:49.101697"
    },
    {
      "article_id": "9031711621983707363",
      "chunk_id": 8,
      "title": "Monorepo vs Multi-repo vs Git submodule vs Git Subtree",
      "topics": [
        "Technology",
        "Code",
        "Software",
        "Dev"
      ],
      "source": "news",
      "url": "https://levelup.gitconnected.com/monorepo-vs-multi-repo-vs-git-submodule-vs-git-subtree-a-complete-guide-for-developers-961535aa6d4c",
      "added_at": "2025-11-09T12:03:49.408001"
    },
    {
      "article_id": "9031711621983707363",
      "chunk_id": 9,
      "title": "Monorepo vs Multi-repo vs Git submodule vs Git Subtree",
      "topics": [
        "Technology",
        "Code",
        "Software",
        "Dev"
      ],
      "source": "news",
      "url": "https://levelup.gitconnected.com/monorepo-vs-multi-repo-vs-git-submodule-vs-git-subtree-a-complete-guide-for-developers-961535aa6d4c",
      "added_at": "2025-11-09T12:03:49.715226"
    },
    {
      "article_id": "9031711621983707363",
      "chunk_id": 10,
      "title": "Monorepo vs Multi-repo vs Git submodule vs Git Subtree",
      "topics": [
        "Technology",
        "Code",
        "Software",
        "Dev"
      ],
      "source": "news",
      "url": "https://levelup.gitconnected.com/monorepo-vs-multi-repo-vs-git-submodule-vs-git-subtree-a-complete-guide-for-developers-961535aa6d4c",
      "added_at": "2025-11-09T12:03:50.637616"
    },
    {
      "article_id": "9031711621983707363",
      "chunk_id": 11,
      "title": "Monorepo vs Multi-repo vs Git submodule vs Git Subtree",
      "topics": [
        "Technology",
        "Code",
        "Software",
        "Dev"
      ],
      "source": "news",
      "url": "https://levelup.gitconnected.com/monorepo-vs-multi-repo-vs-git-submodule-vs-git-subtree-a-complete-guide-for-developers-961535aa6d4c",
      "added_at": "2025-11-09T12:03:50.945173"
    },
    {
      "article_id": "8724880553008199896",
      "chunk_id": 0,
      "title": "Visualize FastAPI endpoints with FastAPI-Voyager",
      "topics": [
        "web development",
        "FastAPI",
        "data visualization",
        "user interaction",
        "frontend"
      ],
      "source": "news",
      "url": "https://www.newsyeah.fun/voyager/",
      "added_at": "2025-11-09T15:36:29.913359"
    },
    {
      "article_id": "2394154087717237900",
      "chunk_id": 0,
      "title": "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology",
      "topics": [
        "history",
        "technology",
        "investigation",
        "gaming",
        "packaging"
      ],
      "source": "news",
      "url": "https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/",
      "added_at": "2025-11-09T15:36:32.880574"
    },
    {
      "article_id": "2394154087717237900",
      "chunk_id": 1,
      "title": "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology",
      "topics": [
        "history",
        "technology",
        "investigation",
        "gaming",
        "packaging"
      ],
      "source": "news",
      "url": "https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/",
      "added_at": "2025-11-09T15:36:33.596963"
    },
    {
      "article_id": "2394154087717237900",
      "chunk_id": 2,
      "title": "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology",
      "topics": [
        "history",
        "technology",
        "investigation",
        "gaming",
        "packaging"
      ],
      "source": "news",
      "url": "https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/",
      "added_at": "2025-11-09T15:36:33.902488"
    },
    {
      "article_id": "2394154087717237900",
      "chunk_id": 3,
      "title": "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology",
      "topics": [
        "history",
        "technology",
        "investigation",
        "gaming",
        "packaging"
      ],
      "source": "news",
      "url": "https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/",
      "added_at": "2025-11-09T15:36:34.313742"
    },
    {
      "article_id": "2394154087717237900",
      "chunk_id": 4,
      "title": "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology",
      "topics": [
        "history",
        "technology",
        "investigation",
        "gaming",
        "packaging"
      ],
      "source": "news",
      "url": "https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/",
      "added_at": "2025-11-09T15:36:34.721656"
    },
    {
      "article_id": "2394154087717237900",
      "chunk_id": 5,
      "title": "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology",
      "topics": [
        "history",
        "technology",
        "investigation",
        "gaming",
        "packaging"
      ],
      "source": "news",
      "url": "https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/",
      "added_at": "2025-11-09T15:36:35.030281"
    },
    {
      "article_id": "2394154087717237900",
      "chunk_id": 6,
      "title": "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology",
      "topics": [
        "history",
        "technology",
        "investigation",
        "gaming",
        "packaging"
      ],
      "source": "news",
      "url": "https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/",
      "added_at": "2025-11-09T15:36:35.335982"
    },
    {
      "article_id": "2394154087717237900",
      "chunk_id": 7,
      "title": "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology",
      "topics": [
        "history",
        "technology",
        "investigation",
        "gaming",
        "packaging"
      ],
      "source": "news",
      "url": "https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/",
      "added_at": "2025-11-09T15:36:35.538746"
    },
    {
      "article_id": "2394154087717237900",
      "chunk_id": 8,
      "title": "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology",
      "topics": [
        "history",
        "technology",
        "investigation",
        "gaming",
        "packaging"
      ],
      "source": "news",
      "url": "https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/",
      "added_at": "2025-11-09T15:36:36.155179"
    },
    {
      "article_id": "2394154087717237900",
      "chunk_id": 9,
      "title": "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology",
      "topics": [
        "history",
        "technology",
        "investigation",
        "gaming",
        "packaging"
      ],
      "source": "news",
      "url": "https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/",
      "added_at": "2025-11-09T15:36:36.462339"
    },
    {
      "article_id": "2394154087717237900",
      "chunk_id": 10,
      "title": "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology",
      "topics": [
        "history",
        "technology",
        "investigation",
        "gaming",
        "packaging"
      ],
      "source": "news",
      "url": "https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/",
      "added_at": "2025-11-09T15:36:36.770416"
    },
    {
      "article_id": "2394154087717237900",
      "chunk_id": 11,
      "title": "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology",
      "topics": [
        "history",
        "technology",
        "investigation",
        "gaming",
        "packaging"
      ],
      "source": "news",
      "url": "https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/",
      "added_at": "2025-11-09T15:36:37.179200"
    },
    {
      "article_id": "2394154087717237900",
      "chunk_id": 12,
      "title": "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology",
      "topics": [
        "history",
        "technology",
        "investigation",
        "gaming",
        "packaging"
      ],
      "source": "news",
      "url": "https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/",
      "added_at": "2025-11-09T15:36:37.487515"
    },
    {
      "article_id": "2394154087717237900",
      "chunk_id": 13,
      "title": "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology",
      "topics": [
        "history",
        "technology",
        "investigation",
        "gaming",
        "packaging"
      ],
      "source": "news",
      "url": "https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/",
      "added_at": "2025-11-09T15:36:37.794019"
    },
    {
      "article_id": "2394154087717237900",
      "chunk_id": 14,
      "title": "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology",
      "topics": [
        "history",
        "technology",
        "investigation",
        "gaming",
        "packaging"
      ],
      "source": "news",
      "url": "https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/",
      "added_at": "2025-11-09T15:36:38.102212"
    },
    {
      "article_id": "2394154087717237900",
      "chunk_id": 15,
      "title": "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology",
      "topics": [
        "history",
        "technology",
        "investigation",
        "gaming",
        "packaging"
      ],
      "source": "news",
      "url": "https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/",
      "added_at": "2025-11-09T15:36:38.408027"
    },
    {
      "article_id": "1869146048070042214",
      "chunk_id": 0,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "online security",
        "web activity"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:36:40.967907"
    },
    {
      "article_id": "1869146048070042214",
      "chunk_id": 1,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "online security",
        "web activity"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:36:41.276561"
    },
    {
      "article_id": "1869146048070042214",
      "chunk_id": 2,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "online security",
        "web activity"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:36:41.787231"
    },
    {
      "article_id": "1869146048070042214",
      "chunk_id": 3,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "online security",
        "web activity"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:36:42.545999"
    },
    {
      "article_id": "1869146048070042214",
      "chunk_id": 4,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "online security",
        "web activity"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:36:42.811064"
    },
    {
      "article_id": "1869146048070042214",
      "chunk_id": 5,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "online security",
        "web activity"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:36:43.118281"
    },
    {
      "article_id": "1869146048070042214",
      "chunk_id": 6,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "online security",
        "web activity"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:36:43.427143"
    },
    {
      "article_id": "1869146048070042214",
      "chunk_id": 7,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "online security",
        "web activity"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:36:43.674346"
    },
    {
      "article_id": "1869146048070042214",
      "chunk_id": 8,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "online security",
        "web activity"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:36:44.040173"
    },
    {
      "article_id": "1869146048070042214",
      "chunk_id": 9,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "online security",
        "web activity"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:36:44.347201"
    },
    {
      "article_id": "1869146048070042214",
      "chunk_id": 10,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "online security",
        "web activity"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:36:45.371162"
    },
    {
      "article_id": "1869146048070042214",
      "chunk_id": 11,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "online security",
        "web activity"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:36:45.679384"
    },
    {
      "article_id": "1869146048070042214",
      "chunk_id": 12,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "online security",
        "web activity"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:36:45.985464"
    },
    {
      "article_id": "1869146048070042214",
      "chunk_id": 13,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "online security",
        "web activity"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:36:46.395260"
    },
    {
      "article_id": "1869146048070042214",
      "chunk_id": 14,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "online security",
        "web activity"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:36:46.702274"
    },
    {
      "article_id": "1869146048070042214",
      "chunk_id": 15,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "online security",
        "web activity"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:36:47.009555"
    },
    {
      "article_id": "1869146048070042214",
      "chunk_id": 16,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "online security",
        "web activity"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:36:47.317173"
    },
    {
      "article_id": "1869146048070042214",
      "chunk_id": 17,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "online security",
        "web activity"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:36:47.621996"
    },
    {
      "article_id": "1869146048070042214",
      "chunk_id": 18,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "online security",
        "web activity"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:36:47.931456"
    },
    {
      "article_id": "1869146048070042214",
      "chunk_id": 19,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "online security",
        "web activity"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:36:48.238436"
    },
    {
      "article_id": "1869146048070042214",
      "chunk_id": 20,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "online security",
        "web activity"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:36:48.444757"
    },
    {
      "article_id": "1869146048070042214",
      "chunk_id": 21,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "online security",
        "web activity"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:36:48.694025"
    },
    {
      "article_id": "1869146048070042214",
      "chunk_id": 22,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "online security",
        "web activity"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:36:48.882331"
    },
    {
      "article_id": "1869146048070042214",
      "chunk_id": 23,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "online security",
        "web activity"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:36:49.314478"
    },
    {
      "article_id": "1869146048070042214",
      "chunk_id": 24,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "online security",
        "web activity"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:36:49.571012"
    },
    {
      "article_id": "1869146048070042214",
      "chunk_id": 25,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "online security",
        "web activity"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:36:49.980027"
    },
    {
      "article_id": "1869146048070042214",
      "chunk_id": 26,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "online security",
        "web activity"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:36:50.286282"
    },
    {
      "article_id": "8805740121820524253",
      "chunk_id": 0,
      "title": "Using bubblewrap to add sandboxing to NetBSD",
      "topics": [
        "Google Summer of Code",
        "2025",
        "Reports",
        "bubblewrap",
        "sandboxing",
        "NetBSD"
      ],
      "source": "news",
      "url": "https://blog.netbsd.org/tnf/entry/gsoc2025_bubblewrap_sandboxing",
      "added_at": "2025-11-09T15:36:53.972985"
    },
    {
      "article_id": "8805740121820524253",
      "chunk_id": 1,
      "title": "Using bubblewrap to add sandboxing to NetBSD",
      "topics": [
        "Google Summer of Code",
        "2025",
        "Reports",
        "bubblewrap",
        "sandboxing",
        "NetBSD"
      ],
      "source": "news",
      "url": "https://blog.netbsd.org/tnf/entry/gsoc2025_bubblewrap_sandboxing",
      "added_at": "2025-11-09T15:36:54.281184"
    },
    {
      "article_id": "8805740121820524253",
      "chunk_id": 2,
      "title": "Using bubblewrap to add sandboxing to NetBSD",
      "topics": [
        "Google Summer of Code",
        "2025",
        "Reports",
        "bubblewrap",
        "sandboxing",
        "NetBSD"
      ],
      "source": "news",
      "url": "https://blog.netbsd.org/tnf/entry/gsoc2025_bubblewrap_sandboxing",
      "added_at": "2025-11-09T15:36:54.587256"
    },
    {
      "article_id": "8805740121820524253",
      "chunk_id": 3,
      "title": "Using bubblewrap to add sandboxing to NetBSD",
      "topics": [
        "Google Summer of Code",
        "2025",
        "Reports",
        "bubblewrap",
        "sandboxing",
        "NetBSD"
      ],
      "source": "news",
      "url": "https://blog.netbsd.org/tnf/entry/gsoc2025_bubblewrap_sandboxing",
      "added_at": "2025-11-09T15:36:54.894903"
    },
    {
      "article_id": "8805740121820524253",
      "chunk_id": 4,
      "title": "Using bubblewrap to add sandboxing to NetBSD",
      "topics": [
        "Google Summer of Code",
        "2025",
        "Reports",
        "bubblewrap",
        "sandboxing",
        "NetBSD"
      ],
      "source": "news",
      "url": "https://blog.netbsd.org/tnf/entry/gsoc2025_bubblewrap_sandboxing",
      "added_at": "2025-11-09T15:36:55.201691"
    },
    {
      "article_id": "8805740121820524253",
      "chunk_id": 5,
      "title": "Using bubblewrap to add sandboxing to NetBSD",
      "topics": [
        "Google Summer of Code",
        "2025",
        "Reports",
        "bubblewrap",
        "sandboxing",
        "NetBSD"
      ],
      "source": "news",
      "url": "https://blog.netbsd.org/tnf/entry/gsoc2025_bubblewrap_sandboxing",
      "added_at": "2025-11-09T15:36:55.611450"
    },
    {
      "article_id": "8805740121820524253",
      "chunk_id": 6,
      "title": "Using bubblewrap to add sandboxing to NetBSD",
      "topics": [
        "Google Summer of Code",
        "2025",
        "Reports",
        "bubblewrap",
        "sandboxing",
        "NetBSD"
      ],
      "source": "news",
      "url": "https://blog.netbsd.org/tnf/entry/gsoc2025_bubblewrap_sandboxing",
      "added_at": "2025-11-09T15:36:55.918509"
    },
    {
      "article_id": "8805740121820524253",
      "chunk_id": 7,
      "title": "Using bubblewrap to add sandboxing to NetBSD",
      "topics": [
        "Google Summer of Code",
        "2025",
        "Reports",
        "bubblewrap",
        "sandboxing",
        "NetBSD"
      ],
      "source": "news",
      "url": "https://blog.netbsd.org/tnf/entry/gsoc2025_bubblewrap_sandboxing",
      "added_at": "2025-11-09T15:36:56.225614"
    },
    {
      "article_id": "8805740121820524253",
      "chunk_id": 8,
      "title": "Using bubblewrap to add sandboxing to NetBSD",
      "topics": [
        "Google Summer of Code",
        "2025",
        "Reports",
        "bubblewrap",
        "sandboxing",
        "NetBSD"
      ],
      "source": "news",
      "url": "https://blog.netbsd.org/tnf/entry/gsoc2025_bubblewrap_sandboxing",
      "added_at": "2025-11-09T15:36:56.533906"
    },
    {
      "article_id": "8805740121820524253",
      "chunk_id": 9,
      "title": "Using bubblewrap to add sandboxing to NetBSD",
      "topics": [
        "Google Summer of Code",
        "2025",
        "Reports",
        "bubblewrap",
        "sandboxing",
        "NetBSD"
      ],
      "source": "news",
      "url": "https://blog.netbsd.org/tnf/entry/gsoc2025_bubblewrap_sandboxing",
      "added_at": "2025-11-09T15:36:56.840202"
    },
    {
      "article_id": "8805740121820524253",
      "chunk_id": 10,
      "title": "Using bubblewrap to add sandboxing to NetBSD",
      "topics": [
        "Google Summer of Code",
        "2025",
        "Reports",
        "bubblewrap",
        "sandboxing",
        "NetBSD"
      ],
      "source": "news",
      "url": "https://blog.netbsd.org/tnf/entry/gsoc2025_bubblewrap_sandboxing",
      "added_at": "2025-11-09T15:36:57.147028"
    },
    {
      "article_id": "8805740121820524253",
      "chunk_id": 11,
      "title": "Using bubblewrap to add sandboxing to NetBSD",
      "topics": [
        "Google Summer of Code",
        "2025",
        "Reports",
        "bubblewrap",
        "sandboxing",
        "NetBSD"
      ],
      "source": "news",
      "url": "https://blog.netbsd.org/tnf/entry/gsoc2025_bubblewrap_sandboxing",
      "added_at": "2025-11-09T15:36:57.454537"
    },
    {
      "article_id": "8805740121820524253",
      "chunk_id": 12,
      "title": "Using bubblewrap to add sandboxing to NetBSD",
      "topics": [
        "Google Summer of Code",
        "2025",
        "Reports",
        "bubblewrap",
        "sandboxing",
        "NetBSD"
      ],
      "source": "news",
      "url": "https://blog.netbsd.org/tnf/entry/gsoc2025_bubblewrap_sandboxing",
      "added_at": "2025-11-09T15:36:57.761446"
    },
    {
      "article_id": "1826134407154398333",
      "chunk_id": 0,
      "title": "Montana Becomes First State to Enshrine 'Right to Compute' into Law",
      "topics": [
        "history",
        "Montana",
        "U.S.",
        "legal protection",
        "citizens' rights"
      ],
      "source": "news",
      "url": "https://montananewsroom.com/montana-becomes-first-state-to-enshrine-right-to-compute-into-law/",
      "added_at": "2025-11-09T15:36:59.912210"
    },
    {
      "article_id": "1826134407154398333",
      "chunk_id": 1,
      "title": "Montana Becomes First State to Enshrine 'Right to Compute' into Law",
      "topics": [
        "history",
        "Montana",
        "U.S.",
        "legal protection",
        "citizens' rights"
      ],
      "source": "news",
      "url": "https://montananewsroom.com/montana-becomes-first-state-to-enshrine-right-to-compute-into-law/",
      "added_at": "2025-11-09T15:37:00.219365"
    },
    {
      "article_id": "1826134407154398333",
      "chunk_id": 2,
      "title": "Montana Becomes First State to Enshrine 'Right to Compute' into Law",
      "topics": [
        "history",
        "Montana",
        "U.S.",
        "legal protection",
        "citizens' rights"
      ],
      "source": "news",
      "url": "https://montananewsroom.com/montana-becomes-first-state-to-enshrine-right-to-compute-into-law/",
      "added_at": "2025-11-09T15:37:00.526777"
    },
    {
      "article_id": "1826134407154398333",
      "chunk_id": 3,
      "title": "Montana Becomes First State to Enshrine 'Right to Compute' into Law",
      "topics": [
        "history",
        "Montana",
        "U.S.",
        "legal protection",
        "citizens' rights"
      ],
      "source": "news",
      "url": "https://montananewsroom.com/montana-becomes-first-state-to-enshrine-right-to-compute-into-law/",
      "added_at": "2025-11-09T15:37:00.833768"
    },
    {
      "article_id": "1826134407154398333",
      "chunk_id": 4,
      "title": "Montana Becomes First State to Enshrine 'Right to Compute' into Law",
      "topics": [
        "history",
        "Montana",
        "U.S.",
        "legal protection",
        "citizens' rights"
      ],
      "source": "news",
      "url": "https://montananewsroom.com/montana-becomes-first-state-to-enshrine-right-to-compute-into-law/",
      "added_at": "2025-11-09T15:37:01.142283"
    },
    {
      "article_id": "2132317040834157480",
      "chunk_id": 0,
      "title": "Show HN: Pipeflow-PHP \u2013 Automate anything with pipelines even non-devs can edit",
      "topics": [
        "PHP",
        "pipeline engine",
        "lightweight",
        "applications",
        "automation"
      ],
      "source": "news",
      "url": "https://github.com/marcosiino/pipeflow-php",
      "added_at": "2025-11-09T15:37:02.983926"
    },
    {
      "article_id": "2132317040834157480",
      "chunk_id": 1,
      "title": "Show HN: Pipeflow-PHP \u2013 Automate anything with pipelines even non-devs can edit",
      "topics": [
        "PHP",
        "pipeline engine",
        "lightweight",
        "applications",
        "automation"
      ],
      "source": "news",
      "url": "https://github.com/marcosiino/pipeflow-php",
      "added_at": "2025-11-09T15:37:03.292475"
    },
    {
      "article_id": "2132317040834157480",
      "chunk_id": 2,
      "title": "Show HN: Pipeflow-PHP \u2013 Automate anything with pipelines even non-devs can edit",
      "topics": [
        "PHP",
        "pipeline engine",
        "lightweight",
        "applications",
        "automation"
      ],
      "source": "news",
      "url": "https://github.com/marcosiino/pipeflow-php",
      "added_at": "2025-11-09T15:37:03.599345"
    },
    {
      "article_id": "2132317040834157480",
      "chunk_id": 3,
      "title": "Show HN: Pipeflow-PHP \u2013 Automate anything with pipelines even non-devs can edit",
      "topics": [
        "PHP",
        "pipeline engine",
        "lightweight",
        "applications",
        "automation"
      ],
      "source": "news",
      "url": "https://github.com/marcosiino/pipeflow-php",
      "added_at": "2025-11-09T15:37:03.906102"
    },
    {
      "article_id": "2132317040834157480",
      "chunk_id": 4,
      "title": "Show HN: Pipeflow-PHP \u2013 Automate anything with pipelines even non-devs can edit",
      "topics": [
        "PHP",
        "pipeline engine",
        "lightweight",
        "applications",
        "automation"
      ],
      "source": "news",
      "url": "https://github.com/marcosiino/pipeflow-php",
      "added_at": "2025-11-09T15:37:04.213934"
    },
    {
      "article_id": "2132317040834157480",
      "chunk_id": 5,
      "title": "Show HN: Pipeflow-PHP \u2013 Automate anything with pipelines even non-devs can edit",
      "topics": [
        "PHP",
        "pipeline engine",
        "lightweight",
        "applications",
        "automation"
      ],
      "source": "news",
      "url": "https://github.com/marcosiino/pipeflow-php",
      "added_at": "2025-11-09T15:37:04.520347"
    },
    {
      "article_id": "2132317040834157480",
      "chunk_id": 6,
      "title": "Show HN: Pipeflow-PHP \u2013 Automate anything with pipelines even non-devs can edit",
      "topics": [
        "PHP",
        "pipeline engine",
        "lightweight",
        "applications",
        "automation"
      ],
      "source": "news",
      "url": "https://github.com/marcosiino/pipeflow-php",
      "added_at": "2025-11-09T15:37:04.828361"
    },
    {
      "article_id": "2132317040834157480",
      "chunk_id": 7,
      "title": "Show HN: Pipeflow-PHP \u2013 Automate anything with pipelines even non-devs can edit",
      "topics": [
        "PHP",
        "pipeline engine",
        "lightweight",
        "applications",
        "automation"
      ],
      "source": "news",
      "url": "https://github.com/marcosiino/pipeflow-php",
      "added_at": "2025-11-09T15:37:05.441914"
    },
    {
      "article_id": "2132317040834157480",
      "chunk_id": 8,
      "title": "Show HN: Pipeflow-PHP \u2013 Automate anything with pipelines even non-devs can edit",
      "topics": [
        "PHP",
        "pipeline engine",
        "lightweight",
        "applications",
        "automation"
      ],
      "source": "news",
      "url": "https://github.com/marcosiino/pipeflow-php",
      "added_at": "2025-11-09T15:37:05.682919"
    },
    {
      "article_id": "2132317040834157480",
      "chunk_id": 9,
      "title": "Show HN: Pipeflow-PHP \u2013 Automate anything with pipelines even non-devs can edit",
      "topics": [
        "PHP",
        "pipeline engine",
        "lightweight",
        "applications",
        "automation"
      ],
      "source": "news",
      "url": "https://github.com/marcosiino/pipeflow-php",
      "added_at": "2025-11-09T15:37:05.954037"
    },
    {
      "article_id": "2132317040834157480",
      "chunk_id": 10,
      "title": "Show HN: Pipeflow-PHP \u2013 Automate anything with pipelines even non-devs can edit",
      "topics": [
        "PHP",
        "pipeline engine",
        "lightweight",
        "applications",
        "automation"
      ],
      "source": "news",
      "url": "https://github.com/marcosiino/pipeflow-php",
      "added_at": "2025-11-09T15:37:06.260946"
    },
    {
      "article_id": "2132317040834157480",
      "chunk_id": 11,
      "title": "Show HN: Pipeflow-PHP \u2013 Automate anything with pipelines even non-devs can edit",
      "topics": [
        "PHP",
        "pipeline engine",
        "lightweight",
        "applications",
        "automation"
      ],
      "source": "news",
      "url": "https://github.com/marcosiino/pipeflow-php",
      "added_at": "2025-11-09T15:37:06.569154"
    },
    {
      "article_id": "2132317040834157480",
      "chunk_id": 12,
      "title": "Show HN: Pipeflow-PHP \u2013 Automate anything with pipelines even non-devs can edit",
      "topics": [
        "PHP",
        "pipeline engine",
        "lightweight",
        "applications",
        "automation"
      ],
      "source": "news",
      "url": "https://github.com/marcosiino/pipeflow-php",
      "added_at": "2025-11-09T15:37:06.875220"
    },
    {
      "article_id": "1886671023262003124",
      "chunk_id": 0,
      "title": "I Am Mark Zuckerberg",
      "topics": [
        "website",
        "Mark Zuckerberg",
        "community service",
        "Hoosiers"
      ],
      "source": "news",
      "url": "https://iammarkzuckerberg.com/",
      "added_at": "2025-11-09T15:37:09.128063"
    },
    {
      "article_id": "1886671023262003124",
      "chunk_id": 1,
      "title": "I Am Mark Zuckerberg",
      "topics": [
        "website",
        "Mark Zuckerberg",
        "community service",
        "Hoosiers"
      ],
      "source": "news",
      "url": "https://iammarkzuckerberg.com/",
      "added_at": "2025-11-09T15:37:09.437193"
    },
    {
      "article_id": "1886671023262003124",
      "chunk_id": 2,
      "title": "I Am Mark Zuckerberg",
      "topics": [
        "website",
        "Mark Zuckerberg",
        "community service",
        "Hoosiers"
      ],
      "source": "news",
      "url": "https://iammarkzuckerberg.com/",
      "added_at": "2025-11-09T15:37:09.643676"
    },
    {
      "article_id": "380610091005562212",
      "chunk_id": 0,
      "title": "Ironclad \u2013 formally verified, real-time capable, Unix-like OS kernel",
      "topics": [
        "formally verified",
        "real-time capable",
        "UNIX-like",
        "operating system kernel"
      ],
      "source": "news",
      "url": "https://ironclad-os.org/",
      "added_at": "2025-11-09T15:37:10.972442"
    },
    {
      "article_id": "380610091005562212",
      "chunk_id": 1,
      "title": "Ironclad \u2013 formally verified, real-time capable, Unix-like OS kernel",
      "topics": [
        "formally verified",
        "real-time capable",
        "UNIX-like",
        "operating system kernel"
      ],
      "source": "news",
      "url": "https://ironclad-os.org/",
      "added_at": "2025-11-09T15:37:11.278484"
    },
    {
      "article_id": "380610091005562212",
      "chunk_id": 2,
      "title": "Ironclad \u2013 formally verified, real-time capable, Unix-like OS kernel",
      "topics": [
        "formally verified",
        "real-time capable",
        "UNIX-like",
        "operating system kernel"
      ],
      "source": "news",
      "url": "https://ironclad-os.org/",
      "added_at": "2025-11-09T15:37:11.585637"
    },
    {
      "article_id": "5192065637015062036",
      "chunk_id": 0,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "static site generator",
        "Zensical",
        "Material for MkDocs"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:37:12.610750"
    },
    {
      "article_id": "5192065637015062036",
      "chunk_id": 1,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "static site generator",
        "Zensical",
        "Material for MkDocs"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:37:12.917657"
    },
    {
      "article_id": "5192065637015062036",
      "chunk_id": 2,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "static site generator",
        "Zensical",
        "Material for MkDocs"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:37:13.327588"
    },
    {
      "article_id": "5192065637015062036",
      "chunk_id": 3,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "static site generator",
        "Zensical",
        "Material for MkDocs"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:37:13.633798"
    },
    {
      "article_id": "5192065637015062036",
      "chunk_id": 4,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "static site generator",
        "Zensical",
        "Material for MkDocs"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:37:14.045171"
    },
    {
      "article_id": "5192065637015062036",
      "chunk_id": 5,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "static site generator",
        "Zensical",
        "Material for MkDocs"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:37:14.350797"
    },
    {
      "article_id": "5192065637015062036",
      "chunk_id": 6,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "static site generator",
        "Zensical",
        "Material for MkDocs"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:37:14.658618"
    },
    {
      "article_id": "5192065637015062036",
      "chunk_id": 7,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "static site generator",
        "Zensical",
        "Material for MkDocs"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:37:15.169760"
    },
    {
      "article_id": "5192065637015062036",
      "chunk_id": 8,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "static site generator",
        "Zensical",
        "Material for MkDocs"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:37:15.477734"
    },
    {
      "article_id": "5192065637015062036",
      "chunk_id": 9,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "static site generator",
        "Zensical",
        "Material for MkDocs"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:37:15.784142"
    },
    {
      "article_id": "5192065637015062036",
      "chunk_id": 10,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "static site generator",
        "Zensical",
        "Material for MkDocs"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:37:16.092100"
    },
    {
      "article_id": "5192065637015062036",
      "chunk_id": 11,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "static site generator",
        "Zensical",
        "Material for MkDocs"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:37:16.400023"
    },
    {
      "article_id": "5192065637015062036",
      "chunk_id": 12,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "static site generator",
        "Zensical",
        "Material for MkDocs"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:37:16.705915"
    },
    {
      "article_id": "5192065637015062036",
      "chunk_id": 13,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "static site generator",
        "Zensical",
        "Material for MkDocs"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:37:17.014011"
    },
    {
      "article_id": "5192065637015062036",
      "chunk_id": 14,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "static site generator",
        "Zensical",
        "Material for MkDocs"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:37:17.320326"
    },
    {
      "article_id": "5192065637015062036",
      "chunk_id": 15,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "static site generator",
        "Zensical",
        "Material for MkDocs"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:37:17.627273"
    },
    {
      "article_id": "5192065637015062036",
      "chunk_id": 16,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "static site generator",
        "Zensical",
        "Material for MkDocs"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:37:17.935904"
    },
    {
      "article_id": "5192065637015062036",
      "chunk_id": 17,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "static site generator",
        "Zensical",
        "Material for MkDocs"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:37:18.856200"
    },
    {
      "article_id": "670343975519548186",
      "chunk_id": 0,
      "title": "The Manuscripts of Edsger W. Dijkstra",
      "topics": [
        "indexing",
        "numerical",
        "EWD",
        "BibT"
      ],
      "source": "news",
      "url": "https://www.cs.utexas.edu/~EWD/",
      "added_at": "2025-11-09T15:48:07.258153"
    },
    {
      "article_id": "670343975519548186",
      "chunk_id": 1,
      "title": "The Manuscripts of Edsger W. Dijkstra",
      "topics": [
        "indexing",
        "numerical",
        "EWD",
        "BibT"
      ],
      "source": "news",
      "url": "https://www.cs.utexas.edu/~EWD/",
      "added_at": "2025-11-09T15:48:07.562835"
    },
    {
      "article_id": "670343975519548186",
      "chunk_id": 2,
      "title": "The Manuscripts of Edsger W. Dijkstra",
      "topics": [
        "indexing",
        "numerical",
        "EWD",
        "BibT"
      ],
      "source": "news",
      "url": "https://www.cs.utexas.edu/~EWD/",
      "added_at": "2025-11-09T15:48:07.870367"
    },
    {
      "article_id": "670343975519548186",
      "chunk_id": 3,
      "title": "The Manuscripts of Edsger W. Dijkstra",
      "topics": [
        "indexing",
        "numerical",
        "EWD",
        "BibT"
      ],
      "source": "news",
      "url": "https://www.cs.utexas.edu/~EWD/",
      "added_at": "2025-11-09T15:48:08.186580"
    },
    {
      "article_id": "670343975519548186",
      "chunk_id": 4,
      "title": "The Manuscripts of Edsger W. Dijkstra",
      "topics": [
        "indexing",
        "numerical",
        "EWD",
        "BibT"
      ],
      "source": "news",
      "url": "https://www.cs.utexas.edu/~EWD/",
      "added_at": "2025-11-09T15:48:08.586165"
    },
    {
      "article_id": "670343975519548186",
      "chunk_id": 5,
      "title": "The Manuscripts of Edsger W. Dijkstra",
      "topics": [
        "indexing",
        "numerical",
        "EWD",
        "BibT"
      ],
      "source": "news",
      "url": "https://www.cs.utexas.edu/~EWD/",
      "added_at": "2025-11-09T15:48:08.786326"
    },
    {
      "article_id": "670343975519548186",
      "chunk_id": 6,
      "title": "The Manuscripts of Edsger W. Dijkstra",
      "topics": [
        "indexing",
        "numerical",
        "EWD",
        "BibT"
      ],
      "source": "news",
      "url": "https://www.cs.utexas.edu/~EWD/",
      "added_at": "2025-11-09T15:48:09.098650"
    },
    {
      "article_id": "670343975519548186",
      "chunk_id": 7,
      "title": "The Manuscripts of Edsger W. Dijkstra",
      "topics": [
        "indexing",
        "numerical",
        "EWD",
        "BibT"
      ],
      "source": "news",
      "url": "https://www.cs.utexas.edu/~EWD/",
      "added_at": "2025-11-09T15:48:09.609306"
    },
    {
      "article_id": "670343975519548186",
      "chunk_id": 8,
      "title": "The Manuscripts of Edsger W. Dijkstra",
      "topics": [
        "indexing",
        "numerical",
        "EWD",
        "BibT"
      ],
      "source": "news",
      "url": "https://www.cs.utexas.edu/~EWD/",
      "added_at": "2025-11-09T15:48:10.027339"
    },
    {
      "article_id": "670343975519548186",
      "chunk_id": 9,
      "title": "The Manuscripts of Edsger W. Dijkstra",
      "topics": [
        "indexing",
        "numerical",
        "EWD",
        "BibT"
      ],
      "source": "news",
      "url": "https://www.cs.utexas.edu/~EWD/",
      "added_at": "2025-11-09T15:48:10.330610"
    },
    {
      "article_id": "670343975519548186",
      "chunk_id": 10,
      "title": "The Manuscripts of Edsger W. Dijkstra",
      "topics": [
        "indexing",
        "numerical",
        "EWD",
        "BibT"
      ],
      "source": "news",
      "url": "https://www.cs.utexas.edu/~EWD/",
      "added_at": "2025-11-09T15:48:10.633167"
    },
    {
      "article_id": "670343975519548186",
      "chunk_id": 11,
      "title": "The Manuscripts of Edsger W. Dijkstra",
      "topics": [
        "indexing",
        "numerical",
        "EWD",
        "BibT"
      ],
      "source": "news",
      "url": "https://www.cs.utexas.edu/~EWD/",
      "added_at": "2025-11-09T15:48:10.940773"
    },
    {
      "article_id": "670343975519548186",
      "chunk_id": 12,
      "title": "The Manuscripts of Edsger W. Dijkstra",
      "topics": [
        "indexing",
        "numerical",
        "EWD",
        "BibT"
      ],
      "source": "news",
      "url": "https://www.cs.utexas.edu/~EWD/",
      "added_at": "2025-11-09T15:48:11.247717"
    },
    {
      "article_id": "5336453069579567915",
      "chunk_id": 0,
      "title": "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology",
      "topics": [
        "technology",
        "detective work",
        "internet history"
      ],
      "source": "news",
      "url": "https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/",
      "added_at": "2025-11-09T15:48:12.681080"
    },
    {
      "article_id": "5336453069579567915",
      "chunk_id": 1,
      "title": "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology",
      "topics": [
        "technology",
        "detective work",
        "internet history"
      ],
      "source": "news",
      "url": "https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/",
      "added_at": "2025-11-09T15:48:13.092241"
    },
    {
      "article_id": "5336453069579567915",
      "chunk_id": 2,
      "title": "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology",
      "topics": [
        "technology",
        "detective work",
        "internet history"
      ],
      "source": "news",
      "url": "https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/",
      "added_at": "2025-11-09T15:48:13.398122"
    },
    {
      "article_id": "5336453069579567915",
      "chunk_id": 3,
      "title": "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology",
      "topics": [
        "technology",
        "detective work",
        "internet history"
      ],
      "source": "news",
      "url": "https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/",
      "added_at": "2025-11-09T15:48:13.706334"
    },
    {
      "article_id": "5336453069579567915",
      "chunk_id": 4,
      "title": "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology",
      "topics": [
        "technology",
        "detective work",
        "internet history"
      ],
      "source": "news",
      "url": "https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/",
      "added_at": "2025-11-09T15:48:14.012671"
    },
    {
      "article_id": "5336453069579567915",
      "chunk_id": 5,
      "title": "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology",
      "topics": [
        "technology",
        "detective work",
        "internet history"
      ],
      "source": "news",
      "url": "https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/",
      "added_at": "2025-11-09T15:48:14.319700"
    },
    {
      "article_id": "5336453069579567915",
      "chunk_id": 6,
      "title": "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology",
      "topics": [
        "technology",
        "detective work",
        "internet history"
      ],
      "source": "news",
      "url": "https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/",
      "added_at": "2025-11-09T15:48:14.627981"
    },
    {
      "article_id": "5336453069579567915",
      "chunk_id": 7,
      "title": "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology",
      "topics": [
        "technology",
        "detective work",
        "internet history"
      ],
      "source": "news",
      "url": "https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/",
      "added_at": "2025-11-09T15:48:14.933997"
    },
    {
      "article_id": "5336453069579567915",
      "chunk_id": 8,
      "title": "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology",
      "topics": [
        "technology",
        "detective work",
        "internet history"
      ],
      "source": "news",
      "url": "https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/",
      "added_at": "2025-11-09T15:48:15.241201"
    },
    {
      "article_id": "5336453069579567915",
      "chunk_id": 9,
      "title": "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology",
      "topics": [
        "technology",
        "detective work",
        "internet history"
      ],
      "source": "news",
      "url": "https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/",
      "added_at": "2025-11-09T15:48:15.548837"
    },
    {
      "article_id": "5336453069579567915",
      "chunk_id": 10,
      "title": "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology",
      "topics": [
        "technology",
        "detective work",
        "internet history"
      ],
      "source": "news",
      "url": "https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/",
      "added_at": "2025-11-09T15:48:15.855972"
    },
    {
      "article_id": "5336453069579567915",
      "chunk_id": 11,
      "title": "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology",
      "topics": [
        "technology",
        "detective work",
        "internet history"
      ],
      "source": "news",
      "url": "https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/",
      "added_at": "2025-11-09T15:48:16.777641"
    },
    {
      "article_id": "5336453069579567915",
      "chunk_id": 12,
      "title": "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology",
      "topics": [
        "technology",
        "detective work",
        "internet history"
      ],
      "source": "news",
      "url": "https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/",
      "added_at": "2025-11-09T15:48:17.086279"
    },
    {
      "article_id": "5336453069579567915",
      "chunk_id": 13,
      "title": "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology",
      "topics": [
        "technology",
        "detective work",
        "internet history"
      ],
      "source": "news",
      "url": "https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/",
      "added_at": "2025-11-09T15:48:17.285690"
    },
    {
      "article_id": "5336453069579567915",
      "chunk_id": 14,
      "title": "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology",
      "topics": [
        "technology",
        "detective work",
        "internet history"
      ],
      "source": "news",
      "url": "https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/",
      "added_at": "2025-11-09T15:48:17.599754"
    },
    {
      "article_id": "5336453069579567915",
      "chunk_id": 15,
      "title": "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology",
      "topics": [
        "technology",
        "detective work",
        "internet history"
      ],
      "source": "news",
      "url": "https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/",
      "added_at": "2025-11-09T15:48:17.905143"
    },
    {
      "article_id": "7052011817839275389",
      "chunk_id": 0,
      "title": "Visualize FastAPI endpoints with FastAPI-Voyager",
      "topics": [
        "web development",
        "API",
        "data visualization",
        "interactive features"
      ],
      "source": "news",
      "url": "https://www.newsyeah.fun/voyager/",
      "added_at": "2025-11-09T15:48:20.874686"
    },
    {
      "article_id": "6984213789381143306",
      "chunk_id": 0,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "web activity",
        "control verification"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:48:23.023992"
    },
    {
      "article_id": "6984213789381143306",
      "chunk_id": 1,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "web activity",
        "control verification"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:48:23.332057"
    },
    {
      "article_id": "6984213789381143306",
      "chunk_id": 2,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "web activity",
        "control verification"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:48:23.945685"
    },
    {
      "article_id": "6984213789381143306",
      "chunk_id": 3,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "web activity",
        "control verification"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:48:24.252505"
    },
    {
      "article_id": "6984213789381143306",
      "chunk_id": 4,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "web activity",
        "control verification"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:48:24.662950"
    },
    {
      "article_id": "6984213789381143306",
      "chunk_id": 5,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "web activity",
        "control verification"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:48:25.071842"
    },
    {
      "article_id": "6984213789381143306",
      "chunk_id": 6,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "web activity",
        "control verification"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:48:25.583717"
    },
    {
      "article_id": "6984213789381143306",
      "chunk_id": 7,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "web activity",
        "control verification"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:48:25.890629"
    },
    {
      "article_id": "6984213789381143306",
      "chunk_id": 8,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "web activity",
        "control verification"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:48:26.301976"
    },
    {
      "article_id": "6984213789381143306",
      "chunk_id": 9,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "web activity",
        "control verification"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:48:26.710162"
    },
    {
      "article_id": "6984213789381143306",
      "chunk_id": 10,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "web activity",
        "control verification"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:48:27.119980"
    },
    {
      "article_id": "6984213789381143306",
      "chunk_id": 11,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "web activity",
        "control verification"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:48:27.427625"
    },
    {
      "article_id": "6984213789381143306",
      "chunk_id": 12,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "web activity",
        "control verification"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:48:27.734191"
    },
    {
      "article_id": "6984213789381143306",
      "chunk_id": 13,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "web activity",
        "control verification"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:48:28.041748"
    },
    {
      "article_id": "6984213789381143306",
      "chunk_id": 14,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "web activity",
        "control verification"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:48:28.348561"
    },
    {
      "article_id": "6984213789381143306",
      "chunk_id": 15,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "web activity",
        "control verification"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:48:28.656667"
    },
    {
      "article_id": "6984213789381143306",
      "chunk_id": 16,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "web activity",
        "control verification"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:48:29.168115"
    },
    {
      "article_id": "6984213789381143306",
      "chunk_id": 17,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "web activity",
        "control verification"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:48:29.577320"
    },
    {
      "article_id": "6984213789381143306",
      "chunk_id": 18,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "web activity",
        "control verification"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:48:29.884499"
    },
    {
      "article_id": "6984213789381143306",
      "chunk_id": 19,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "web activity",
        "control verification"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:48:30.192914"
    },
    {
      "article_id": "6984213789381143306",
      "chunk_id": 20,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "web activity",
        "control verification"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:48:30.498985"
    },
    {
      "article_id": "6984213789381143306",
      "chunk_id": 21,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "web activity",
        "control verification"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:48:30.807097"
    },
    {
      "article_id": "6984213789381143306",
      "chunk_id": 22,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "web activity",
        "control verification"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:48:31.215740"
    },
    {
      "article_id": "6984213789381143306",
      "chunk_id": 23,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "web activity",
        "control verification"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:48:31.523054"
    },
    {
      "article_id": "6984213789381143306",
      "chunk_id": 24,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "web activity",
        "control verification"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:48:31.830493"
    },
    {
      "article_id": "6984213789381143306",
      "chunk_id": 25,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "web activity",
        "control verification"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:48:32.137530"
    },
    {
      "article_id": "6984213789381143306",
      "chunk_id": 26,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "web activity",
        "control verification"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:48:32.451952"
    },
    {
      "article_id": "3222392749056923458",
      "chunk_id": 0,
      "title": "Using bubblewrap to add sandboxing to NetBSD",
      "topics": [
        "software development",
        "Google Summer of Code",
        "NetBSD",
        "sandboxing",
        "bubblewrap"
      ],
      "source": "news",
      "url": "https://blog.netbsd.org/tnf/entry/gsoc2025_bubblewrap_sandboxing",
      "added_at": "2025-11-09T15:48:34.463651"
    },
    {
      "article_id": "3222392749056923458",
      "chunk_id": 1,
      "title": "Using bubblewrap to add sandboxing to NetBSD",
      "topics": [
        "software development",
        "Google Summer of Code",
        "NetBSD",
        "sandboxing",
        "bubblewrap"
      ],
      "source": "news",
      "url": "https://blog.netbsd.org/tnf/entry/gsoc2025_bubblewrap_sandboxing",
      "added_at": "2025-11-09T15:48:34.676493"
    },
    {
      "article_id": "3222392749056923458",
      "chunk_id": 2,
      "title": "Using bubblewrap to add sandboxing to NetBSD",
      "topics": [
        "software development",
        "Google Summer of Code",
        "NetBSD",
        "sandboxing",
        "bubblewrap"
      ],
      "source": "news",
      "url": "https://blog.netbsd.org/tnf/entry/gsoc2025_bubblewrap_sandboxing",
      "added_at": "2025-11-09T15:48:34.900240"
    },
    {
      "article_id": "3222392749056923458",
      "chunk_id": 3,
      "title": "Using bubblewrap to add sandboxing to NetBSD",
      "topics": [
        "software development",
        "Google Summer of Code",
        "NetBSD",
        "sandboxing",
        "bubblewrap"
      ],
      "source": "news",
      "url": "https://blog.netbsd.org/tnf/entry/gsoc2025_bubblewrap_sandboxing",
      "added_at": "2025-11-09T15:48:35.157095"
    },
    {
      "article_id": "3222392749056923458",
      "chunk_id": 4,
      "title": "Using bubblewrap to add sandboxing to NetBSD",
      "topics": [
        "software development",
        "Google Summer of Code",
        "NetBSD",
        "sandboxing",
        "bubblewrap"
      ],
      "source": "news",
      "url": "https://blog.netbsd.org/tnf/entry/gsoc2025_bubblewrap_sandboxing",
      "added_at": "2025-11-09T15:48:35.618734"
    },
    {
      "article_id": "3222392749056923458",
      "chunk_id": 5,
      "title": "Using bubblewrap to add sandboxing to NetBSD",
      "topics": [
        "software development",
        "Google Summer of Code",
        "NetBSD",
        "sandboxing",
        "bubblewrap"
      ],
      "source": "news",
      "url": "https://blog.netbsd.org/tnf/entry/gsoc2025_bubblewrap_sandboxing",
      "added_at": "2025-11-09T15:48:35.926184"
    },
    {
      "article_id": "3222392749056923458",
      "chunk_id": 6,
      "title": "Using bubblewrap to add sandboxing to NetBSD",
      "topics": [
        "software development",
        "Google Summer of Code",
        "NetBSD",
        "sandboxing",
        "bubblewrap"
      ],
      "source": "news",
      "url": "https://blog.netbsd.org/tnf/entry/gsoc2025_bubblewrap_sandboxing",
      "added_at": "2025-11-09T15:48:36.335494"
    },
    {
      "article_id": "3222392749056923458",
      "chunk_id": 7,
      "title": "Using bubblewrap to add sandboxing to NetBSD",
      "topics": [
        "software development",
        "Google Summer of Code",
        "NetBSD",
        "sandboxing",
        "bubblewrap"
      ],
      "source": "news",
      "url": "https://blog.netbsd.org/tnf/entry/gsoc2025_bubblewrap_sandboxing",
      "added_at": "2025-11-09T15:48:36.643173"
    },
    {
      "article_id": "3222392749056923458",
      "chunk_id": 8,
      "title": "Using bubblewrap to add sandboxing to NetBSD",
      "topics": [
        "software development",
        "Google Summer of Code",
        "NetBSD",
        "sandboxing",
        "bubblewrap"
      ],
      "source": "news",
      "url": "https://blog.netbsd.org/tnf/entry/gsoc2025_bubblewrap_sandboxing",
      "added_at": "2025-11-09T15:48:36.951526"
    },
    {
      "article_id": "3222392749056923458",
      "chunk_id": 9,
      "title": "Using bubblewrap to add sandboxing to NetBSD",
      "topics": [
        "software development",
        "Google Summer of Code",
        "NetBSD",
        "sandboxing",
        "bubblewrap"
      ],
      "source": "news",
      "url": "https://blog.netbsd.org/tnf/entry/gsoc2025_bubblewrap_sandboxing",
      "added_at": "2025-11-09T15:48:37.564476"
    },
    {
      "article_id": "3222392749056923458",
      "chunk_id": 10,
      "title": "Using bubblewrap to add sandboxing to NetBSD",
      "topics": [
        "software development",
        "Google Summer of Code",
        "NetBSD",
        "sandboxing",
        "bubblewrap"
      ],
      "source": "news",
      "url": "https://blog.netbsd.org/tnf/entry/gsoc2025_bubblewrap_sandboxing",
      "added_at": "2025-11-09T15:48:37.808634"
    },
    {
      "article_id": "3222392749056923458",
      "chunk_id": 11,
      "title": "Using bubblewrap to add sandboxing to NetBSD",
      "topics": [
        "software development",
        "Google Summer of Code",
        "NetBSD",
        "sandboxing",
        "bubblewrap"
      ],
      "source": "news",
      "url": "https://blog.netbsd.org/tnf/entry/gsoc2025_bubblewrap_sandboxing",
      "added_at": "2025-11-09T15:48:38.178692"
    },
    {
      "article_id": "3222392749056923458",
      "chunk_id": 12,
      "title": "Using bubblewrap to add sandboxing to NetBSD",
      "topics": [
        "software development",
        "Google Summer of Code",
        "NetBSD",
        "sandboxing",
        "bubblewrap"
      ],
      "source": "news",
      "url": "https://blog.netbsd.org/tnf/entry/gsoc2025_bubblewrap_sandboxing",
      "added_at": "2025-11-09T15:48:38.486036"
    },
    {
      "article_id": "2738018305339901175",
      "chunk_id": 0,
      "title": "Montana Becomes First State to Enshrine 'Right to Compute' into Law",
      "topics": [
        "history",
        "Montana",
        "state law",
        "citizens' rights",
        "legal protection"
      ],
      "source": "news",
      "url": "https://montananewsroom.com/montana-becomes-first-state-to-enshrine-right-to-compute-into-law/",
      "added_at": "2025-11-09T15:48:41.149740"
    },
    {
      "article_id": "2738018305339901175",
      "chunk_id": 1,
      "title": "Montana Becomes First State to Enshrine 'Right to Compute' into Law",
      "topics": [
        "history",
        "Montana",
        "state law",
        "citizens' rights",
        "legal protection"
      ],
      "source": "news",
      "url": "https://montananewsroom.com/montana-becomes-first-state-to-enshrine-right-to-compute-into-law/",
      "added_at": "2025-11-09T15:48:41.459665"
    },
    {
      "article_id": "2738018305339901175",
      "chunk_id": 2,
      "title": "Montana Becomes First State to Enshrine 'Right to Compute' into Law",
      "topics": [
        "history",
        "Montana",
        "state law",
        "citizens' rights",
        "legal protection"
      ],
      "source": "news",
      "url": "https://montananewsroom.com/montana-becomes-first-state-to-enshrine-right-to-compute-into-law/",
      "added_at": "2025-11-09T15:48:41.762892"
    },
    {
      "article_id": "2738018305339901175",
      "chunk_id": 3,
      "title": "Montana Becomes First State to Enshrine 'Right to Compute' into Law",
      "topics": [
        "history",
        "Montana",
        "state law",
        "citizens' rights",
        "legal protection"
      ],
      "source": "news",
      "url": "https://montananewsroom.com/montana-becomes-first-state-to-enshrine-right-to-compute-into-law/",
      "added_at": "2025-11-09T15:48:42.048367"
    },
    {
      "article_id": "2738018305339901175",
      "chunk_id": 4,
      "title": "Montana Becomes First State to Enshrine 'Right to Compute' into Law",
      "topics": [
        "history",
        "Montana",
        "state law",
        "citizens' rights",
        "legal protection"
      ],
      "source": "news",
      "url": "https://montananewsroom.com/montana-becomes-first-state-to-enshrine-right-to-compute-into-law/",
      "added_at": "2025-11-09T15:48:42.274768"
    },
    {
      "article_id": "5774591527350371752",
      "chunk_id": 0,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "software development",
        "static site generator",
        "Material for MkDocs"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:48:43.298818"
    },
    {
      "article_id": "5774591527350371752",
      "chunk_id": 1,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "software development",
        "static site generator",
        "Material for MkDocs"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:48:43.504895"
    },
    {
      "article_id": "5774591527350371752",
      "chunk_id": 2,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "software development",
        "static site generator",
        "Material for MkDocs"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:48:43.810809"
    },
    {
      "article_id": "5774591527350371752",
      "chunk_id": 3,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "software development",
        "static site generator",
        "Material for MkDocs"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:48:44.118177"
    },
    {
      "article_id": "5774591527350371752",
      "chunk_id": 4,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "software development",
        "static site generator",
        "Material for MkDocs"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:48:44.447645"
    },
    {
      "article_id": "5774591527350371752",
      "chunk_id": 5,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "software development",
        "static site generator",
        "Material for MkDocs"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:48:44.732603"
    },
    {
      "article_id": "5774591527350371752",
      "chunk_id": 6,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "software development",
        "static site generator",
        "Material for MkDocs"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:48:45.039473"
    },
    {
      "article_id": "5774591527350371752",
      "chunk_id": 7,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "software development",
        "static site generator",
        "Material for MkDocs"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:48:45.346891"
    },
    {
      "article_id": "5774591527350371752",
      "chunk_id": 8,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "software development",
        "static site generator",
        "Material for MkDocs"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:48:45.654470"
    },
    {
      "article_id": "5774591527350371752",
      "chunk_id": 9,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "software development",
        "static site generator",
        "Material for MkDocs"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:48:45.962877"
    },
    {
      "article_id": "5774591527350371752",
      "chunk_id": 10,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "software development",
        "static site generator",
        "Material for MkDocs"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:48:46.268964"
    },
    {
      "article_id": "5774591527350371752",
      "chunk_id": 11,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "software development",
        "static site generator",
        "Material for MkDocs"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:48:46.575469"
    },
    {
      "article_id": "5774591527350371752",
      "chunk_id": 12,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "software development",
        "static site generator",
        "Material for MkDocs"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:48:46.883093"
    },
    {
      "article_id": "5774591527350371752",
      "chunk_id": 13,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "software development",
        "static site generator",
        "Material for MkDocs"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:48:47.190933"
    },
    {
      "article_id": "5774591527350371752",
      "chunk_id": 14,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "software development",
        "static site generator",
        "Material for MkDocs"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:48:47.599745"
    },
    {
      "article_id": "5774591527350371752",
      "chunk_id": 15,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "software development",
        "static site generator",
        "Material for MkDocs"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:48:47.908011"
    },
    {
      "article_id": "5774591527350371752",
      "chunk_id": 16,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "software development",
        "static site generator",
        "Material for MkDocs"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:48:48.214288"
    },
    {
      "article_id": "5774591527350371752",
      "chunk_id": 17,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "software development",
        "static site generator",
        "Material for MkDocs"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:48:48.521698"
    },
    {
      "article_id": "7664770114481337322",
      "chunk_id": 0,
      "title": "I Am Mark Zuckerberg",
      "topics": [
        "website",
        "Mark Zuckerberg",
        "Hoosiers",
        "assistance"
      ],
      "source": "news",
      "url": "https://iammarkzuckerberg.com/",
      "added_at": "2025-11-09T15:48:50.774302"
    },
    {
      "article_id": "7664770114481337322",
      "chunk_id": 1,
      "title": "I Am Mark Zuckerberg",
      "topics": [
        "website",
        "Mark Zuckerberg",
        "Hoosiers",
        "assistance"
      ],
      "source": "news",
      "url": "https://iammarkzuckerberg.com/",
      "added_at": "2025-11-09T15:48:51.081277"
    },
    {
      "article_id": "7664770114481337322",
      "chunk_id": 2,
      "title": "I Am Mark Zuckerberg",
      "topics": [
        "website",
        "Mark Zuckerberg",
        "Hoosiers",
        "assistance"
      ],
      "source": "news",
      "url": "https://iammarkzuckerberg.com/",
      "added_at": "2025-11-09T15:48:51.388601"
    },
    {
      "article_id": "6006956938719801033",
      "chunk_id": 0,
      "title": "Ironclad \u2013 formally verified, real-time capable, Unix-like OS kernel",
      "topics": [
        "formally verified",
        "real-time capable",
        "operating system",
        "kernel",
        "UNIX-like"
      ],
      "source": "news",
      "url": "https://ironclad-os.org/",
      "added_at": "2025-11-09T15:48:53.027826"
    },
    {
      "article_id": "6006956938719801033",
      "chunk_id": 1,
      "title": "Ironclad \u2013 formally verified, real-time capable, Unix-like OS kernel",
      "topics": [
        "formally verified",
        "real-time capable",
        "operating system",
        "kernel",
        "UNIX-like"
      ],
      "source": "news",
      "url": "https://ironclad-os.org/",
      "added_at": "2025-11-09T15:48:53.334088"
    },
    {
      "article_id": "6006956938719801033",
      "chunk_id": 2,
      "title": "Ironclad \u2013 formally verified, real-time capable, Unix-like OS kernel",
      "topics": [
        "formally verified",
        "real-time capable",
        "operating system",
        "kernel",
        "UNIX-like"
      ],
      "source": "news",
      "url": "https://ironclad-os.org/",
      "added_at": "2025-11-09T15:48:53.643837"
    },
    {
      "article_id": "3962670354649777398",
      "chunk_id": 0,
      "title": "The Manuscripts of Edsger W. Dijkstra",
      "topics": [
        "Numerical indexes",
        "Classification",
        "Bibliographic databases"
      ],
      "source": "news",
      "url": "https://www.cs.utexas.edu/~EWD/",
      "added_at": "2025-11-09T15:55:34.037466"
    },
    {
      "article_id": "3962670354649777398",
      "chunk_id": 1,
      "title": "The Manuscripts of Edsger W. Dijkstra",
      "topics": [
        "Numerical indexes",
        "Classification",
        "Bibliographic databases"
      ],
      "source": "news",
      "url": "https://www.cs.utexas.edu/~EWD/",
      "added_at": "2025-11-09T15:55:34.758345"
    },
    {
      "article_id": "3962670354649777398",
      "chunk_id": 2,
      "title": "The Manuscripts of Edsger W. Dijkstra",
      "topics": [
        "Numerical indexes",
        "Classification",
        "Bibliographic databases"
      ],
      "source": "news",
      "url": "https://www.cs.utexas.edu/~EWD/",
      "added_at": "2025-11-09T15:55:35.263729"
    },
    {
      "article_id": "3962670354649777398",
      "chunk_id": 3,
      "title": "The Manuscripts of Edsger W. Dijkstra",
      "topics": [
        "Numerical indexes",
        "Classification",
        "Bibliographic databases"
      ],
      "source": "news",
      "url": "https://www.cs.utexas.edu/~EWD/",
      "added_at": "2025-11-09T15:55:35.776815"
    },
    {
      "article_id": "3962670354649777398",
      "chunk_id": 4,
      "title": "The Manuscripts of Edsger W. Dijkstra",
      "topics": [
        "Numerical indexes",
        "Classification",
        "Bibliographic databases"
      ],
      "source": "news",
      "url": "https://www.cs.utexas.edu/~EWD/",
      "added_at": "2025-11-09T15:55:36.200654"
    },
    {
      "article_id": "3962670354649777398",
      "chunk_id": 5,
      "title": "The Manuscripts of Edsger W. Dijkstra",
      "topics": [
        "Numerical indexes",
        "Classification",
        "Bibliographic databases"
      ],
      "source": "news",
      "url": "https://www.cs.utexas.edu/~EWD/",
      "added_at": "2025-11-09T15:55:36.805422"
    },
    {
      "article_id": "3962670354649777398",
      "chunk_id": 6,
      "title": "The Manuscripts of Edsger W. Dijkstra",
      "topics": [
        "Numerical indexes",
        "Classification",
        "Bibliographic databases"
      ],
      "source": "news",
      "url": "https://www.cs.utexas.edu/~EWD/",
      "added_at": "2025-11-09T15:55:37.211836"
    },
    {
      "article_id": "3962670354649777398",
      "chunk_id": 7,
      "title": "The Manuscripts of Edsger W. Dijkstra",
      "topics": [
        "Numerical indexes",
        "Classification",
        "Bibliographic databases"
      ],
      "source": "news",
      "url": "https://www.cs.utexas.edu/~EWD/",
      "added_at": "2025-11-09T15:55:37.532795"
    },
    {
      "article_id": "3962670354649777398",
      "chunk_id": 8,
      "title": "The Manuscripts of Edsger W. Dijkstra",
      "topics": [
        "Numerical indexes",
        "Classification",
        "Bibliographic databases"
      ],
      "source": "news",
      "url": "https://www.cs.utexas.edu/~EWD/",
      "added_at": "2025-11-09T15:55:37.825106"
    },
    {
      "article_id": "3962670354649777398",
      "chunk_id": 9,
      "title": "The Manuscripts of Edsger W. Dijkstra",
      "topics": [
        "Numerical indexes",
        "Classification",
        "Bibliographic databases"
      ],
      "source": "news",
      "url": "https://www.cs.utexas.edu/~EWD/",
      "added_at": "2025-11-09T15:55:38.132344"
    },
    {
      "article_id": "3962670354649777398",
      "chunk_id": 10,
      "title": "The Manuscripts of Edsger W. Dijkstra",
      "topics": [
        "Numerical indexes",
        "Classification",
        "Bibliographic databases"
      ],
      "source": "news",
      "url": "https://www.cs.utexas.edu/~EWD/",
      "added_at": "2025-11-09T15:55:38.465413"
    },
    {
      "article_id": "3962670354649777398",
      "chunk_id": 11,
      "title": "The Manuscripts of Edsger W. Dijkstra",
      "topics": [
        "Numerical indexes",
        "Classification",
        "Bibliographic databases"
      ],
      "source": "news",
      "url": "https://www.cs.utexas.edu/~EWD/",
      "added_at": "2025-11-09T15:55:39.003592"
    },
    {
      "article_id": "3962670354649777398",
      "chunk_id": 12,
      "title": "The Manuscripts of Edsger W. Dijkstra",
      "topics": [
        "Numerical indexes",
        "Classification",
        "Bibliographic databases"
      ],
      "source": "news",
      "url": "https://www.cs.utexas.edu/~EWD/",
      "added_at": "2025-11-09T15:55:39.489244"
    },
    {
      "article_id": "295890002928905557",
      "chunk_id": 0,
      "title": "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology",
      "topics": [
        "Internet history",
        "Game development",
        "Investigative journalism"
      ],
      "source": "news",
      "url": "https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/",
      "added_at": "2025-11-09T15:55:41.407448"
    },
    {
      "article_id": "295890002928905557",
      "chunk_id": 1,
      "title": "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology",
      "topics": [
        "Internet history",
        "Game development",
        "Investigative journalism"
      ],
      "source": "news",
      "url": "https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/",
      "added_at": "2025-11-09T15:55:41.717165"
    },
    {
      "article_id": "295890002928905557",
      "chunk_id": 2,
      "title": "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology",
      "topics": [
        "Internet history",
        "Game development",
        "Investigative journalism"
      ],
      "source": "news",
      "url": "https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/",
      "added_at": "2025-11-09T15:55:42.041162"
    },
    {
      "article_id": "295890002928905557",
      "chunk_id": 3,
      "title": "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology",
      "topics": [
        "Internet history",
        "Game development",
        "Investigative journalism"
      ],
      "source": "news",
      "url": "https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/",
      "added_at": "2025-11-09T15:55:42.335326"
    },
    {
      "article_id": "295890002928905557",
      "chunk_id": 4,
      "title": "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology",
      "topics": [
        "Internet history",
        "Game development",
        "Investigative journalism"
      ],
      "source": "news",
      "url": "https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/",
      "added_at": "2025-11-09T15:55:42.572814"
    },
    {
      "article_id": "295890002928905557",
      "chunk_id": 5,
      "title": "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology",
      "topics": [
        "Internet history",
        "Game development",
        "Investigative journalism"
      ],
      "source": "news",
      "url": "https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/",
      "added_at": "2025-11-09T15:55:43.306842"
    },
    {
      "article_id": "295890002928905557",
      "chunk_id": 6,
      "title": "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology",
      "topics": [
        "Internet history",
        "Game development",
        "Investigative journalism"
      ],
      "source": "news",
      "url": "https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/",
      "added_at": "2025-11-09T15:55:43.767679"
    },
    {
      "article_id": "295890002928905557",
      "chunk_id": 7,
      "title": "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology",
      "topics": [
        "Internet history",
        "Game development",
        "Investigative journalism"
      ],
      "source": "news",
      "url": "https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/",
      "added_at": "2025-11-09T15:55:44.286163"
    },
    {
      "article_id": "295890002928905557",
      "chunk_id": 8,
      "title": "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology",
      "topics": [
        "Internet history",
        "Game development",
        "Investigative journalism"
      ],
      "source": "news",
      "url": "https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/",
      "added_at": "2025-11-09T15:55:44.630143"
    },
    {
      "article_id": "295890002928905557",
      "chunk_id": 9,
      "title": "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology",
      "topics": [
        "Internet history",
        "Game development",
        "Investigative journalism"
      ],
      "source": "news",
      "url": "https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/",
      "added_at": "2025-11-09T15:55:44.914967"
    },
    {
      "article_id": "295890002928905557",
      "chunk_id": 10,
      "title": "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology",
      "topics": [
        "Internet history",
        "Game development",
        "Investigative journalism"
      ],
      "source": "news",
      "url": "https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/",
      "added_at": "2025-11-09T15:55:45.166191"
    },
    {
      "article_id": "295890002928905557",
      "chunk_id": 11,
      "title": "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology",
      "topics": [
        "Internet history",
        "Game development",
        "Investigative journalism"
      ],
      "source": "news",
      "url": "https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/",
      "added_at": "2025-11-09T15:55:45.606113"
    },
    {
      "article_id": "295890002928905557",
      "chunk_id": 12,
      "title": "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology",
      "topics": [
        "Internet history",
        "Game development",
        "Investigative journalism"
      ],
      "source": "news",
      "url": "https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/",
      "added_at": "2025-11-09T15:55:45.919970"
    },
    {
      "article_id": "295890002928905557",
      "chunk_id": 13,
      "title": "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology",
      "topics": [
        "Internet history",
        "Game development",
        "Investigative journalism"
      ],
      "source": "news",
      "url": "https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/",
      "added_at": "2025-11-09T15:55:46.248791"
    },
    {
      "article_id": "295890002928905557",
      "chunk_id": 14,
      "title": "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology",
      "topics": [
        "Internet history",
        "Game development",
        "Investigative journalism"
      ],
      "source": "news",
      "url": "https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/",
      "added_at": "2025-11-09T15:55:46.529148"
    },
    {
      "article_id": "295890002928905557",
      "chunk_id": 15,
      "title": "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology",
      "topics": [
        "Internet history",
        "Game development",
        "Investigative journalism"
      ],
      "source": "news",
      "url": "https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/",
      "added_at": "2025-11-09T15:55:46.835040"
    },
    {
      "article_id": "6860706918762962110",
      "chunk_id": 0,
      "title": "Visualize FastAPI endpoints with FastAPI-Voyager",
      "topics": [
        "web development",
        "FastAPI",
        "visualization",
        "user interaction",
        "data exploration"
      ],
      "source": "news",
      "url": "https://www.newsyeah.fun/voyager/",
      "added_at": "2025-11-09T15:55:49.197300"
    },
    {
      "article_id": "6984213789381143306",
      "chunk_id": 0,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "web activity",
        "control verification"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:55:51.293817"
    },
    {
      "article_id": "6984213789381143306",
      "chunk_id": 1,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "web activity",
        "control verification"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:55:51.552851"
    },
    {
      "article_id": "6984213789381143306",
      "chunk_id": 2,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "web activity",
        "control verification"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:55:52.162280"
    },
    {
      "article_id": "6984213789381143306",
      "chunk_id": 3,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "web activity",
        "control verification"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:55:52.468896"
    },
    {
      "article_id": "6984213789381143306",
      "chunk_id": 4,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "web activity",
        "control verification"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:55:52.775400"
    },
    {
      "article_id": "6984213789381143306",
      "chunk_id": 5,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "web activity",
        "control verification"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:55:53.081176"
    },
    {
      "article_id": "6984213789381143306",
      "chunk_id": 6,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "web activity",
        "control verification"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:55:53.415058"
    },
    {
      "article_id": "6984213789381143306",
      "chunk_id": 7,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "web activity",
        "control verification"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:55:53.802155"
    },
    {
      "article_id": "6984213789381143306",
      "chunk_id": 8,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "web activity",
        "control verification"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:55:54.311536"
    },
    {
      "article_id": "6984213789381143306",
      "chunk_id": 9,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "web activity",
        "control verification"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:55:54.618758"
    },
    {
      "article_id": "6984213789381143306",
      "chunk_id": 10,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "web activity",
        "control verification"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:55:54.973823"
    },
    {
      "article_id": "6984213789381143306",
      "chunk_id": 11,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "web activity",
        "control verification"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:55:55.232155"
    },
    {
      "article_id": "6984213789381143306",
      "chunk_id": 12,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "web activity",
        "control verification"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:55:55.551175"
    },
    {
      "article_id": "6984213789381143306",
      "chunk_id": 13,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "web activity",
        "control verification"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:55:56.280743"
    },
    {
      "article_id": "6984213789381143306",
      "chunk_id": 14,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "web activity",
        "control verification"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:55:56.584463"
    },
    {
      "article_id": "6984213789381143306",
      "chunk_id": 15,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "web activity",
        "control verification"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:55:57.037866"
    },
    {
      "article_id": "6984213789381143306",
      "chunk_id": 16,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "web activity",
        "control verification"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:55:57.296840"
    },
    {
      "article_id": "6984213789381143306",
      "chunk_id": 17,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "web activity",
        "control verification"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:55:57.590646"
    },
    {
      "article_id": "6984213789381143306",
      "chunk_id": 18,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "web activity",
        "control verification"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:55:58.117823"
    },
    {
      "article_id": "6984213789381143306",
      "chunk_id": 19,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "web activity",
        "control verification"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:55:58.421246"
    },
    {
      "article_id": "6984213789381143306",
      "chunk_id": 20,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "web activity",
        "control verification"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:55:58.739500"
    },
    {
      "article_id": "6984213789381143306",
      "chunk_id": 21,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "web activity",
        "control verification"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:56:00.079530"
    },
    {
      "article_id": "6984213789381143306",
      "chunk_id": 22,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "web activity",
        "control verification"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:56:00.510040"
    },
    {
      "article_id": "6984213789381143306",
      "chunk_id": 23,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "web activity",
        "control verification"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:56:00.848383"
    },
    {
      "article_id": "6984213789381143306",
      "chunk_id": 24,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "web activity",
        "control verification"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:56:01.228016"
    },
    {
      "article_id": "6984213789381143306",
      "chunk_id": 25,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "web activity",
        "control verification"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:56:01.451040"
    },
    {
      "article_id": "6984213789381143306",
      "chunk_id": 26,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "web activity",
        "control verification"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:56:01.794825"
    },
    {
      "article_id": "1596958057563952222",
      "chunk_id": 0,
      "title": "Using bubblewrap to add sandboxing to NetBSD",
      "topics": [
        "programming",
        "Google Summer of Code",
        "sandboxing",
        "NetBSD"
      ],
      "source": "news",
      "url": "https://blog.netbsd.org/tnf/entry/gsoc2025_bubblewrap_sandboxing",
      "added_at": "2025-11-09T15:56:03.355195"
    },
    {
      "article_id": "1596958057563952222",
      "chunk_id": 1,
      "title": "Using bubblewrap to add sandboxing to NetBSD",
      "topics": [
        "programming",
        "Google Summer of Code",
        "sandboxing",
        "NetBSD"
      ],
      "source": "news",
      "url": "https://blog.netbsd.org/tnf/entry/gsoc2025_bubblewrap_sandboxing",
      "added_at": "2025-11-09T15:56:03.569373"
    },
    {
      "article_id": "1596958057563952222",
      "chunk_id": 2,
      "title": "Using bubblewrap to add sandboxing to NetBSD",
      "topics": [
        "programming",
        "Google Summer of Code",
        "sandboxing",
        "NetBSD"
      ],
      "source": "news",
      "url": "https://blog.netbsd.org/tnf/entry/gsoc2025_bubblewrap_sandboxing",
      "added_at": "2025-11-09T15:56:03.823223"
    },
    {
      "article_id": "1596958057563952222",
      "chunk_id": 3,
      "title": "Using bubblewrap to add sandboxing to NetBSD",
      "topics": [
        "programming",
        "Google Summer of Code",
        "sandboxing",
        "NetBSD"
      ],
      "source": "news",
      "url": "https://blog.netbsd.org/tnf/entry/gsoc2025_bubblewrap_sandboxing",
      "added_at": "2025-11-09T15:56:04.080243"
    },
    {
      "article_id": "1596958057563952222",
      "chunk_id": 4,
      "title": "Using bubblewrap to add sandboxing to NetBSD",
      "topics": [
        "programming",
        "Google Summer of Code",
        "sandboxing",
        "NetBSD"
      ],
      "source": "news",
      "url": "https://blog.netbsd.org/tnf/entry/gsoc2025_bubblewrap_sandboxing",
      "added_at": "2025-11-09T15:56:04.391098"
    },
    {
      "article_id": "1596958057563952222",
      "chunk_id": 5,
      "title": "Using bubblewrap to add sandboxing to NetBSD",
      "topics": [
        "programming",
        "Google Summer of Code",
        "sandboxing",
        "NetBSD"
      ],
      "source": "news",
      "url": "https://blog.netbsd.org/tnf/entry/gsoc2025_bubblewrap_sandboxing",
      "added_at": "2025-11-09T15:56:04.646917"
    },
    {
      "article_id": "1596958057563952222",
      "chunk_id": 6,
      "title": "Using bubblewrap to add sandboxing to NetBSD",
      "topics": [
        "programming",
        "Google Summer of Code",
        "sandboxing",
        "NetBSD"
      ],
      "source": "news",
      "url": "https://blog.netbsd.org/tnf/entry/gsoc2025_bubblewrap_sandboxing",
      "added_at": "2025-11-09T15:56:04.886758"
    },
    {
      "article_id": "1596958057563952222",
      "chunk_id": 7,
      "title": "Using bubblewrap to add sandboxing to NetBSD",
      "topics": [
        "programming",
        "Google Summer of Code",
        "sandboxing",
        "NetBSD"
      ],
      "source": "news",
      "url": "https://blog.netbsd.org/tnf/entry/gsoc2025_bubblewrap_sandboxing",
      "added_at": "2025-11-09T15:56:05.093293"
    },
    {
      "article_id": "1596958057563952222",
      "chunk_id": 8,
      "title": "Using bubblewrap to add sandboxing to NetBSD",
      "topics": [
        "programming",
        "Google Summer of Code",
        "sandboxing",
        "NetBSD"
      ],
      "source": "news",
      "url": "https://blog.netbsd.org/tnf/entry/gsoc2025_bubblewrap_sandboxing",
      "added_at": "2025-11-09T15:56:05.402593"
    },
    {
      "article_id": "1596958057563952222",
      "chunk_id": 9,
      "title": "Using bubblewrap to add sandboxing to NetBSD",
      "topics": [
        "programming",
        "Google Summer of Code",
        "sandboxing",
        "NetBSD"
      ],
      "source": "news",
      "url": "https://blog.netbsd.org/tnf/entry/gsoc2025_bubblewrap_sandboxing",
      "added_at": "2025-11-09T15:56:05.739358"
    },
    {
      "article_id": "1596958057563952222",
      "chunk_id": 10,
      "title": "Using bubblewrap to add sandboxing to NetBSD",
      "topics": [
        "programming",
        "Google Summer of Code",
        "sandboxing",
        "NetBSD"
      ],
      "source": "news",
      "url": "https://blog.netbsd.org/tnf/entry/gsoc2025_bubblewrap_sandboxing",
      "added_at": "2025-11-09T15:56:05.932708"
    },
    {
      "article_id": "1596958057563952222",
      "chunk_id": 11,
      "title": "Using bubblewrap to add sandboxing to NetBSD",
      "topics": [
        "programming",
        "Google Summer of Code",
        "sandboxing",
        "NetBSD"
      ],
      "source": "news",
      "url": "https://blog.netbsd.org/tnf/entry/gsoc2025_bubblewrap_sandboxing",
      "added_at": "2025-11-09T15:56:06.170332"
    },
    {
      "article_id": "1596958057563952222",
      "chunk_id": 12,
      "title": "Using bubblewrap to add sandboxing to NetBSD",
      "topics": [
        "programming",
        "Google Summer of Code",
        "sandboxing",
        "NetBSD"
      ],
      "source": "news",
      "url": "https://blog.netbsd.org/tnf/entry/gsoc2025_bubblewrap_sandboxing",
      "added_at": "2025-11-09T15:56:06.394229"
    },
    {
      "article_id": "5413222526982348809",
      "chunk_id": 0,
      "title": "Montana Becomes First State to Enshrine 'Right to Compute' into Law",
      "topics": [
        "legal protection",
        "Montana",
        "citizens' rights",
        "history"
      ],
      "source": "news",
      "url": "https://montananewsroom.com/montana-becomes-first-state-to-enshrine-right-to-compute-into-law/",
      "added_at": "2025-11-09T15:56:09.458169"
    },
    {
      "article_id": "5413222526982348809",
      "chunk_id": 1,
      "title": "Montana Becomes First State to Enshrine 'Right to Compute' into Law",
      "topics": [
        "legal protection",
        "Montana",
        "citizens' rights",
        "history"
      ],
      "source": "news",
      "url": "https://montananewsroom.com/montana-becomes-first-state-to-enshrine-right-to-compute-into-law/",
      "added_at": "2025-11-09T15:56:09.764346"
    },
    {
      "article_id": "5413222526982348809",
      "chunk_id": 2,
      "title": "Montana Becomes First State to Enshrine 'Right to Compute' into Law",
      "topics": [
        "legal protection",
        "Montana",
        "citizens' rights",
        "history"
      ],
      "source": "news",
      "url": "https://montananewsroom.com/montana-becomes-first-state-to-enshrine-right-to-compute-into-law/",
      "added_at": "2025-11-09T15:56:10.072464"
    },
    {
      "article_id": "5413222526982348809",
      "chunk_id": 3,
      "title": "Montana Becomes First State to Enshrine 'Right to Compute' into Law",
      "topics": [
        "legal protection",
        "Montana",
        "citizens' rights",
        "history"
      ],
      "source": "news",
      "url": "https://montananewsroom.com/montana-becomes-first-state-to-enshrine-right-to-compute-into-law/",
      "added_at": "2025-11-09T15:56:10.378684"
    },
    {
      "article_id": "5413222526982348809",
      "chunk_id": 4,
      "title": "Montana Becomes First State to Enshrine 'Right to Compute' into Law",
      "topics": [
        "legal protection",
        "Montana",
        "citizens' rights",
        "history"
      ],
      "source": "news",
      "url": "https://montananewsroom.com/montana-becomes-first-state-to-enshrine-right-to-compute-into-law/",
      "added_at": "2025-11-09T15:56:10.994340"
    },
    {
      "article_id": "2742989716431158064",
      "chunk_id": 0,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "software",
        "static site generator",
        "modern"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:56:11.812548"
    },
    {
      "article_id": "2742989716431158064",
      "chunk_id": 1,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "software",
        "static site generator",
        "modern"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:56:12.017030"
    },
    {
      "article_id": "2742989716431158064",
      "chunk_id": 2,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "software",
        "static site generator",
        "modern"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:56:12.429016"
    },
    {
      "article_id": "2742989716431158064",
      "chunk_id": 3,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "software",
        "static site generator",
        "modern"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:56:12.733918"
    },
    {
      "article_id": "2742989716431158064",
      "chunk_id": 4,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "software",
        "static site generator",
        "modern"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:56:13.041225"
    },
    {
      "article_id": "2742989716431158064",
      "chunk_id": 5,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "software",
        "static site generator",
        "modern"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:56:13.348530"
    },
    {
      "article_id": "2742989716431158064",
      "chunk_id": 6,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "software",
        "static site generator",
        "modern"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:56:13.655157"
    },
    {
      "article_id": "2742989716431158064",
      "chunk_id": 7,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "software",
        "static site generator",
        "modern"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:56:13.963827"
    },
    {
      "article_id": "2742989716431158064",
      "chunk_id": 8,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "software",
        "static site generator",
        "modern"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:56:14.269855"
    },
    {
      "article_id": "2742989716431158064",
      "chunk_id": 9,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "software",
        "static site generator",
        "modern"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:56:14.680591"
    },
    {
      "article_id": "2742989716431158064",
      "chunk_id": 10,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "software",
        "static site generator",
        "modern"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:56:15.089181"
    },
    {
      "article_id": "2742989716431158064",
      "chunk_id": 11,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "software",
        "static site generator",
        "modern"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:56:15.398173"
    },
    {
      "article_id": "2742989716431158064",
      "chunk_id": 12,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "software",
        "static site generator",
        "modern"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:56:15.703354"
    },
    {
      "article_id": "2742989716431158064",
      "chunk_id": 13,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "software",
        "static site generator",
        "modern"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:56:16.010780"
    },
    {
      "article_id": "2742989716431158064",
      "chunk_id": 14,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "software",
        "static site generator",
        "modern"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:56:16.651546"
    },
    {
      "article_id": "2742989716431158064",
      "chunk_id": 15,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "software",
        "static site generator",
        "modern"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:56:16.933411"
    },
    {
      "article_id": "2742989716431158064",
      "chunk_id": 16,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "software",
        "static site generator",
        "modern"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:56:17.239273"
    },
    {
      "article_id": "2742989716431158064",
      "chunk_id": 17,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "software",
        "static site generator",
        "modern"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:56:17.650062"
    },
    {
      "article_id": "2686732243144846519",
      "chunk_id": 0,
      "title": "I Am Mark Zuckerberg",
      "topics": [
        "website",
        "Mark Zuckerberg",
        "community service",
        "Hoosiers",
        "identity"
      ],
      "source": "news",
      "url": "https://iammarkzuckerberg.com/",
      "added_at": "2025-11-09T15:56:19.698133"
    },
    {
      "article_id": "2686732243144846519",
      "chunk_id": 1,
      "title": "I Am Mark Zuckerberg",
      "topics": [
        "website",
        "Mark Zuckerberg",
        "community service",
        "Hoosiers",
        "identity"
      ],
      "source": "news",
      "url": "https://iammarkzuckerberg.com/",
      "added_at": "2025-11-09T15:56:19.892334"
    },
    {
      "article_id": "2686732243144846519",
      "chunk_id": 2,
      "title": "I Am Mark Zuckerberg",
      "topics": [
        "website",
        "Mark Zuckerberg",
        "community service",
        "Hoosiers",
        "identity"
      ],
      "source": "news",
      "url": "https://iammarkzuckerberg.com/",
      "added_at": "2025-11-09T15:56:20.107986"
    },
    {
      "article_id": "7814549832573697797",
      "chunk_id": 0,
      "title": "Ironclad \u2013 formally verified, real-time capable, Unix-like OS kernel",
      "topics": [
        "real-time",
        "operating system",
        "UNIX-like",
        "kernel",
        "formally verified"
      ],
      "source": "news",
      "url": "https://ironclad-os.org/",
      "added_at": "2025-11-09T15:56:21.643686"
    },
    {
      "article_id": "7814549832573697797",
      "chunk_id": 1,
      "title": "Ironclad \u2013 formally verified, real-time capable, Unix-like OS kernel",
      "topics": [
        "real-time",
        "operating system",
        "UNIX-like",
        "kernel",
        "formally verified"
      ],
      "source": "news",
      "url": "https://ironclad-os.org/",
      "added_at": "2025-11-09T15:56:21.949676"
    },
    {
      "article_id": "7814549832573697797",
      "chunk_id": 2,
      "title": "Ironclad \u2013 formally verified, real-time capable, Unix-like OS kernel",
      "topics": [
        "real-time",
        "operating system",
        "UNIX-like",
        "kernel",
        "formally verified"
      ],
      "source": "news",
      "url": "https://ironclad-os.org/",
      "added_at": "2025-11-09T15:56:22.258244"
    },
    {
      "article_id": "7274642597512286300",
      "chunk_id": 0,
      "title": "The Manuscripts of Edsger W. Dijkstra",
      "topics": [
        "indexing",
        "numerical",
        "EWD",
        "BibT"
      ],
      "source": "news",
      "url": "https://www.cs.utexas.edu/~EWD/",
      "added_at": "2025-11-09T15:57:35.067392"
    },
    {
      "article_id": "7274642597512286300",
      "chunk_id": 1,
      "title": "The Manuscripts of Edsger W. Dijkstra",
      "topics": [
        "indexing",
        "numerical",
        "EWD",
        "BibT"
      ],
      "source": "news",
      "url": "https://www.cs.utexas.edu/~EWD/",
      "added_at": "2025-11-09T15:57:36.702337"
    },
    {
      "article_id": "7274642597512286300",
      "chunk_id": 2,
      "title": "The Manuscripts of Edsger W. Dijkstra",
      "topics": [
        "indexing",
        "numerical",
        "EWD",
        "BibT"
      ],
      "source": "news",
      "url": "https://www.cs.utexas.edu/~EWD/",
      "added_at": "2025-11-09T15:57:37.623838"
    },
    {
      "article_id": "7274642597512286300",
      "chunk_id": 3,
      "title": "The Manuscripts of Edsger W. Dijkstra",
      "topics": [
        "indexing",
        "numerical",
        "EWD",
        "BibT"
      ],
      "source": "news",
      "url": "https://www.cs.utexas.edu/~EWD/",
      "added_at": "2025-11-09T15:57:37.932132"
    },
    {
      "article_id": "7274642597512286300",
      "chunk_id": 4,
      "title": "The Manuscripts of Edsger W. Dijkstra",
      "topics": [
        "indexing",
        "numerical",
        "EWD",
        "BibT"
      ],
      "source": "news",
      "url": "https://www.cs.utexas.edu/~EWD/",
      "added_at": "2025-11-09T15:57:38.750341"
    },
    {
      "article_id": "7274642597512286300",
      "chunk_id": 5,
      "title": "The Manuscripts of Edsger W. Dijkstra",
      "topics": [
        "indexing",
        "numerical",
        "EWD",
        "BibT"
      ],
      "source": "news",
      "url": "https://www.cs.utexas.edu/~EWD/",
      "added_at": "2025-11-09T15:57:39.263183"
    },
    {
      "article_id": "7274642597512286300",
      "chunk_id": 6,
      "title": "The Manuscripts of Edsger W. Dijkstra",
      "topics": [
        "indexing",
        "numerical",
        "EWD",
        "BibT"
      ],
      "source": "news",
      "url": "https://www.cs.utexas.edu/~EWD/",
      "added_at": "2025-11-09T15:57:39.568603"
    },
    {
      "article_id": "7274642597512286300",
      "chunk_id": 7,
      "title": "The Manuscripts of Edsger W. Dijkstra",
      "topics": [
        "indexing",
        "numerical",
        "EWD",
        "BibT"
      ],
      "source": "news",
      "url": "https://www.cs.utexas.edu/~EWD/",
      "added_at": "2025-11-09T15:57:39.876217"
    },
    {
      "article_id": "7274642597512286300",
      "chunk_id": 8,
      "title": "The Manuscripts of Edsger W. Dijkstra",
      "topics": [
        "indexing",
        "numerical",
        "EWD",
        "BibT"
      ],
      "source": "news",
      "url": "https://www.cs.utexas.edu/~EWD/",
      "added_at": "2025-11-09T15:57:40.184833"
    },
    {
      "article_id": "7274642597512286300",
      "chunk_id": 9,
      "title": "The Manuscripts of Edsger W. Dijkstra",
      "topics": [
        "indexing",
        "numerical",
        "EWD",
        "BibT"
      ],
      "source": "news",
      "url": "https://www.cs.utexas.edu/~EWD/",
      "added_at": "2025-11-09T15:57:40.592144"
    },
    {
      "article_id": "7274642597512286300",
      "chunk_id": 10,
      "title": "The Manuscripts of Edsger W. Dijkstra",
      "topics": [
        "indexing",
        "numerical",
        "EWD",
        "BibT"
      ],
      "source": "news",
      "url": "https://www.cs.utexas.edu/~EWD/",
      "added_at": "2025-11-09T15:57:40.901778"
    },
    {
      "article_id": "7274642597512286300",
      "chunk_id": 11,
      "title": "The Manuscripts of Edsger W. Dijkstra",
      "topics": [
        "indexing",
        "numerical",
        "EWD",
        "BibT"
      ],
      "source": "news",
      "url": "https://www.cs.utexas.edu/~EWD/",
      "added_at": "2025-11-09T15:57:41.309680"
    },
    {
      "article_id": "7274642597512286300",
      "chunk_id": 12,
      "title": "The Manuscripts of Edsger W. Dijkstra",
      "topics": [
        "indexing",
        "numerical",
        "EWD",
        "BibT"
      ],
      "source": "news",
      "url": "https://www.cs.utexas.edu/~EWD/",
      "added_at": "2025-11-09T15:57:41.617988"
    },
    {
      "article_id": "6597347448727373032",
      "chunk_id": 0,
      "title": "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology",
      "topics": [
        "internet history",
        "research",
        "investigation",
        "technology",
        "gaming"
      ],
      "source": "news",
      "url": "https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/",
      "added_at": "2025-11-09T15:57:44.176072"
    },
    {
      "article_id": "6597347448727373032",
      "chunk_id": 1,
      "title": "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology",
      "topics": [
        "internet history",
        "research",
        "investigation",
        "technology",
        "gaming"
      ],
      "source": "news",
      "url": "https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/",
      "added_at": "2025-11-09T15:57:44.485239"
    },
    {
      "article_id": "6597347448727373032",
      "chunk_id": 2,
      "title": "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology",
      "topics": [
        "internet history",
        "research",
        "investigation",
        "technology",
        "gaming"
      ],
      "source": "news",
      "url": "https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/",
      "added_at": "2025-11-09T15:57:44.857723"
    },
    {
      "article_id": "6597347448727373032",
      "chunk_id": 3,
      "title": "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology",
      "topics": [
        "internet history",
        "research",
        "investigation",
        "technology",
        "gaming"
      ],
      "source": "news",
      "url": "https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/",
      "added_at": "2025-11-09T15:57:45.098095"
    },
    {
      "article_id": "6597347448727373032",
      "chunk_id": 4,
      "title": "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology",
      "topics": [
        "internet history",
        "research",
        "investigation",
        "technology",
        "gaming"
      ],
      "source": "news",
      "url": "https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/",
      "added_at": "2025-11-09T15:57:45.404732"
    },
    {
      "article_id": "6597347448727373032",
      "chunk_id": 5,
      "title": "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology",
      "topics": [
        "internet history",
        "research",
        "investigation",
        "technology",
        "gaming"
      ],
      "source": "news",
      "url": "https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/",
      "added_at": "2025-11-09T15:57:45.712170"
    },
    {
      "article_id": "6597347448727373032",
      "chunk_id": 6,
      "title": "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology",
      "topics": [
        "internet history",
        "research",
        "investigation",
        "technology",
        "gaming"
      ],
      "source": "news",
      "url": "https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/",
      "added_at": "2025-11-09T15:57:46.021357"
    },
    {
      "article_id": "6597347448727373032",
      "chunk_id": 7,
      "title": "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology",
      "topics": [
        "internet history",
        "research",
        "investigation",
        "technology",
        "gaming"
      ],
      "source": "news",
      "url": "https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/",
      "added_at": "2025-11-09T15:57:46.327260"
    },
    {
      "article_id": "6597347448727373032",
      "chunk_id": 8,
      "title": "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology",
      "topics": [
        "internet history",
        "research",
        "investigation",
        "technology",
        "gaming"
      ],
      "source": "news",
      "url": "https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/",
      "added_at": "2025-11-09T15:57:46.634822"
    },
    {
      "article_id": "6597347448727373032",
      "chunk_id": 9,
      "title": "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology",
      "topics": [
        "internet history",
        "research",
        "investigation",
        "technology",
        "gaming"
      ],
      "source": "news",
      "url": "https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/",
      "added_at": "2025-11-09T15:57:47.044325"
    },
    {
      "article_id": "6597347448727373032",
      "chunk_id": 10,
      "title": "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology",
      "topics": [
        "internet history",
        "research",
        "investigation",
        "technology",
        "gaming"
      ],
      "source": "news",
      "url": "https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/",
      "added_at": "2025-11-09T15:57:47.351436"
    },
    {
      "article_id": "6597347448727373032",
      "chunk_id": 11,
      "title": "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology",
      "topics": [
        "internet history",
        "research",
        "investigation",
        "technology",
        "gaming"
      ],
      "source": "news",
      "url": "https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/",
      "added_at": "2025-11-09T15:57:47.760657"
    },
    {
      "article_id": "6597347448727373032",
      "chunk_id": 12,
      "title": "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology",
      "topics": [
        "internet history",
        "research",
        "investigation",
        "technology",
        "gaming"
      ],
      "source": "news",
      "url": "https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/",
      "added_at": "2025-11-09T15:57:48.171126"
    },
    {
      "article_id": "6597347448727373032",
      "chunk_id": 13,
      "title": "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology",
      "topics": [
        "internet history",
        "research",
        "investigation",
        "technology",
        "gaming"
      ],
      "source": "news",
      "url": "https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/",
      "added_at": "2025-11-09T15:57:48.497786"
    },
    {
      "article_id": "6597347448727373032",
      "chunk_id": 14,
      "title": "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology",
      "topics": [
        "internet history",
        "research",
        "investigation",
        "technology",
        "gaming"
      ],
      "source": "news",
      "url": "https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/",
      "added_at": "2025-11-09T15:57:48.888904"
    },
    {
      "article_id": "6597347448727373032",
      "chunk_id": 15,
      "title": "Reviving Classic Unix Games: A 20-Year Journey Through Software Archaeology",
      "topics": [
        "internet history",
        "research",
        "investigation",
        "technology",
        "gaming"
      ],
      "source": "news",
      "url": "https://vejeta.com/reviving-classic-unix-games-a-20-year-journey-through-software-archaeology/",
      "added_at": "2025-11-09T15:57:49.296114"
    },
    {
      "article_id": "7643618233456594432",
      "chunk_id": 0,
      "title": "Visualize FastAPI endpoints with FastAPI-Voyager",
      "topics": [
        "web development",
        "API",
        "FastAPI",
        "data visualization",
        "user interaction"
      ],
      "source": "news",
      "url": "https://www.newsyeah.fun/voyager/",
      "added_at": "2025-11-09T15:57:51.447729"
    },
    {
      "article_id": "1816113217470598566",
      "chunk_id": 0,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "control verification",
        "online activity"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:57:54.802734"
    },
    {
      "article_id": "1816113217470598566",
      "chunk_id": 1,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "control verification",
        "online activity"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:57:55.030816"
    },
    {
      "article_id": "1816113217470598566",
      "chunk_id": 2,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "control verification",
        "online activity"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:57:55.544413"
    },
    {
      "article_id": "1816113217470598566",
      "chunk_id": 3,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "control verification",
        "online activity"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:57:55.850489"
    },
    {
      "article_id": "1816113217470598566",
      "chunk_id": 4,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "control verification",
        "online activity"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:57:56.157211"
    },
    {
      "article_id": "1816113217470598566",
      "chunk_id": 5,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "control verification",
        "online activity"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:57:56.465035"
    },
    {
      "article_id": "1816113217470598566",
      "chunk_id": 6,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "control verification",
        "online activity"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:57:56.771881"
    },
    {
      "article_id": "1816113217470598566",
      "chunk_id": 7,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "control verification",
        "online activity"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:57:57.080643"
    },
    {
      "article_id": "1816113217470598566",
      "chunk_id": 8,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "control verification",
        "online activity"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:57:57.386042"
    },
    {
      "article_id": "1816113217470598566",
      "chunk_id": 9,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "control verification",
        "online activity"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:57:57.695112"
    },
    {
      "article_id": "1816113217470598566",
      "chunk_id": 10,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "control verification",
        "online activity"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:57:58.001169"
    },
    {
      "article_id": "1816113217470598566",
      "chunk_id": 11,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "control verification",
        "online activity"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:57:58.308218"
    },
    {
      "article_id": "1816113217470598566",
      "chunk_id": 12,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "control verification",
        "online activity"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:57:58.514333"
    },
    {
      "article_id": "1816113217470598566",
      "chunk_id": 13,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "control verification",
        "online activity"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:57:58.819276"
    },
    {
      "article_id": "1816113217470598566",
      "chunk_id": 14,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "control verification",
        "online activity"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:57:59.024550"
    },
    {
      "article_id": "1816113217470598566",
      "chunk_id": 15,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "control verification",
        "online activity"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:57:59.333035"
    },
    {
      "article_id": "1816113217470598566",
      "chunk_id": 16,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "control verification",
        "online activity"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:57:59.638948"
    },
    {
      "article_id": "1816113217470598566",
      "chunk_id": 17,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "control verification",
        "online activity"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:57:59.910139"
    },
    {
      "article_id": "1816113217470598566",
      "chunk_id": 18,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "control verification",
        "online activity"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:58:00.154422"
    },
    {
      "article_id": "1816113217470598566",
      "chunk_id": 19,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "control verification",
        "online activity"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:58:00.458281"
    },
    {
      "article_id": "1816113217470598566",
      "chunk_id": 20,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "control verification",
        "online activity"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:58:00.766304"
    },
    {
      "article_id": "1816113217470598566",
      "chunk_id": 21,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "control verification",
        "online activity"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:58:01.072993"
    },
    {
      "article_id": "1816113217470598566",
      "chunk_id": 22,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "control verification",
        "online activity"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:58:01.379550"
    },
    {
      "article_id": "1816113217470598566",
      "chunk_id": 23,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "control verification",
        "online activity"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:58:01.686343"
    },
    {
      "article_id": "1816113217470598566",
      "chunk_id": 24,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "control verification",
        "online activity"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:58:01.994383"
    },
    {
      "article_id": "1816113217470598566",
      "chunk_id": 25,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "control verification",
        "online activity"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:58:02.198979"
    },
    {
      "article_id": "1816113217470598566",
      "chunk_id": 26,
      "title": "Email verification protocol",
      "topics": [
        "email verification",
        "control verification",
        "online activity"
      ],
      "source": "news",
      "url": "https://github.com/WICG/email-verification-protocol",
      "added_at": "2025-11-09T15:58:02.505967"
    },
    {
      "article_id": "5523012415423943567",
      "chunk_id": 0,
      "title": "Using bubblewrap to add sandboxing to NetBSD",
      "topics": [
        "programming",
        "Google Summer of Code",
        "sandboxing",
        "NetBSD",
        "bubblewrap"
      ],
      "source": "news",
      "url": "https://blog.netbsd.org/tnf/entry/gsoc2025_bubblewrap_sandboxing",
      "added_at": "2025-11-09T15:58:04.759119"
    },
    {
      "article_id": "5523012415423943567",
      "chunk_id": 1,
      "title": "Using bubblewrap to add sandboxing to NetBSD",
      "topics": [
        "programming",
        "Google Summer of Code",
        "sandboxing",
        "NetBSD",
        "bubblewrap"
      ],
      "source": "news",
      "url": "https://blog.netbsd.org/tnf/entry/gsoc2025_bubblewrap_sandboxing",
      "added_at": "2025-11-09T15:58:05.107759"
    },
    {
      "article_id": "5523012415423943567",
      "chunk_id": 2,
      "title": "Using bubblewrap to add sandboxing to NetBSD",
      "topics": [
        "programming",
        "Google Summer of Code",
        "sandboxing",
        "NetBSD",
        "bubblewrap"
      ],
      "source": "news",
      "url": "https://blog.netbsd.org/tnf/entry/gsoc2025_bubblewrap_sandboxing",
      "added_at": "2025-11-09T15:58:05.475425"
    },
    {
      "article_id": "5523012415423943567",
      "chunk_id": 3,
      "title": "Using bubblewrap to add sandboxing to NetBSD",
      "topics": [
        "programming",
        "Google Summer of Code",
        "sandboxing",
        "NetBSD",
        "bubblewrap"
      ],
      "source": "news",
      "url": "https://blog.netbsd.org/tnf/entry/gsoc2025_bubblewrap_sandboxing",
      "added_at": "2025-11-09T15:58:05.987806"
    },
    {
      "article_id": "5523012415423943567",
      "chunk_id": 4,
      "title": "Using bubblewrap to add sandboxing to NetBSD",
      "topics": [
        "programming",
        "Google Summer of Code",
        "sandboxing",
        "NetBSD",
        "bubblewrap"
      ],
      "source": "news",
      "url": "https://blog.netbsd.org/tnf/entry/gsoc2025_bubblewrap_sandboxing",
      "added_at": "2025-11-09T15:58:06.295001"
    },
    {
      "article_id": "5523012415423943567",
      "chunk_id": 5,
      "title": "Using bubblewrap to add sandboxing to NetBSD",
      "topics": [
        "programming",
        "Google Summer of Code",
        "sandboxing",
        "NetBSD",
        "bubblewrap"
      ],
      "source": "news",
      "url": "https://blog.netbsd.org/tnf/entry/gsoc2025_bubblewrap_sandboxing",
      "added_at": "2025-11-09T15:58:06.602542"
    },
    {
      "article_id": "5523012415423943567",
      "chunk_id": 6,
      "title": "Using bubblewrap to add sandboxing to NetBSD",
      "topics": [
        "programming",
        "Google Summer of Code",
        "sandboxing",
        "NetBSD",
        "bubblewrap"
      ],
      "source": "news",
      "url": "https://blog.netbsd.org/tnf/entry/gsoc2025_bubblewrap_sandboxing",
      "added_at": "2025-11-09T15:58:06.909843"
    },
    {
      "article_id": "5523012415423943567",
      "chunk_id": 7,
      "title": "Using bubblewrap to add sandboxing to NetBSD",
      "topics": [
        "programming",
        "Google Summer of Code",
        "sandboxing",
        "NetBSD",
        "bubblewrap"
      ],
      "source": "news",
      "url": "https://blog.netbsd.org/tnf/entry/gsoc2025_bubblewrap_sandboxing",
      "added_at": "2025-11-09T15:58:07.216174"
    },
    {
      "article_id": "5523012415423943567",
      "chunk_id": 8,
      "title": "Using bubblewrap to add sandboxing to NetBSD",
      "topics": [
        "programming",
        "Google Summer of Code",
        "sandboxing",
        "NetBSD",
        "bubblewrap"
      ],
      "source": "news",
      "url": "https://blog.netbsd.org/tnf/entry/gsoc2025_bubblewrap_sandboxing",
      "added_at": "2025-11-09T15:58:07.421543"
    },
    {
      "article_id": "5523012415423943567",
      "chunk_id": 9,
      "title": "Using bubblewrap to add sandboxing to NetBSD",
      "topics": [
        "programming",
        "Google Summer of Code",
        "sandboxing",
        "NetBSD",
        "bubblewrap"
      ],
      "source": "news",
      "url": "https://blog.netbsd.org/tnf/entry/gsoc2025_bubblewrap_sandboxing",
      "added_at": "2025-11-09T15:58:07.729657"
    },
    {
      "article_id": "5523012415423943567",
      "chunk_id": 10,
      "title": "Using bubblewrap to add sandboxing to NetBSD",
      "topics": [
        "programming",
        "Google Summer of Code",
        "sandboxing",
        "NetBSD",
        "bubblewrap"
      ],
      "source": "news",
      "url": "https://blog.netbsd.org/tnf/entry/gsoc2025_bubblewrap_sandboxing",
      "added_at": "2025-11-09T15:58:08.035370"
    },
    {
      "article_id": "5523012415423943567",
      "chunk_id": 11,
      "title": "Using bubblewrap to add sandboxing to NetBSD",
      "topics": [
        "programming",
        "Google Summer of Code",
        "sandboxing",
        "NetBSD",
        "bubblewrap"
      ],
      "source": "news",
      "url": "https://blog.netbsd.org/tnf/entry/gsoc2025_bubblewrap_sandboxing",
      "added_at": "2025-11-09T15:58:08.254780"
    },
    {
      "article_id": "5523012415423943567",
      "chunk_id": 12,
      "title": "Using bubblewrap to add sandboxing to NetBSD",
      "topics": [
        "programming",
        "Google Summer of Code",
        "sandboxing",
        "NetBSD",
        "bubblewrap"
      ],
      "source": "news",
      "url": "https://blog.netbsd.org/tnf/entry/gsoc2025_bubblewrap_sandboxing",
      "added_at": "2025-11-09T15:58:08.547615"
    },
    {
      "article_id": "1733058420916330971",
      "chunk_id": 0,
      "title": "Montana Becomes First State to Enshrine 'Right to Compute' into Law",
      "topics": [
        "history",
        "Montana",
        "state law",
        "citizens' rights",
        "legal protection"
      ],
      "source": "news",
      "url": "https://montananewsroom.com/montana-becomes-first-state-to-enshrine-right-to-compute-into-law/",
      "added_at": "2025-11-09T15:58:10.902686"
    },
    {
      "article_id": "1733058420916330971",
      "chunk_id": 1,
      "title": "Montana Becomes First State to Enshrine 'Right to Compute' into Law",
      "topics": [
        "history",
        "Montana",
        "state law",
        "citizens' rights",
        "legal protection"
      ],
      "source": "news",
      "url": "https://montananewsroom.com/montana-becomes-first-state-to-enshrine-right-to-compute-into-law/",
      "added_at": "2025-11-09T15:58:11.212133"
    },
    {
      "article_id": "1733058420916330971",
      "chunk_id": 2,
      "title": "Montana Becomes First State to Enshrine 'Right to Compute' into Law",
      "topics": [
        "history",
        "Montana",
        "state law",
        "citizens' rights",
        "legal protection"
      ],
      "source": "news",
      "url": "https://montananewsroom.com/montana-becomes-first-state-to-enshrine-right-to-compute-into-law/",
      "added_at": "2025-11-09T15:58:11.620142"
    },
    {
      "article_id": "1733058420916330971",
      "chunk_id": 3,
      "title": "Montana Becomes First State to Enshrine 'Right to Compute' into Law",
      "topics": [
        "history",
        "Montana",
        "state law",
        "citizens' rights",
        "legal protection"
      ],
      "source": "news",
      "url": "https://montananewsroom.com/montana-becomes-first-state-to-enshrine-right-to-compute-into-law/",
      "added_at": "2025-11-09T15:58:11.927883"
    },
    {
      "article_id": "1733058420916330971",
      "chunk_id": 4,
      "title": "Montana Becomes First State to Enshrine 'Right to Compute' into Law",
      "topics": [
        "history",
        "Montana",
        "state law",
        "citizens' rights",
        "legal protection"
      ],
      "source": "news",
      "url": "https://montananewsroom.com/montana-becomes-first-state-to-enshrine-right-to-compute-into-law/",
      "added_at": "2025-11-09T15:58:12.141961"
    },
    {
      "article_id": "3191832929143411579",
      "chunk_id": 0,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "static site generator",
        "modern",
        "Zensical",
        "Material for MkDocs",
        "team"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:58:14.181222"
    },
    {
      "article_id": "3191832929143411579",
      "chunk_id": 1,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "static site generator",
        "modern",
        "Zensical",
        "Material for MkDocs",
        "team"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:58:14.589043"
    },
    {
      "article_id": "3191832929143411579",
      "chunk_id": 2,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "static site generator",
        "modern",
        "Zensical",
        "Material for MkDocs",
        "team"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:58:14.896961"
    },
    {
      "article_id": "3191832929143411579",
      "chunk_id": 3,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "static site generator",
        "modern",
        "Zensical",
        "Material for MkDocs",
        "team"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:58:15.204413"
    },
    {
      "article_id": "3191832929143411579",
      "chunk_id": 4,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "static site generator",
        "modern",
        "Zensical",
        "Material for MkDocs",
        "team"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:58:15.421834"
    },
    {
      "article_id": "3191832929143411579",
      "chunk_id": 5,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "static site generator",
        "modern",
        "Zensical",
        "Material for MkDocs",
        "team"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:58:15.717063"
    },
    {
      "article_id": "3191832929143411579",
      "chunk_id": 6,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "static site generator",
        "modern",
        "Zensical",
        "Material for MkDocs",
        "team"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:58:16.023249"
    },
    {
      "article_id": "3191832929143411579",
      "chunk_id": 7,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "static site generator",
        "modern",
        "Zensical",
        "Material for MkDocs",
        "team"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:58:16.330389"
    },
    {
      "article_id": "3191832929143411579",
      "chunk_id": 8,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "static site generator",
        "modern",
        "Zensical",
        "Material for MkDocs",
        "team"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:58:16.637052"
    },
    {
      "article_id": "3191832929143411579",
      "chunk_id": 9,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "static site generator",
        "modern",
        "Zensical",
        "Material for MkDocs",
        "team"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:58:16.945308"
    },
    {
      "article_id": "3191832929143411579",
      "chunk_id": 10,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "static site generator",
        "modern",
        "Zensical",
        "Material for MkDocs",
        "team"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:58:17.151767"
    },
    {
      "article_id": "3191832929143411579",
      "chunk_id": 11,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "static site generator",
        "modern",
        "Zensical",
        "Material for MkDocs",
        "team"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:58:17.342113"
    },
    {
      "article_id": "3191832929143411579",
      "chunk_id": 12,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "static site generator",
        "modern",
        "Zensical",
        "Material for MkDocs",
        "team"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:58:17.610110"
    },
    {
      "article_id": "3191832929143411579",
      "chunk_id": 13,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "static site generator",
        "modern",
        "Zensical",
        "Material for MkDocs",
        "team"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:58:17.867800"
    },
    {
      "article_id": "3191832929143411579",
      "chunk_id": 14,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "static site generator",
        "modern",
        "Zensical",
        "Material for MkDocs",
        "team"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:58:18.173535"
    },
    {
      "article_id": "3191832929143411579",
      "chunk_id": 15,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "static site generator",
        "modern",
        "Zensical",
        "Material for MkDocs",
        "team"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:58:18.584173"
    },
    {
      "article_id": "3191832929143411579",
      "chunk_id": 16,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "static site generator",
        "modern",
        "Zensical",
        "Material for MkDocs",
        "team"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:58:18.890014"
    },
    {
      "article_id": "3191832929143411579",
      "chunk_id": 17,
      "title": "Zensical \u2013 A modern static site generator built by the Material for MkDocs team",
      "topics": [
        "static site generator",
        "modern",
        "Zensical",
        "Material for MkDocs",
        "team"
      ],
      "source": "news",
      "url": "https://squidfunk.github.io/mkdocs-material/blog/2025/11/05/zensical/",
      "added_at": "2025-11-09T15:58:19.197815"
    },
    {
      "article_id": "1865792894362204715",
      "chunk_id": 0,
      "title": "I Am Mark Zuckerberg",
      "topics": [
        "personal branding",
        "activism",
        "Mark Zuckerberg",
        "website"
      ],
      "source": "news",
      "url": "https://iammarkzuckerberg.com/",
      "added_at": "2025-11-09T15:58:21.615850"
    },
    {
      "article_id": "1865792894362204715",
      "chunk_id": 1,
      "title": "I Am Mark Zuckerberg",
      "topics": [
        "personal branding",
        "activism",
        "Mark Zuckerberg",
        "website"
      ],
      "source": "news",
      "url": "https://iammarkzuckerberg.com/",
      "added_at": "2025-11-09T15:58:21.962190"
    },
    {
      "article_id": "1865792894362204715",
      "chunk_id": 2,
      "title": "I Am Mark Zuckerberg",
      "topics": [
        "personal branding",
        "activism",
        "Mark Zuckerberg",
        "website"
      ],
      "source": "news",
      "url": "https://iammarkzuckerberg.com/",
      "added_at": "2025-11-09T15:58:22.208467"
    },
    {
      "article_id": "2233081092756928513",
      "chunk_id": 0,
      "title": "Ironclad \u2013 formally verified, real-time capable, Unix-like OS kernel",
      "topics": [
        "operating system",
        "kernel",
        "real-time",
        "UNIX-like",
        "formal verification"
      ],
      "source": "news",
      "url": "https://ironclad-os.org/",
      "added_at": "2025-11-09T15:58:23.454809"
    },
    {
      "article_id": "2233081092756928513",
      "chunk_id": 1,
      "title": "Ironclad \u2013 formally verified, real-time capable, Unix-like OS kernel",
      "topics": [
        "operating system",
        "kernel",
        "real-time",
        "UNIX-like",
        "formal verification"
      ],
      "source": "news",
      "url": "https://ironclad-os.org/",
      "added_at": "2025-11-09T15:58:23.908794"
    },
    {
      "article_id": "2233081092756928513",
      "chunk_id": 2,
      "title": "Ironclad \u2013 formally verified, real-time capable, Unix-like OS kernel",
      "topics": [
        "operating system",
        "kernel",
        "real-time",
        "UNIX-like",
        "formal verification"
      ],
      "source": "news",
      "url": "https://ironclad-os.org/",
      "added_at": "2025-11-09T15:58:24.214953"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 0,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:14.091104"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 1,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:14.374321"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 2,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:15.382118"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 3,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:16.362316"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 4,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:16.707360"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 5,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:17.798652"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 6,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:18.024469"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 7,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:18.545057"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 8,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:18.843909"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 9,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:19.163187"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 10,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:19.379044"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 11,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:19.580987"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 12,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:19.808035"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 13,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:20.051371"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 14,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:20.297735"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 15,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:20.634178"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 16,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:21.000306"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 17,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:21.240169"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 18,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:21.537069"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 19,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:21.797174"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 20,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:22.092052"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 21,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:22.325393"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 22,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:22.535842"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 23,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:22.795178"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 24,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:23.034624"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 25,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:23.325179"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 26,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:23.559432"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 27,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:23.900121"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 28,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:24.144283"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 29,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:24.565313"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 30,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:24.782095"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 31,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:25.034881"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 32,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:25.330213"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 33,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:25.535024"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 34,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:25.771053"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 35,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:26.037087"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 36,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:26.253163"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 37,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:26.527024"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 38,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:26.748232"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 39,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:27.448996"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 40,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:27.694096"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 41,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:28.113007"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 42,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:28.390424"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 43,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:28.651562"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 44,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:28.935410"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 45,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:29.241220"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 46,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:29.535474"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 47,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:29.875357"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 48,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:30.211411"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 49,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:30.525728"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 50,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:30.862159"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 51,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:31.337888"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 52,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:31.783348"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 53,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:32.066972"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 54,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:32.324895"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 55,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:32.537151"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 56,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:33.017364"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 57,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:33.510990"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 58,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:33.784086"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 59,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:33.983059"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 60,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:34.311004"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 61,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:34.595305"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 62,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:34.863475"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 63,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:35.101043"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 64,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:35.419282"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 65,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:35.820186"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 66,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:36.038104"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 67,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:36.379158"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 68,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:36.837034"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 69,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:37.054048"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 70,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:37.343099"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 71,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:37.639091"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 72,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:37.965127"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 73,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:38.237162"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 74,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:38.508078"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 75,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:38.717988"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 76,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:38.920481"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 77,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:39.150547"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 78,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:39.376331"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 79,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:39.675787"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 80,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:39.941183"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 81,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:40.251172"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 82,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:40.474036"
    },
    {
      "article_id": "1920503016844949361",
      "chunk_id": 83,
      "title": "Selective_Serotonin_Reuptake_Inhibitors_and_Advers.pdf",
      "topics": [
        "Health"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:09:40.737242"
    },
    {
      "article_id": "5823419667686607092",
      "chunk_id": 0,
      "title": "GCF-Giraffe-booklet-2017-LR-spreads-c-GCF.compressed.pdf",
      "topics": [
        "Animals",
        "Giraffes"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:21:13.699850"
    },
    {
      "article_id": "5823419667686607092",
      "chunk_id": 1,
      "title": "GCF-Giraffe-booklet-2017-LR-spreads-c-GCF.compressed.pdf",
      "topics": [
        "Animals",
        "Giraffes"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:21:14.064691"
    },
    {
      "article_id": "5823419667686607092",
      "chunk_id": 2,
      "title": "GCF-Giraffe-booklet-2017-LR-spreads-c-GCF.compressed.pdf",
      "topics": [
        "Animals",
        "Giraffes"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:21:14.269800"
    },
    {
      "article_id": "5823419667686607092",
      "chunk_id": 3,
      "title": "GCF-Giraffe-booklet-2017-LR-spreads-c-GCF.compressed.pdf",
      "topics": [
        "Animals",
        "Giraffes"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:21:14.581365"
    },
    {
      "article_id": "5823419667686607092",
      "chunk_id": 4,
      "title": "GCF-Giraffe-booklet-2017-LR-spreads-c-GCF.compressed.pdf",
      "topics": [
        "Animals",
        "Giraffes"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:21:14.790089"
    },
    {
      "article_id": "5823419667686607092",
      "chunk_id": 5,
      "title": "GCF-Giraffe-booklet-2017-LR-spreads-c-GCF.compressed.pdf",
      "topics": [
        "Animals",
        "Giraffes"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:21:15.047672"
    },
    {
      "article_id": "5823419667686607092",
      "chunk_id": 6,
      "title": "GCF-Giraffe-booklet-2017-LR-spreads-c-GCF.compressed.pdf",
      "topics": [
        "Animals",
        "Giraffes"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:21:15.248761"
    },
    {
      "article_id": "5823419667686607092",
      "chunk_id": 7,
      "title": "GCF-Giraffe-booklet-2017-LR-spreads-c-GCF.compressed.pdf",
      "topics": [
        "Animals",
        "Giraffes"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:21:15.468016"
    },
    {
      "article_id": "5823419667686607092",
      "chunk_id": 8,
      "title": "GCF-Giraffe-booklet-2017-LR-spreads-c-GCF.compressed.pdf",
      "topics": [
        "Animals",
        "Giraffes"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:21:15.662744"
    },
    {
      "article_id": "5823419667686607092",
      "chunk_id": 9,
      "title": "GCF-Giraffe-booklet-2017-LR-spreads-c-GCF.compressed.pdf",
      "topics": [
        "Animals",
        "Giraffes"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:21:15.931129"
    },
    {
      "article_id": "5823419667686607092",
      "chunk_id": 10,
      "title": "GCF-Giraffe-booklet-2017-LR-spreads-c-GCF.compressed.pdf",
      "topics": [
        "Animals",
        "Giraffes"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:21:16.248226"
    },
    {
      "article_id": "5823419667686607092",
      "chunk_id": 11,
      "title": "GCF-Giraffe-booklet-2017-LR-spreads-c-GCF.compressed.pdf",
      "topics": [
        "Animals",
        "Giraffes"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:21:16.507231"
    },
    {
      "article_id": "5823419667686607092",
      "chunk_id": 12,
      "title": "GCF-Giraffe-booklet-2017-LR-spreads-c-GCF.compressed.pdf",
      "topics": [
        "Animals",
        "Giraffes"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:21:16.807107"
    },
    {
      "article_id": "5823419667686607092",
      "chunk_id": 13,
      "title": "GCF-Giraffe-booklet-2017-LR-spreads-c-GCF.compressed.pdf",
      "topics": [
        "Animals",
        "Giraffes"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:21:17.022299"
    },
    {
      "article_id": "5823419667686607092",
      "chunk_id": 14,
      "title": "GCF-Giraffe-booklet-2017-LR-spreads-c-GCF.compressed.pdf",
      "topics": [
        "Animals",
        "Giraffes"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:21:17.343850"
    },
    {
      "article_id": "5823419667686607092",
      "chunk_id": 15,
      "title": "GCF-Giraffe-booklet-2017-LR-spreads-c-GCF.compressed.pdf",
      "topics": [
        "Animals",
        "Giraffes"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:21:17.554036"
    },
    {
      "article_id": "5823419667686607092",
      "chunk_id": 16,
      "title": "GCF-Giraffe-booklet-2017-LR-spreads-c-GCF.compressed.pdf",
      "topics": [
        "Animals",
        "Giraffes"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:21:17.775200"
    },
    {
      "article_id": "5823419667686607092",
      "chunk_id": 17,
      "title": "GCF-Giraffe-booklet-2017-LR-spreads-c-GCF.compressed.pdf",
      "topics": [
        "Animals",
        "Giraffes"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:21:18.048044"
    },
    {
      "article_id": "5823419667686607092",
      "chunk_id": 18,
      "title": "GCF-Giraffe-booklet-2017-LR-spreads-c-GCF.compressed.pdf",
      "topics": [
        "Animals",
        "Giraffes"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:21:18.254023"
    },
    {
      "article_id": "5823419667686607092",
      "chunk_id": 19,
      "title": "GCF-Giraffe-booklet-2017-LR-spreads-c-GCF.compressed.pdf",
      "topics": [
        "Animals",
        "Giraffes"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:21:18.787394"
    },
    {
      "article_id": "5823419667686607092",
      "chunk_id": 20,
      "title": "GCF-Giraffe-booklet-2017-LR-spreads-c-GCF.compressed.pdf",
      "topics": [
        "Animals",
        "Giraffes"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:21:19.097625"
    },
    {
      "article_id": "5823419667686607092",
      "chunk_id": 21,
      "title": "GCF-Giraffe-booklet-2017-LR-spreads-c-GCF.compressed.pdf",
      "topics": [
        "Animals",
        "Giraffes"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:21:19.307251"
    },
    {
      "article_id": "5823419667686607092",
      "chunk_id": 22,
      "title": "GCF-Giraffe-booklet-2017-LR-spreads-c-GCF.compressed.pdf",
      "topics": [
        "Animals",
        "Giraffes"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:21:19.526882"
    },
    {
      "article_id": "5823419667686607092",
      "chunk_id": 23,
      "title": "GCF-Giraffe-booklet-2017-LR-spreads-c-GCF.compressed.pdf",
      "topics": [
        "Animals",
        "Giraffes"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:21:19.736072"
    },
    {
      "article_id": "5823419667686607092",
      "chunk_id": 24,
      "title": "GCF-Giraffe-booklet-2017-LR-spreads-c-GCF.compressed.pdf",
      "topics": [
        "Animals",
        "Giraffes"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:21:19.935036"
    },
    {
      "article_id": "5823419667686607092",
      "chunk_id": 25,
      "title": "GCF-Giraffe-booklet-2017-LR-spreads-c-GCF.compressed.pdf",
      "topics": [
        "Animals",
        "Giraffes"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:21:20.149047"
    },
    {
      "article_id": "5823419667686607092",
      "chunk_id": 26,
      "title": "GCF-Giraffe-booklet-2017-LR-spreads-c-GCF.compressed.pdf",
      "topics": [
        "Animals",
        "Giraffes"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:21:20.365848"
    },
    {
      "article_id": "5823419667686607092",
      "chunk_id": 27,
      "title": "GCF-Giraffe-booklet-2017-LR-spreads-c-GCF.compressed.pdf",
      "topics": [
        "Animals",
        "Giraffes"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:21:20.760201"
    },
    {
      "article_id": "5823419667686607092",
      "chunk_id": 28,
      "title": "GCF-Giraffe-booklet-2017-LR-spreads-c-GCF.compressed.pdf",
      "topics": [
        "Animals",
        "Giraffes"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:21:21.065201"
    },
    {
      "article_id": "5823419667686607092",
      "chunk_id": 29,
      "title": "GCF-Giraffe-booklet-2017-LR-spreads-c-GCF.compressed.pdf",
      "topics": [
        "Animals",
        "Giraffes"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:21:21.326138"
    },
    {
      "article_id": "5823419667686607092",
      "chunk_id": 30,
      "title": "GCF-Giraffe-booklet-2017-LR-spreads-c-GCF.compressed.pdf",
      "topics": [
        "Animals",
        "Giraffes"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:21:21.527890"
    },
    {
      "article_id": "5823419667686607092",
      "chunk_id": 31,
      "title": "GCF-Giraffe-booklet-2017-LR-spreads-c-GCF.compressed.pdf",
      "topics": [
        "Animals",
        "Giraffes"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:21:21.741931"
    },
    {
      "article_id": "5823419667686607092",
      "chunk_id": 32,
      "title": "GCF-Giraffe-booklet-2017-LR-spreads-c-GCF.compressed.pdf",
      "topics": [
        "Animals",
        "Giraffes"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:21:22.253189"
    },
    {
      "article_id": "5823419667686607092",
      "chunk_id": 33,
      "title": "GCF-Giraffe-booklet-2017-LR-spreads-c-GCF.compressed.pdf",
      "topics": [
        "Animals",
        "Giraffes"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:21:22.790004"
    },
    {
      "article_id": "5823419667686607092",
      "chunk_id": 34,
      "title": "GCF-Giraffe-booklet-2017-LR-spreads-c-GCF.compressed.pdf",
      "topics": [
        "Animals",
        "Giraffes"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:21:23.289362"
    },
    {
      "article_id": "5823419667686607092",
      "chunk_id": 35,
      "title": "GCF-Giraffe-booklet-2017-LR-spreads-c-GCF.compressed.pdf",
      "topics": [
        "Animals",
        "Giraffes"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:21:23.490850"
    },
    {
      "article_id": "5823419667686607092",
      "chunk_id": 36,
      "title": "GCF-Giraffe-booklet-2017-LR-spreads-c-GCF.compressed.pdf",
      "topics": [
        "Animals",
        "Giraffes"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:21:23.783261"
    },
    {
      "article_id": "5823419667686607092",
      "chunk_id": 37,
      "title": "GCF-Giraffe-booklet-2017-LR-spreads-c-GCF.compressed.pdf",
      "topics": [
        "Animals",
        "Giraffes"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:21:24.160124"
    },
    {
      "article_id": "5823419667686607092",
      "chunk_id": 38,
      "title": "GCF-Giraffe-booklet-2017-LR-spreads-c-GCF.compressed.pdf",
      "topics": [
        "Animals",
        "Giraffes"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:21:24.599097"
    },
    {
      "article_id": "5823419667686607092",
      "chunk_id": 39,
      "title": "GCF-Giraffe-booklet-2017-LR-spreads-c-GCF.compressed.pdf",
      "topics": [
        "Animals",
        "Giraffes"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:21:24.975386"
    },
    {
      "article_id": "5823419667686607092",
      "chunk_id": 40,
      "title": "GCF-Giraffe-booklet-2017-LR-spreads-c-GCF.compressed.pdf",
      "topics": [
        "Animals",
        "Giraffes"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:21:25.322037"
    },
    {
      "article_id": "5823419667686607092",
      "chunk_id": 41,
      "title": "GCF-Giraffe-booklet-2017-LR-spreads-c-GCF.compressed.pdf",
      "topics": [
        "Animals",
        "Giraffes"
      ],
      "source": "user",
      "url": null,
      "user_email": "system",
      "added_at": "2025-11-10T12:21:25.546185"
    }
  ],
  "last_updated": "2025-11-10T12:21:25.551358"
}